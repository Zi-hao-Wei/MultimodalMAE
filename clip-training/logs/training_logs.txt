2023-01-22 22:44:40,044 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 4, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:44:42,294 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:44:42,294 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:44:42,295 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:44:42,295 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:44:42,295 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2023-01-22 22:44:42,305 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 64
2023-01-22 22:44:42,305 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:44:42,305 CLIP_COCO_TRAIN INFO:   Total optimization steps = 64715
2023-01-22 22:44:42,306 CLIP_COCO_TRAIN INFO:   warmup steps = 12943
2023-01-22 22:46:13,572 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 4, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:46:15,732 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:46:15,732 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:46:15,733 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:46:15,733 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:46:15,733 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2023-01-22 22:46:15,734 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 64
2023-01-22 22:46:15,734 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:46:15,735 CLIP_COCO_TRAIN INFO:   Total optimization steps = 64715
2023-01-22 22:46:15,735 CLIP_COCO_TRAIN INFO:   warmup steps = 12943
2023-01-22 22:48:00,658 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 4, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:48:02,678 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:48:02,679 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:48:02,679 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:48:02,680 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:48:02,680 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2023-01-22 22:48:02,680 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 64
2023-01-22 22:48:02,681 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:48:02,681 CLIP_COCO_TRAIN INFO:   Total optimization steps = 64715
2023-01-22 22:48:02,681 CLIP_COCO_TRAIN INFO:   warmup steps = 12943
2023-01-22 22:50:40,381 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 4, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:50:42,462 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:50:42,462 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:50:42,463 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:50:42,463 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:50:42,464 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2023-01-22 22:50:42,464 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 64
2023-01-22 22:50:42,464 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:50:42,465 CLIP_COCO_TRAIN INFO:   Total optimization steps = 64715
2023-01-22 22:50:42,465 CLIP_COCO_TRAIN INFO:   warmup steps = 12943
2023-01-22 22:52:21,394 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 4, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:52:23,534 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:52:23,536 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:52:23,537 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:52:23,537 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:52:23,538 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2023-01-22 22:52:23,538 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 64
2023-01-22 22:52:23,538 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:52:23,539 CLIP_COCO_TRAIN INFO:   Total optimization steps = 64715
2023-01-22 22:52:23,539 CLIP_COCO_TRAIN INFO:   warmup steps = 12943
2023-01-22 22:52:58,390 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 4, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:53:00,489 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:53:00,490 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:53:00,490 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:53:00,490 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:53:00,491 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2023-01-22 22:53:00,491 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 64
2023-01-22 22:53:00,492 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:53:00,492 CLIP_COCO_TRAIN INFO:   Total optimization steps = 64715
2023-01-22 22:53:00,492 CLIP_COCO_TRAIN INFO:   warmup steps = 12943
2023-01-22 22:56:37,338 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 4, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:56:39,429 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:56:39,429 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:56:39,430 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:56:39,430 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:56:39,431 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2023-01-22 22:56:39,431 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 64
2023-01-22 22:56:39,431 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:56:39,431 CLIP_COCO_TRAIN INFO:   Total optimization steps = 64715
2023-01-22 22:56:39,432 CLIP_COCO_TRAIN INFO:   warmup steps = 12943
2023-01-22 22:58:01,089 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 64, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:58:04,293 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:58:04,294 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:58:04,294 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:58:04,294 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:58:04,295 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 64
2023-01-22 22:58:04,295 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 64
2023-01-22 22:58:04,295 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:58:04,295 CLIP_COCO_TRAIN INFO:   Total optimization steps = 64715
2023-01-22 22:58:04,296 CLIP_COCO_TRAIN INFO:   warmup steps = 12943
2023-01-22 22:59:17,518 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 32, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 22:59:19,565 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 22:59:19,565 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 22:59:19,566 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 22:59:19,566 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 22:59:19,567 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 32
2023-01-22 22:59:19,567 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 32
2023-01-22 22:59:19,568 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 22:59:19,568 CLIP_COCO_TRAIN INFO:   Total optimization steps = 129395
2023-01-22 22:59:19,568 CLIP_COCO_TRAIN INFO:   warmup steps = 25879
2023-01-22 23:00:27,120 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 32, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:00:29,260 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:00:29,261 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:00:29,262 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:00:29,263 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:00:29,263 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 32
2023-01-22 23:00:29,263 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 32
2023-01-22 23:00:29,264 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:00:29,264 CLIP_COCO_TRAIN INFO:   Total optimization steps = 129395
2023-01-22 23:00:29,264 CLIP_COCO_TRAIN INFO:   warmup steps = 25879
2023-01-22 23:02:57,567 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 32, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:02:59,618 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:02:59,618 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:02:59,619 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:02:59,619 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:02:59,619 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 32
2023-01-22 23:02:59,620 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 32
2023-01-22 23:02:59,620 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:02:59,620 CLIP_COCO_TRAIN INFO:   Total optimization steps = 129395
2023-01-22 23:02:59,621 CLIP_COCO_TRAIN INFO:   warmup steps = 25879
2023-01-22 23:03:28,903 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 32, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:03:30,990 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:03:30,990 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:03:30,991 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:03:30,991 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:03:30,992 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 32
2023-01-22 23:03:30,992 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 32
2023-01-22 23:03:30,992 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:03:30,993 CLIP_COCO_TRAIN INFO:   Total optimization steps = 129395
2023-01-22 23:03:30,993 CLIP_COCO_TRAIN INFO:   warmup steps = 25879
2023-01-22 23:04:09,821 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 32, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:04:11,864 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:04:11,865 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:04:11,865 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:04:11,865 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:04:11,866 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 32
2023-01-22 23:04:11,866 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 32
2023-01-22 23:04:11,866 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:04:11,867 CLIP_COCO_TRAIN INFO:   Total optimization steps = 129395
2023-01-22 23:04:11,867 CLIP_COCO_TRAIN INFO:   warmup steps = 25879
2023-01-22 23:06:44,796 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 8, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:06:47,055 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:06:47,055 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:06:47,056 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:06:47,056 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:06:47,056 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 8
2023-01-22 23:06:47,057 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 8
2023-01-22 23:06:47,057 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:06:47,058 CLIP_COCO_TRAIN INFO:   Total optimization steps = 517510
2023-01-22 23:06:47,058 CLIP_COCO_TRAIN INFO:   warmup steps = 103502
2023-01-22 23:07:06,123 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000000, loss: nan (nan)
2023-01-22 23:07:21,762 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000000, loss: nan (nan)
2023-01-22 23:08:34,583 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 8, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:08:36,690 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:08:36,690 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:08:36,691 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:08:36,691 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:08:36,692 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 8
2023-01-22 23:08:36,692 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 8
2023-01-22 23:08:36,692 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:08:36,693 CLIP_COCO_TRAIN INFO:   Total optimization steps = 517510
2023-01-22 23:08:36,693 CLIP_COCO_TRAIN INFO:   warmup steps = 103502
2023-01-22 23:09:10,541 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 8, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:09:12,661 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:09:12,661 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:09:12,662 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:09:12,662 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:09:12,662 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 8
2023-01-22 23:09:12,663 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 8
2023-01-22 23:09:12,663 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:09:12,663 CLIP_COCO_TRAIN INFO:   Total optimization steps = 517510
2023-01-22 23:09:12,664 CLIP_COCO_TRAIN INFO:   warmup steps = 103502
2023-01-22 23:11:54,102 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 8, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 5e-06, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:11:56,226 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:11:56,228 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:11:56,228 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:11:56,229 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:11:56,229 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 8
2023-01-22 23:11:56,230 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 8
2023-01-22 23:11:56,230 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:11:56,230 CLIP_COCO_TRAIN INFO:   Total optimization steps = 517510
2023-01-22 23:11:56,231 CLIP_COCO_TRAIN INFO:   warmup steps = 103502
2023-01-22 23:15:09,095 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 8, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 5e-06, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:15:11,360 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:15:11,360 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:15:11,361 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:15:11,361 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:15:11,362 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 8
2023-01-22 23:15:11,362 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 8
2023-01-22 23:15:11,363 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:15:11,363 CLIP_COCO_TRAIN INFO:   Total optimization steps = 517510
2023-01-22 23:15:11,364 CLIP_COCO_TRAIN INFO:   warmup steps = 103502
2023-01-22 23:15:48,755 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 8, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 5e-06, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:15:51,020 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:15:51,021 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:15:51,021 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:15:51,022 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:15:51,022 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 8
2023-01-22 23:15:51,023 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 8
2023-01-22 23:15:51,023 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:15:51,023 CLIP_COCO_TRAIN INFO:   Total optimization steps = 517510
2023-01-22 23:15:51,023 CLIP_COCO_TRAIN INFO:   warmup steps = 103502
2023-01-22 23:16:15,133 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 8, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 5e-06, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:16:17,367 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:16:17,368 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:16:17,369 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:16:17,369 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:16:17,370 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 8
2023-01-22 23:16:17,370 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 8
2023-01-22 23:16:17,370 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:16:17,371 CLIP_COCO_TRAIN INFO:   Total optimization steps = 517510
2023-01-22 23:16:17,371 CLIP_COCO_TRAIN INFO:   warmup steps = 103502
2023-01-22 23:16:29,952 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000000, loss: 0.9713 (0.9737)
2023-01-22 23:16:40,116 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000000, loss: 0.9663 (0.9725)
2023-01-22 23:16:50,525 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 150, lr: 0.000000, loss: 0.9671 (0.9703)
2023-01-22 23:17:01,144 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 200, lr: 0.000000, loss: 0.9573 (0.9675)
2023-01-22 23:18:55,767 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 5e-06, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:18:57,862 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:18:57,862 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:18:57,864 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:18:57,865 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:18:57,866 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 16
2023-01-22 23:18:57,866 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 16
2023-01-22 23:18:57,867 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:18:57,867 CLIP_COCO_TRAIN INFO:   Total optimization steps = 258755
2023-01-22 23:18:57,867 CLIP_COCO_TRAIN INFO:   warmup steps = 51751
2023-01-22 23:19:17,597 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000000, loss: 0.9707 (0.9733)
2023-01-22 23:19:36,100 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000000, loss: 0.9674 (0.9706)
2023-01-22 23:19:54,760 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 150, lr: 0.000000, loss: 0.9539 (0.9665)
2023-01-22 23:20:13,688 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 200, lr: 0.000000, loss: 0.9342 (0.9610)
2023-01-22 23:20:33,845 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 250, lr: 0.000000, loss: 0.9149 (0.9539)
2023-01-22 23:20:59,794 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 1000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 5e-06, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:21:01,983 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:21:01,984 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:21:01,985 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:21:01,985 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:21:01,985 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 16
2023-01-22 23:21:01,986 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 16
2023-01-22 23:21:01,986 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:21:01,986 CLIP_COCO_TRAIN INFO:   Total optimization steps = 258755
2023-01-22 23:21:01,987 CLIP_COCO_TRAIN INFO:   warmup steps = 51751
2023-01-22 23:21:21,761 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000000, loss: 0.9707 (0.9733)
2023-01-22 23:21:39,969 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000000, loss: 0.9674 (0.9706)
2023-01-22 23:21:59,340 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 150, lr: 0.000000, loss: 0.9539 (0.9665)
2023-01-22 23:22:19,068 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 200, lr: 0.000000, loss: 0.9342 (0.9610)
2023-01-22 23:22:41,215 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 250, lr: 0.000000, loss: 0.9149 (0.9539)
2023-01-22 23:23:01,306 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 300, lr: 0.000000, loss: 0.8899 (0.9455)
2023-01-22 23:23:21,669 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 350, lr: 0.000000, loss: 0.8646 (0.9357)
2023-01-22 23:23:41,881 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 400, lr: 0.000000, loss: 0.8308 (0.9246)
2023-01-22 23:24:02,151 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 450, lr: 0.000000, loss: 0.7972 (0.9123)
2023-01-22 23:24:22,181 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 500, lr: 0.000000, loss: 0.7646 (0.8990)
2023-01-22 23:24:42,900 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 550, lr: 0.000000, loss: 0.7227 (0.8846)
2023-01-22 23:25:04,023 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 600, lr: 0.000000, loss: 0.6831 (0.8693)
2023-01-22 23:25:24,692 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 650, lr: 0.000000, loss: 0.6432 (0.8533)
2023-01-22 23:25:44,483 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 700, lr: 0.000000, loss: 0.6048 (0.8368)
2023-01-22 23:26:04,403 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 750, lr: 0.000000, loss: 0.5642 (0.8199)
2023-01-22 23:26:24,097 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 800, lr: 0.000000, loss: 0.5319 (0.8029)
2023-01-22 23:26:44,476 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 850, lr: 0.000000, loss: 0.4958 (0.7859)
2023-01-22 23:27:04,202 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 900, lr: 0.000000, loss: 0.4679 (0.7691)
2023-01-22 23:27:23,861 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 950, lr: 0.000000, loss: 0.4423 (0.7525)
2023-01-22 23:27:43,572 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1000, lr: 0.000000, loss: 0.4180 (0.7364)
2023-01-22 23:27:44,967 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_0_1000.pt
2023-01-22 23:28:04,584 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1050, lr: 0.000000, loss: 0.3923 (0.7205)
2023-01-22 23:28:24,468 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1100, lr: 0.000000, loss: 0.3742 (0.7051)
2023-01-22 23:28:45,024 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1150, lr: 0.000000, loss: 0.3502 (0.6902)
2023-01-22 23:29:05,472 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1200, lr: 0.000000, loss: 0.3331 (0.6756)
2023-01-22 23:29:58,136 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-22 23:30:00,206 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-22 23:30:00,206 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-22 23:30:00,207 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-22 23:30:00,207 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-22 23:30:00,207 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 16
2023-01-22 23:30:00,208 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 16
2023-01-22 23:30:00,208 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-22 23:30:00,209 CLIP_COCO_TRAIN INFO:   Total optimization steps = 258755
2023-01-22 23:30:00,209 CLIP_COCO_TRAIN INFO:   warmup steps = 51751
2023-01-22 23:30:19,538 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000000, loss: 0.7713 (0.9035)
2023-01-22 23:30:36,760 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000001, loss: 0.4396 (0.7468)
2023-01-22 23:30:54,184 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 150, lr: 0.000001, loss: 0.2569 (0.6099)
2023-01-22 23:31:12,372 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 200, lr: 0.000002, loss: 0.1620 (0.5086)
2023-01-22 23:31:30,739 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 250, lr: 0.000002, loss: 0.1164 (0.4341)
2023-01-22 23:31:49,487 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 300, lr: 0.000003, loss: 0.0902 (0.3786)
2023-01-22 23:32:08,377 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 350, lr: 0.000003, loss: 0.0735 (0.3364)
2023-01-22 23:32:27,420 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 400, lr: 0.000004, loss: 0.0732 (0.3034)
2023-01-22 23:32:46,447 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 450, lr: 0.000004, loss: 0.0619 (0.2770)
2023-01-22 23:33:05,640 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 500, lr: 0.000005, loss: 0.0604 (0.2556)
2023-01-22 23:33:24,659 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 550, lr: 0.000005, loss: 0.0591 (0.2378)
2023-01-22 23:33:43,986 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 600, lr: 0.000006, loss: 0.0551 (0.2229)
2023-01-22 23:34:03,156 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 650, lr: 0.000006, loss: 0.0537 (0.2101)
2023-01-22 23:34:22,250 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 700, lr: 0.000007, loss: 0.0571 (0.1992)
2023-01-22 23:34:41,600 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 750, lr: 0.000007, loss: 0.0591 (0.1897)
2023-01-22 23:35:00,957 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 800, lr: 0.000008, loss: 0.0532 (0.1813)
2023-01-22 23:35:20,173 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 850, lr: 0.000008, loss: 0.0531 (0.1738)
2023-01-22 23:35:39,458 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 900, lr: 0.000009, loss: 0.0532 (0.1672)
2023-01-22 23:35:58,933 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 950, lr: 0.000009, loss: 0.0539 (0.1612)
2023-01-22 23:36:18,348 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1000, lr: 0.000010, loss: 0.0529 (0.1558)
2023-01-22 23:36:37,818 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1050, lr: 0.000010, loss: 0.0507 (0.1510)
2023-01-22 23:36:57,170 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1100, lr: 0.000011, loss: 0.0563 (0.1465)
2023-01-22 23:37:16,700 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1150, lr: 0.000011, loss: 0.0542 (0.1425)
2023-01-22 23:37:36,194 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1200, lr: 0.000012, loss: 0.0553 (0.1387)
2023-01-22 23:37:55,776 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1250, lr: 0.000012, loss: 0.0516 (0.1353)
2023-01-22 23:38:15,400 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1300, lr: 0.000013, loss: 0.0500 (0.1321)
2023-01-22 23:38:35,046 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1350, lr: 0.000013, loss: 0.0506 (0.1292)
2023-01-22 23:38:54,781 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1400, lr: 0.000014, loss: 0.0536 (0.1264)
2023-01-22 23:39:14,505 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1450, lr: 0.000014, loss: 0.0505 (0.1239)
2023-01-22 23:39:34,247 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1500, lr: 0.000014, loss: 0.0518 (0.1215)
2023-01-22 23:39:54,242 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1550, lr: 0.000015, loss: 0.0524 (0.1193)
2023-01-22 23:40:13,864 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1600, lr: 0.000015, loss: 0.0530 (0.1172)
2023-01-22 23:40:33,393 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1650, lr: 0.000016, loss: 0.0496 (0.1152)
2023-01-22 23:40:52,902 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1700, lr: 0.000016, loss: 0.0502 (0.1133)
2023-01-22 23:41:12,415 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1750, lr: 0.000017, loss: 0.0502 (0.1116)
2023-01-22 23:41:31,900 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1800, lr: 0.000017, loss: 0.0506 (0.1099)
2023-01-22 23:41:51,426 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1850, lr: 0.000018, loss: 0.0527 (0.1083)
2023-01-22 23:42:10,884 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1900, lr: 0.000018, loss: 0.0514 (0.1068)
2023-01-22 23:42:30,357 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1950, lr: 0.000019, loss: 0.0551 (0.1054)
2023-01-22 23:42:49,841 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2000, lr: 0.000019, loss: 0.0526 (0.1041)
2023-01-22 23:43:09,382 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2050, lr: 0.000020, loss: 0.0511 (0.1028)
2023-01-22 23:43:28,909 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2100, lr: 0.000020, loss: 0.0481 (0.1016)
2023-01-22 23:43:48,403 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2150, lr: 0.000021, loss: 0.0533 (0.1004)
2023-01-22 23:44:07,992 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2200, lr: 0.000021, loss: 0.0525 (0.0993)
2023-01-22 23:44:27,523 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2250, lr: 0.000022, loss: 0.0506 (0.0983)
2023-01-22 23:44:47,111 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2300, lr: 0.000022, loss: 0.0500 (0.0973)
2023-01-22 23:45:06,603 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2350, lr: 0.000023, loss: 0.0486 (0.0963)
2023-01-22 23:45:26,117 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2400, lr: 0.000023, loss: 0.0514 (0.0954)
2023-01-22 23:45:45,612 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2450, lr: 0.000024, loss: 0.0529 (0.0945)
2023-01-22 23:46:05,131 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2500, lr: 0.000024, loss: 0.0481 (0.0936)
2023-01-22 23:46:24,500 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2550, lr: 0.000025, loss: 0.0502 (0.0928)
2023-01-22 23:46:43,991 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2600, lr: 0.000025, loss: 0.0522 (0.0920)
2023-01-22 23:47:03,533 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2650, lr: 0.000026, loss: 0.0507 (0.0912)
2023-01-22 23:47:22,958 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2700, lr: 0.000026, loss: 0.0514 (0.0905)
2023-01-22 23:47:42,423 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2750, lr: 0.000027, loss: 0.0495 (0.0898)
2023-01-22 23:48:02,542 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2800, lr: 0.000027, loss: 0.0490 (0.0891)
2023-01-22 23:48:25,363 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2850, lr: 0.000028, loss: 0.0555 (0.0885)
2023-01-22 23:48:45,284 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2900, lr: 0.000028, loss: 0.0518 (0.0878)
2023-01-22 23:49:05,207 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2950, lr: 0.000029, loss: 0.0517 (0.0872)
2023-01-22 23:49:25,247 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3000, lr: 0.000029, loss: 0.0508 (0.0866)
2023-01-22 23:49:45,314 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3050, lr: 0.000029, loss: 0.0534 (0.0860)
2023-01-22 23:50:05,383 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3100, lr: 0.000030, loss: 0.0501 (0.0855)
2023-01-22 23:50:25,470 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3150, lr: 0.000030, loss: 0.0551 (0.0849)
2023-01-22 23:50:45,683 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3200, lr: 0.000031, loss: 0.0514 (0.0844)
2023-01-22 23:51:05,665 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3250, lr: 0.000031, loss: 0.0504 (0.0839)
2023-01-22 23:51:25,722 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3300, lr: 0.000032, loss: 0.0519 (0.0834)
2023-01-22 23:51:45,964 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3350, lr: 0.000032, loss: 0.0495 (0.0829)
2023-01-22 23:52:06,024 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3400, lr: 0.000033, loss: 0.0531 (0.0824)
2023-01-22 23:52:26,062 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3450, lr: 0.000033, loss: 0.0495 (0.0820)
2023-01-22 23:52:46,201 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3500, lr: 0.000034, loss: 0.0503 (0.0816)
2023-01-22 23:53:06,301 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3550, lr: 0.000034, loss: 0.0504 (0.0811)
2023-01-22 23:53:26,457 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3600, lr: 0.000035, loss: 0.0491 (0.0807)
2023-01-22 23:53:46,595 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3650, lr: 0.000035, loss: 0.0479 (0.0803)
2023-01-22 23:54:06,694 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3700, lr: 0.000036, loss: 0.0515 (0.0799)
2023-01-22 23:54:26,853 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3750, lr: 0.000036, loss: 0.0489 (0.0795)
2023-01-22 23:54:46,959 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3800, lr: 0.000037, loss: 0.0515 (0.0792)
2023-01-22 23:55:07,200 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3850, lr: 0.000037, loss: 0.0555 (0.0788)
2023-01-22 23:55:27,191 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3900, lr: 0.000038, loss: 0.0538 (0.0785)
2023-01-22 23:55:47,345 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3950, lr: 0.000038, loss: 0.0520 (0.0781)
2023-01-22 23:56:07,449 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4000, lr: 0.000039, loss: 0.0508 (0.0778)
2023-01-22 23:56:27,538 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4050, lr: 0.000039, loss: 0.0527 (0.0774)
2023-01-22 23:56:47,567 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4100, lr: 0.000040, loss: 0.0499 (0.0771)
2023-01-22 23:57:07,659 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4150, lr: 0.000040, loss: 0.0533 (0.0768)
2023-01-22 23:57:27,921 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4200, lr: 0.000041, loss: 0.0509 (0.0765)
2023-01-22 23:57:48,265 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4250, lr: 0.000041, loss: 0.0532 (0.0762)
2023-01-22 23:58:08,685 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4300, lr: 0.000042, loss: 0.0484 (0.0759)
2023-01-22 23:58:28,801 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4350, lr: 0.000042, loss: 0.0505 (0.0756)
2023-01-22 23:58:48,650 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4400, lr: 0.000043, loss: 0.0486 (0.0753)
2023-01-22 23:59:08,494 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4450, lr: 0.000043, loss: 0.0502 (0.0750)
2023-01-22 23:59:28,390 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4500, lr: 0.000043, loss: 0.0534 (0.0748)
2023-01-22 23:59:48,036 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4550, lr: 0.000044, loss: 0.0486 (0.0745)
2023-01-23 00:00:07,871 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4600, lr: 0.000044, loss: 0.0502 (0.0742)
2023-01-23 00:00:27,665 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4650, lr: 0.000045, loss: 0.0546 (0.0740)
2023-01-23 00:00:47,354 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4700, lr: 0.000045, loss: 0.0486 (0.0737)
2023-01-23 00:01:07,253 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4750, lr: 0.000046, loss: 0.0514 (0.0735)
2023-01-23 00:01:26,827 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4800, lr: 0.000046, loss: 0.0508 (0.0733)
2023-01-23 00:01:46,605 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4850, lr: 0.000047, loss: 0.0498 (0.0730)
2023-01-23 00:02:06,264 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4900, lr: 0.000047, loss: 0.0508 (0.0728)
2023-01-23 00:02:26,048 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4950, lr: 0.000048, loss: 0.0492 (0.0726)
2023-01-23 00:02:45,690 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5000, lr: 0.000048, loss: 0.0515 (0.0724)
2023-01-23 00:03:05,405 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5050, lr: 0.000049, loss: 0.0554 (0.0721)
2023-01-23 00:03:25,163 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5100, lr: 0.000049, loss: 0.0539 (0.0719)
2023-01-23 00:03:44,901 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5150, lr: 0.000050, loss: 0.0487 (0.0717)
2023-01-23 00:04:04,562 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5200, lr: 0.000050, loss: 0.0515 (0.0715)
2023-01-23 00:04:24,168 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5250, lr: 0.000051, loss: 0.0526 (0.0713)
2023-01-23 00:04:43,904 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5300, lr: 0.000051, loss: 0.0480 (0.0711)
2023-01-23 00:05:03,634 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5350, lr: 0.000052, loss: 0.0479 (0.0709)
2023-01-23 00:05:23,281 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5400, lr: 0.000052, loss: 0.0498 (0.0707)
2023-01-23 00:05:42,930 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5450, lr: 0.000053, loss: 0.0513 (0.0706)
2023-01-23 00:06:02,549 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5500, lr: 0.000053, loss: 0.0503 (0.0704)
2023-01-23 00:06:22,301 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5550, lr: 0.000054, loss: 0.0519 (0.0702)
2023-01-23 00:06:41,977 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5600, lr: 0.000054, loss: 0.0492 (0.0700)
2023-01-23 00:07:01,631 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5650, lr: 0.000055, loss: 0.0485 (0.0698)
2023-01-23 00:07:21,297 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5700, lr: 0.000055, loss: 0.0512 (0.0697)
2023-01-23 00:07:40,904 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5750, lr: 0.000056, loss: 0.0507 (0.0695)
2023-01-23 00:08:00,537 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5800, lr: 0.000056, loss: 0.0553 (0.0693)
2023-01-23 00:08:20,238 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5850, lr: 0.000057, loss: 0.0488 (0.0692)
2023-01-23 00:08:39,827 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5900, lr: 0.000057, loss: 0.0510 (0.0690)
2023-01-23 00:08:59,532 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5950, lr: 0.000057, loss: 0.0484 (0.0689)
2023-01-23 00:09:19,268 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6000, lr: 0.000058, loss: 0.0494 (0.0687)
2023-01-23 00:09:38,868 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6050, lr: 0.000058, loss: 0.0485 (0.0685)
2023-01-23 00:09:58,523 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6100, lr: 0.000059, loss: 0.0515 (0.0684)
2023-01-23 00:10:18,200 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6150, lr: 0.000059, loss: 0.0481 (0.0683)
2023-01-23 00:10:37,816 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6200, lr: 0.000060, loss: 0.0499 (0.0681)
2023-01-23 00:10:57,336 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6250, lr: 0.000060, loss: 0.0508 (0.0680)
2023-01-23 00:11:17,027 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6300, lr: 0.000061, loss: 0.0480 (0.0678)
2023-01-23 00:11:36,723 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6350, lr: 0.000061, loss: 0.0487 (0.0677)
2023-01-23 00:11:56,293 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6400, lr: 0.000062, loss: 0.0538 (0.0675)
2023-01-23 00:12:16,011 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6450, lr: 0.000062, loss: 0.0511 (0.0674)
2023-01-23 00:12:35,732 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6500, lr: 0.000063, loss: 0.0509 (0.0673)
2023-01-23 00:12:56,688 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6550, lr: 0.000063, loss: 0.0489 (0.0672)
2023-01-23 00:13:20,213 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6600, lr: 0.000064, loss: 0.0510 (0.0670)
2023-01-23 00:13:40,182 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6650, lr: 0.000064, loss: 0.0510 (0.0669)
2023-01-23 00:14:01,043 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6700, lr: 0.000065, loss: 0.0536 (0.0668)
2023-01-23 00:14:21,187 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6750, lr: 0.000065, loss: 0.0490 (0.0666)
2023-01-23 00:14:41,657 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6800, lr: 0.000066, loss: 0.0471 (0.0665)
2023-01-23 00:15:02,085 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6850, lr: 0.000066, loss: 0.0504 (0.0664)
2023-01-23 00:15:22,796 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6900, lr: 0.000067, loss: 0.0520 (0.0663)
2023-01-23 00:15:43,237 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6950, lr: 0.000067, loss: 0.0477 (0.0662)
2023-01-23 00:17:50,938 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 00:17:59,815 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 00:18:01,901 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 00:18:01,902 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 00:18:01,903 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 00:18:01,904 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 00:18:01,904 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 16
2023-01-23 00:18:01,905 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 16
2023-01-23 00:18:01,905 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 00:18:01,906 CLIP_COCO_TRAIN INFO:   Total optimization steps = 258755
2023-01-23 00:18:01,906 CLIP_COCO_TRAIN INFO:   warmup steps = 51751
2023-01-23 00:18:15,929 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 16, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 00:18:17,963 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 00:18:17,964 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 00:18:17,964 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 00:18:17,965 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 00:18:17,965 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 16
2023-01-23 00:18:17,965 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 16
2023-01-23 00:18:17,966 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 00:18:17,966 CLIP_COCO_TRAIN INFO:   Total optimization steps = 258755
2023-01-23 00:18:17,967 CLIP_COCO_TRAIN INFO:   warmup steps = 51751
2023-01-23 00:18:36,699 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 50, lr: 0.000000, loss: 0.9809 (1.1012)
2023-01-23 00:18:53,519 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 100, lr: 0.000001, loss: 0.6285 (0.9487)
2023-01-23 00:19:11,102 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 150, lr: 0.000001, loss: 0.4126 (0.8013)
2023-01-23 00:19:28,519 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 200, lr: 0.000002, loss: 0.3025 (0.6889)
2023-01-23 00:19:46,698 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 250, lr: 0.000002, loss: 0.2471 (0.6054)
2023-01-23 00:20:06,555 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 300, lr: 0.000003, loss: 0.2136 (0.5425)
2023-01-23 00:20:25,824 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 350, lr: 0.000003, loss: 0.1884 (0.4939)
2023-01-23 00:20:45,079 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 400, lr: 0.000004, loss: 0.1720 (0.4547)
2023-01-23 00:21:04,036 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 450, lr: 0.000004, loss: 0.1421 (0.4215)
2023-01-23 00:21:23,191 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 500, lr: 0.000005, loss: 0.1235 (0.3926)
2023-01-23 00:21:42,512 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 550, lr: 0.000005, loss: 0.1084 (0.3674)
2023-01-23 00:22:02,467 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 600, lr: 0.000006, loss: 0.0933 (0.3452)
2023-01-23 00:22:21,891 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 650, lr: 0.000006, loss: 0.0851 (0.3257)
2023-01-23 00:22:40,449 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 700, lr: 0.000007, loss: 0.0821 (0.3084)
2023-01-23 00:22:59,108 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 750, lr: 0.000007, loss: 0.0777 (0.2931)
2023-01-23 00:23:17,686 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 800, lr: 0.000008, loss: 0.0699 (0.2793)
2023-01-23 00:23:36,503 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 850, lr: 0.000008, loss: 0.0651 (0.2670)
2023-01-23 00:23:56,944 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 900, lr: 0.000009, loss: 0.0653 (0.2558)
2023-01-23 00:24:16,499 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 950, lr: 0.000009, loss: 0.0649 (0.2458)
2023-01-23 00:24:35,382 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1000, lr: 0.000010, loss: 0.0607 (0.2366)
2023-01-23 00:24:54,754 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1050, lr: 0.000010, loss: 0.0583 (0.2283)
2023-01-23 00:25:13,924 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1100, lr: 0.000011, loss: 0.0628 (0.2207)
2023-01-23 00:25:32,746 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1150, lr: 0.000011, loss: 0.0603 (0.2137)
2023-01-23 00:25:51,413 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1200, lr: 0.000012, loss: 0.0592 (0.2072)
2023-01-23 00:26:10,069 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1250, lr: 0.000012, loss: 0.0562 (0.2012)
2023-01-23 00:26:28,723 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1300, lr: 0.000013, loss: 0.0541 (0.1957)
2023-01-23 00:26:47,486 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1350, lr: 0.000013, loss: 0.0546 (0.1906)
2023-01-23 00:27:06,826 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1400, lr: 0.000014, loss: 0.0582 (0.1858)
2023-01-23 00:27:25,840 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1450, lr: 0.000014, loss: 0.0553 (0.1813)
2023-01-23 00:27:44,598 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1500, lr: 0.000014, loss: 0.0547 (0.1772)
2023-01-23 00:28:03,381 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1550, lr: 0.000015, loss: 0.0546 (0.1732)
2023-01-23 00:28:22,169 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1600, lr: 0.000015, loss: 0.0574 (0.1696)
2023-01-23 00:28:40,996 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1650, lr: 0.000016, loss: 0.0538 (0.1661)
2023-01-23 00:28:59,754 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1700, lr: 0.000016, loss: 0.0530 (0.1628)
2023-01-23 00:29:18,428 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1750, lr: 0.000017, loss: 0.0529 (0.1597)
2023-01-23 00:29:37,124 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1800, lr: 0.000017, loss: 0.0529 (0.1567)
2023-01-23 00:29:55,916 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1850, lr: 0.000018, loss: 0.0535 (0.1540)
2023-01-23 00:30:14,785 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1900, lr: 0.000018, loss: 0.0528 (0.1513)
2023-01-23 00:30:33,689 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 1950, lr: 0.000019, loss: 0.0586 (0.1488)
2023-01-23 00:30:52,777 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2000, lr: 0.000019, loss: 0.0550 (0.1464)
2023-01-23 00:31:11,749 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2050, lr: 0.000020, loss: 0.0526 (0.1442)
2023-01-23 00:31:30,803 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2100, lr: 0.000020, loss: 0.0519 (0.1420)
2023-01-23 00:31:49,690 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2150, lr: 0.000021, loss: 0.0542 (0.1400)
2023-01-23 00:32:08,637 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2200, lr: 0.000021, loss: 0.0535 (0.1380)
2023-01-23 00:32:27,576 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2250, lr: 0.000022, loss: 0.0525 (0.1361)
2023-01-23 00:32:46,587 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2300, lr: 0.000022, loss: 0.0515 (0.1343)
2023-01-23 00:33:05,613 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2350, lr: 0.000023, loss: 0.0504 (0.1326)
2023-01-23 00:33:25,475 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2400, lr: 0.000023, loss: 0.0519 (0.1309)
2023-01-23 00:33:44,920 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2450, lr: 0.000024, loss: 0.0531 (0.1293)
2023-01-23 00:34:04,169 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2500, lr: 0.000024, loss: 0.0501 (0.1278)
2023-01-23 00:34:23,271 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2550, lr: 0.000025, loss: 0.0520 (0.1263)
2023-01-23 00:34:42,493 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2600, lr: 0.000025, loss: 0.0528 (0.1249)
2023-01-23 00:35:02,313 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2650, lr: 0.000026, loss: 0.0514 (0.1235)
2023-01-23 00:35:22,067 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2700, lr: 0.000026, loss: 0.0522 (0.1222)
2023-01-23 00:35:42,320 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2750, lr: 0.000027, loss: 0.0517 (0.1209)
2023-01-23 00:36:02,580 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2800, lr: 0.000027, loss: 0.0500 (0.1197)
2023-01-23 00:36:22,918 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2850, lr: 0.000028, loss: 0.0551 (0.1185)
2023-01-23 00:36:43,169 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2900, lr: 0.000028, loss: 0.0524 (0.1174)
2023-01-23 00:37:04,781 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 2950, lr: 0.000029, loss: 0.0512 (0.1163)
2023-01-23 00:37:23,877 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3000, lr: 0.000029, loss: 0.0506 (0.1152)
2023-01-23 00:37:42,722 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3050, lr: 0.000029, loss: 0.0519 (0.1141)
2023-01-23 00:38:01,760 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3100, lr: 0.000030, loss: 0.0491 (0.1131)
2023-01-23 00:38:20,998 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3150, lr: 0.000030, loss: 0.0543 (0.1122)
2023-01-23 00:38:40,647 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3200, lr: 0.000031, loss: 0.0525 (0.1112)
2023-01-23 00:38:59,565 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3250, lr: 0.000031, loss: 0.0497 (0.1103)
2023-01-23 00:39:18,428 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3300, lr: 0.000032, loss: 0.0520 (0.1094)
2023-01-23 00:39:37,354 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3350, lr: 0.000032, loss: 0.0516 (0.1085)
2023-01-23 00:39:56,240 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3400, lr: 0.000033, loss: 0.0518 (0.1076)
2023-01-23 00:40:15,055 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3450, lr: 0.000033, loss: 0.0491 (0.1068)
2023-01-23 00:40:34,076 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3500, lr: 0.000034, loss: 0.0498 (0.1060)
2023-01-23 00:40:53,147 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3550, lr: 0.000034, loss: 0.0508 (0.1053)
2023-01-23 00:41:12,030 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3600, lr: 0.000035, loss: 0.0506 (0.1045)
2023-01-23 00:41:31,005 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3650, lr: 0.000035, loss: 0.0476 (0.1038)
2023-01-23 00:41:49,851 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3700, lr: 0.000036, loss: 0.0505 (0.1030)
2023-01-23 00:42:08,751 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3750, lr: 0.000036, loss: 0.0505 (0.1023)
2023-01-23 00:42:27,817 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3800, lr: 0.000037, loss: 0.0509 (0.1016)
2023-01-23 00:42:46,815 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3850, lr: 0.000037, loss: 0.0532 (0.1010)
2023-01-23 00:43:05,798 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3900, lr: 0.000038, loss: 0.0517 (0.1003)
2023-01-23 00:43:24,677 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 3950, lr: 0.000038, loss: 0.0502 (0.0997)
2023-01-23 00:43:43,583 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4000, lr: 0.000039, loss: 0.0497 (0.0991)
2023-01-23 00:44:02,587 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4050, lr: 0.000039, loss: 0.0512 (0.0985)
2023-01-23 00:44:21,476 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4100, lr: 0.000040, loss: 0.0498 (0.0979)
2023-01-23 00:44:40,347 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4150, lr: 0.000040, loss: 0.0520 (0.0973)
2023-01-23 00:44:59,327 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4200, lr: 0.000041, loss: 0.0495 (0.0967)
2023-01-23 00:45:18,333 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4250, lr: 0.000041, loss: 0.0522 (0.0962)
2023-01-23 00:45:37,269 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4300, lr: 0.000042, loss: 0.0489 (0.0956)
2023-01-23 00:45:56,099 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4350, lr: 0.000042, loss: 0.0494 (0.0951)
2023-01-23 00:46:14,694 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4400, lr: 0.000043, loss: 0.0485 (0.0946)
2023-01-23 00:46:33,301 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4450, lr: 0.000043, loss: 0.0496 (0.0941)
2023-01-23 00:46:52,018 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4500, lr: 0.000043, loss: 0.0509 (0.0936)
2023-01-23 00:47:10,608 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4550, lr: 0.000044, loss: 0.0465 (0.0931)
2023-01-23 00:47:29,236 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4600, lr: 0.000044, loss: 0.0495 (0.0926)
2023-01-23 00:47:47,838 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4650, lr: 0.000045, loss: 0.0515 (0.0921)
2023-01-23 00:48:06,468 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4700, lr: 0.000045, loss: 0.0477 (0.0917)
2023-01-23 00:48:25,354 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4750, lr: 0.000046, loss: 0.0491 (0.0912)
2023-01-23 00:48:44,826 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4800, lr: 0.000046, loss: 0.0497 (0.0908)
2023-01-23 00:49:04,967 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4850, lr: 0.000047, loss: 0.0490 (0.0904)
2023-01-23 00:49:24,518 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4900, lr: 0.000047, loss: 0.0491 (0.0899)
2023-01-23 00:49:43,094 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 4950, lr: 0.000048, loss: 0.0476 (0.0895)
2023-01-23 00:50:01,681 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5000, lr: 0.000048, loss: 0.0494 (0.0891)
2023-01-23 00:50:20,469 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5050, lr: 0.000049, loss: 0.0535 (0.0887)
2023-01-23 00:50:39,216 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5100, lr: 0.000049, loss: 0.0526 (0.0883)
2023-01-23 00:50:57,940 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5150, lr: 0.000050, loss: 0.0471 (0.0880)
2023-01-23 00:51:16,740 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5200, lr: 0.000050, loss: 0.0495 (0.0876)
2023-01-23 00:51:35,417 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5250, lr: 0.000051, loss: 0.0495 (0.0872)
2023-01-23 00:51:54,164 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5300, lr: 0.000051, loss: 0.0459 (0.0868)
2023-01-23 00:52:12,879 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5350, lr: 0.000052, loss: 0.0458 (0.0865)
2023-01-23 00:52:31,597 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5400, lr: 0.000052, loss: 0.0491 (0.0861)
2023-01-23 00:52:50,175 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5450, lr: 0.000053, loss: 0.0493 (0.0858)
2023-01-23 00:53:08,970 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5500, lr: 0.000053, loss: 0.0486 (0.0854)
2023-01-23 00:53:27,710 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5550, lr: 0.000054, loss: 0.0496 (0.0851)
2023-01-23 00:53:46,444 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5600, lr: 0.000054, loss: 0.0465 (0.0848)
2023-01-23 00:54:05,478 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5650, lr: 0.000055, loss: 0.0470 (0.0844)
2023-01-23 00:54:24,148 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5700, lr: 0.000055, loss: 0.0489 (0.0841)
2023-01-23 00:54:42,841 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5750, lr: 0.000056, loss: 0.0502 (0.0838)
2023-01-23 00:55:01,526 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5800, lr: 0.000056, loss: 0.0514 (0.0835)
2023-01-23 00:55:20,262 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5850, lr: 0.000057, loss: 0.0459 (0.0832)
2023-01-23 00:55:38,906 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5900, lr: 0.000057, loss: 0.0472 (0.0829)
2023-01-23 00:55:57,694 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 5950, lr: 0.000057, loss: 0.0463 (0.0826)
2023-01-23 00:56:16,337 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6000, lr: 0.000058, loss: 0.0464 (0.0823)
2023-01-23 00:56:34,985 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6050, lr: 0.000058, loss: 0.0464 (0.0820)
2023-01-23 00:56:53,673 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6100, lr: 0.000059, loss: 0.0481 (0.0817)
2023-01-23 00:57:12,451 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6150, lr: 0.000059, loss: 0.0470 (0.0815)
2023-01-23 00:57:31,160 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6200, lr: 0.000060, loss: 0.0475 (0.0812)
2023-01-23 00:57:49,835 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6250, lr: 0.000060, loss: 0.0476 (0.0809)
2023-01-23 00:58:08,686 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6300, lr: 0.000061, loss: 0.0455 (0.0807)
2023-01-23 00:58:27,308 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6350, lr: 0.000061, loss: 0.0458 (0.0804)
2023-01-23 00:58:46,069 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6400, lr: 0.000062, loss: 0.0505 (0.0801)
2023-01-23 00:59:05,093 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6450, lr: 0.000062, loss: 0.0486 (0.0799)
2023-01-23 00:59:24,907 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6500, lr: 0.000063, loss: 0.0495 (0.0796)
2023-01-23 00:59:43,628 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6550, lr: 0.000063, loss: 0.0454 (0.0794)
2023-01-23 01:00:02,357 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6600, lr: 0.000064, loss: 0.0484 (0.0792)
2023-01-23 01:00:21,085 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6650, lr: 0.000064, loss: 0.0489 (0.0789)
2023-01-23 01:00:39,775 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6700, lr: 0.000065, loss: 0.0509 (0.0787)
2023-01-23 01:00:58,560 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6750, lr: 0.000065, loss: 0.0456 (0.0784)
2023-01-23 01:01:17,336 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6800, lr: 0.000066, loss: 0.0452 (0.0782)
2023-01-23 01:01:36,103 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6850, lr: 0.000066, loss: 0.0477 (0.0780)
2023-01-23 01:01:54,870 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6900, lr: 0.000067, loss: 0.0504 (0.0778)
2023-01-23 01:02:13,480 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 6950, lr: 0.000067, loss: 0.0448 (0.0775)
2023-01-23 01:02:32,209 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 7000, lr: 0.000068, loss: 0.0463 (0.0773)
2023-01-23 01:02:50,854 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 7050, lr: 0.000068, loss: 0.0469 (0.0771)
2023-01-23 01:03:09,632 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 7100, lr: 0.000069, loss: 0.0472 (0.0769)
2023-01-23 01:03:28,362 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 7150, lr: 0.000069, loss: 0.0466 (0.0767)
2023-01-23 01:03:47,046 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 7200, lr: 0.000070, loss: 0.0476 (0.0765)
2023-01-23 01:04:05,816 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 7250, lr: 0.000070, loss: 0.0438 (0.0763)
2023-01-23 01:04:24,529 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 7300, lr: 0.000071, loss: 0.0467 (0.0761)
2023-01-23 01:04:43,282 CLIP_COCO_TRAIN INFO: Epoch: 0, global_step: 7350, lr: 0.000071, loss: 0.0461 (0.0759)
2023-01-23 01:05:01,961 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7400, lr: 0.000071, loss: 0.0470 (0.0757)
2023-01-23 01:05:20,596 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7450, lr: 0.000072, loss: 0.0424 (0.0755)
2023-01-23 01:05:39,212 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7500, lr: 0.000072, loss: 0.0486 (0.0753)
2023-01-23 01:05:57,823 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7550, lr: 0.000073, loss: 0.0447 (0.0751)
2023-01-23 01:06:16,553 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7600, lr: 0.000073, loss: 0.0496 (0.0750)
2023-01-23 01:06:35,189 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7650, lr: 0.000074, loss: 0.0465 (0.0748)
2023-01-23 01:06:53,856 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7700, lr: 0.000074, loss: 0.0463 (0.0746)
2023-01-23 01:07:12,493 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7750, lr: 0.000075, loss: 0.0468 (0.0744)
2023-01-23 01:07:31,219 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7800, lr: 0.000075, loss: 0.0449 (0.0742)
2023-01-23 01:07:49,827 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7850, lr: 0.000076, loss: 0.0481 (0.0741)
2023-01-23 01:08:08,477 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7900, lr: 0.000076, loss: 0.0501 (0.0739)
2023-01-23 01:08:27,195 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 7950, lr: 0.000077, loss: 0.0459 (0.0737)
2023-01-23 01:08:45,825 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8000, lr: 0.000077, loss: 0.0475 (0.0735)
2023-01-23 01:09:04,445 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8050, lr: 0.000078, loss: 0.0486 (0.0734)
2023-01-23 01:09:23,299 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8100, lr: 0.000078, loss: 0.0468 (0.0732)
2023-01-23 01:09:41,764 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8150, lr: 0.000079, loss: 0.0460 (0.0731)
2023-01-23 01:10:00,219 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8200, lr: 0.000079, loss: 0.0465 (0.0729)
2023-01-23 01:10:18,573 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8250, lr: 0.000080, loss: 0.0491 (0.0727)
2023-01-23 01:10:37,026 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8300, lr: 0.000080, loss: 0.0490 (0.0726)
2023-01-23 01:10:55,341 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8350, lr: 0.000081, loss: 0.0448 (0.0724)
2023-01-23 01:11:13,650 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8400, lr: 0.000081, loss: 0.0458 (0.0723)
2023-01-23 01:11:32,017 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8450, lr: 0.000082, loss: 0.0511 (0.0721)
2023-01-23 01:11:50,243 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8500, lr: 0.000082, loss: 0.0453 (0.0720)
2023-01-23 01:12:08,572 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8550, lr: 0.000083, loss: 0.0471 (0.0718)
2023-01-23 01:12:26,915 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8600, lr: 0.000083, loss: 0.0494 (0.0717)
2023-01-23 01:12:45,250 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8650, lr: 0.000084, loss: 0.0475 (0.0715)
2023-01-23 01:13:03,538 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8700, lr: 0.000084, loss: 0.0452 (0.0714)
2023-01-23 01:13:21,889 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8750, lr: 0.000085, loss: 0.0472 (0.0713)
2023-01-23 01:13:40,151 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8800, lr: 0.000085, loss: 0.0465 (0.0711)
2023-01-23 01:14:01,638 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8850, lr: 0.000086, loss: 0.0437 (0.0710)
2023-01-23 01:14:20,893 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8900, lr: 0.000086, loss: 0.0439 (0.0708)
2023-01-23 01:14:39,651 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 8950, lr: 0.000086, loss: 0.0477 (0.0707)
2023-01-23 01:14:59,311 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9000, lr: 0.000087, loss: 0.0457 (0.0706)
2023-01-23 01:15:18,997 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9050, lr: 0.000087, loss: 0.0457 (0.0704)
2023-01-23 01:15:39,118 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9100, lr: 0.000088, loss: 0.0459 (0.0703)
2023-01-23 01:15:58,848 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9150, lr: 0.000088, loss: 0.0472 (0.0702)
2023-01-23 01:16:17,643 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9200, lr: 0.000089, loss: 0.0457 (0.0700)
2023-01-23 01:16:37,431 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9250, lr: 0.000089, loss: 0.0473 (0.0699)
2023-01-23 01:16:57,495 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9300, lr: 0.000090, loss: 0.0516 (0.0698)
2023-01-23 01:17:17,356 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9350, lr: 0.000090, loss: 0.0470 (0.0697)
2023-01-23 01:17:36,865 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9400, lr: 0.000091, loss: 0.0459 (0.0695)
2023-01-23 01:17:56,289 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9450, lr: 0.000091, loss: 0.0476 (0.0694)
2023-01-23 01:18:15,886 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9500, lr: 0.000092, loss: 0.0466 (0.0693)
2023-01-23 01:18:35,248 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9550, lr: 0.000092, loss: 0.0450 (0.0692)
2023-01-23 01:18:54,648 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9600, lr: 0.000093, loss: 0.0468 (0.0691)
2023-01-23 01:19:14,059 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9650, lr: 0.000093, loss: 0.0460 (0.0689)
2023-01-23 01:19:32,826 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9700, lr: 0.000094, loss: 0.0460 (0.0688)
2023-01-23 01:19:51,456 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9750, lr: 0.000094, loss: 0.0459 (0.0687)
2023-01-23 01:20:10,247 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9800, lr: 0.000095, loss: 0.0455 (0.0686)
2023-01-23 01:20:29,018 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9850, lr: 0.000095, loss: 0.0447 (0.0685)
2023-01-23 01:20:47,798 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9900, lr: 0.000096, loss: 0.0483 (0.0684)
2023-01-23 01:21:06,701 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 9950, lr: 0.000096, loss: 0.0491 (0.0683)
2023-01-23 01:21:25,503 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10000, lr: 0.000097, loss: 0.0460 (0.0682)
2023-01-23 01:21:26,905 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_1_10000.pt
2023-01-23 01:21:45,620 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10050, lr: 0.000097, loss: 0.0480 (0.0681)
2023-01-23 01:22:04,606 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10100, lr: 0.000098, loss: 0.0454 (0.0679)
2023-01-23 01:22:23,760 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10150, lr: 0.000098, loss: 0.0446 (0.0678)
2023-01-23 01:22:42,958 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10200, lr: 0.000099, loss: 0.0479 (0.0677)
2023-01-23 01:23:02,071 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10250, lr: 0.000099, loss: 0.0474 (0.0676)
2023-01-23 01:23:21,287 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10300, lr: 0.000100, loss: 0.0453 (0.0675)
2023-01-23 01:23:40,348 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10350, lr: 0.000100, loss: 0.0457 (0.0674)
2023-01-23 01:23:59,485 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10400, lr: 0.000100, loss: 0.0485 (0.0673)
2023-01-23 01:24:18,636 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10450, lr: 0.000101, loss: 0.0441 (0.0672)
2023-01-23 01:24:37,804 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10500, lr: 0.000101, loss: 0.0457 (0.0671)
2023-01-23 01:24:56,922 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10550, lr: 0.000102, loss: 0.0480 (0.0670)
2023-01-23 01:25:16,075 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10600, lr: 0.000102, loss: 0.0431 (0.0669)
2023-01-23 01:25:35,227 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10650, lr: 0.000103, loss: 0.0477 (0.0668)
2023-01-23 01:25:54,465 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10700, lr: 0.000103, loss: 0.0451 (0.0667)
2023-01-23 01:26:13,989 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10750, lr: 0.000104, loss: 0.0452 (0.0666)
2023-01-23 01:26:33,372 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10800, lr: 0.000104, loss: 0.0434 (0.0665)
2023-01-23 01:26:52,366 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10850, lr: 0.000105, loss: 0.0455 (0.0664)
2023-01-23 01:27:11,277 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10900, lr: 0.000105, loss: 0.0485 (0.0664)
2023-01-23 01:27:30,287 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 10950, lr: 0.000106, loss: 0.0461 (0.0663)
2023-01-23 01:27:49,154 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11000, lr: 0.000106, loss: 0.0466 (0.0662)
2023-01-23 01:28:07,971 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11050, lr: 0.000107, loss: 0.0470 (0.0661)
2023-01-23 01:28:26,899 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11100, lr: 0.000107, loss: 0.0493 (0.0660)
2023-01-23 01:28:45,810 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11150, lr: 0.000108, loss: 0.0638 (0.0660)
2023-01-23 01:29:04,776 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11200, lr: 0.000108, loss: 0.0558 (0.0660)
2023-01-23 01:29:23,737 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11250, lr: 0.000109, loss: 0.0582 (0.0659)
2023-01-23 01:29:42,619 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11300, lr: 0.000109, loss: 0.0518 (0.0658)
2023-01-23 01:30:01,597 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11350, lr: 0.000110, loss: 0.0521 (0.0658)
2023-01-23 01:30:20,605 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11400, lr: 0.000110, loss: 0.0564 (0.0657)
2023-01-23 01:30:39,553 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11450, lr: 0.000111, loss: 0.0519 (0.0657)
2023-01-23 01:30:58,549 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11500, lr: 0.000111, loss: 0.0530 (0.0656)
2023-01-23 01:31:17,528 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11550, lr: 0.000112, loss: 0.0533 (0.0656)
2023-01-23 01:31:36,681 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11600, lr: 0.000112, loss: 0.0532 (0.0655)
2023-01-23 01:31:55,660 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11650, lr: 0.000113, loss: 0.0615 (0.0655)
2023-01-23 01:32:14,730 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11700, lr: 0.000113, loss: 0.0551 (0.0654)
2023-01-23 01:32:33,674 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11750, lr: 0.000114, loss: 0.0510 (0.0654)
2023-01-23 01:32:52,633 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11800, lr: 0.000114, loss: 0.0532 (0.0653)
2023-01-23 01:33:11,521 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11850, lr: 0.000114, loss: 0.0562 (0.0653)
2023-01-23 01:33:30,478 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11900, lr: 0.000115, loss: 0.0532 (0.0652)
2023-01-23 01:33:49,580 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 11950, lr: 0.000115, loss: 0.0536 (0.0652)
2023-01-23 01:34:08,555 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12000, lr: 0.000116, loss: 0.0504 (0.0651)
2023-01-23 01:34:28,345 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12050, lr: 0.000116, loss: 0.0534 (0.0650)
2023-01-23 01:34:48,328 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12100, lr: 0.000117, loss: 0.0535 (0.0650)
2023-01-23 01:35:07,349 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12150, lr: 0.000117, loss: 0.0532 (0.0649)
2023-01-23 01:35:26,333 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12200, lr: 0.000118, loss: 0.0518 (0.0649)
2023-01-23 01:35:46,578 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12250, lr: 0.000118, loss: 0.0512 (0.0648)
2023-01-23 01:36:06,556 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12300, lr: 0.000119, loss: 0.0536 (0.0648)
2023-01-23 01:36:26,339 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12350, lr: 0.000119, loss: 0.0507 (0.0647)
2023-01-23 01:36:46,015 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12400, lr: 0.000120, loss: 0.0548 (0.0647)
2023-01-23 01:37:06,112 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12450, lr: 0.000120, loss: 0.0521 (0.0646)
2023-01-23 01:37:26,746 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12500, lr: 0.000121, loss: 0.0469 (0.0646)
2023-01-23 01:37:46,772 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12550, lr: 0.000121, loss: 0.0495 (0.0645)
2023-01-23 01:38:06,836 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12600, lr: 0.000122, loss: 0.0517 (0.0644)
2023-01-23 01:38:26,888 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12650, lr: 0.000122, loss: 0.0459 (0.0644)
2023-01-23 01:38:45,821 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12700, lr: 0.000123, loss: 0.0456 (0.0643)
2023-01-23 01:39:05,211 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12750, lr: 0.000123, loss: 0.0498 (0.0642)
2023-01-23 01:39:24,064 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12800, lr: 0.000124, loss: 0.0432 (0.0641)
2023-01-23 01:39:42,826 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12850, lr: 0.000124, loss: 0.0451 (0.0641)
2023-01-23 01:40:01,554 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12900, lr: 0.000125, loss: 0.0458 (0.0640)
2023-01-23 01:40:20,315 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 12950, lr: 0.000125, loss: 0.0514 (0.0639)
2023-01-23 01:40:39,013 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13000, lr: 0.000126, loss: 0.0472 (0.0639)
2023-01-23 01:40:57,808 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13050, lr: 0.000126, loss: 0.0471 (0.0638)
2023-01-23 01:41:16,534 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13100, lr: 0.000127, loss: 0.0451 (0.0637)
2023-01-23 01:41:35,289 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13150, lr: 0.000127, loss: 0.0435 (0.0637)
2023-01-23 01:41:54,043 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13200, lr: 0.000128, loss: 0.0460 (0.0636)
2023-01-23 01:42:12,678 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13250, lr: 0.000128, loss: 0.0458 (0.0635)
2023-01-23 01:42:31,392 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13300, lr: 0.000128, loss: 0.0449 (0.0635)
2023-01-23 01:42:50,215 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13350, lr: 0.000129, loss: 0.0482 (0.0634)
2023-01-23 01:43:08,922 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13400, lr: 0.000129, loss: 0.0461 (0.0633)
2023-01-23 01:43:27,751 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13450, lr: 0.000130, loss: 0.0458 (0.0633)
2023-01-23 01:43:46,560 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13500, lr: 0.000130, loss: 0.0459 (0.0632)
2023-01-23 01:44:05,417 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13550, lr: 0.000131, loss: 0.0490 (0.0632)
2023-01-23 01:44:24,173 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13600, lr: 0.000131, loss: 0.0453 (0.0631)
2023-01-23 01:44:43,063 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13650, lr: 0.000132, loss: 0.0466 (0.0630)
2023-01-23 01:45:01,894 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13700, lr: 0.000132, loss: 0.0459 (0.0630)
2023-01-23 01:45:20,708 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13750, lr: 0.000133, loss: 0.0451 (0.0629)
2023-01-23 01:45:39,593 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13800, lr: 0.000133, loss: 0.0444 (0.0628)
2023-01-23 01:45:58,283 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13850, lr: 0.000134, loss: 0.0492 (0.0628)
2023-01-23 01:46:17,028 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13900, lr: 0.000134, loss: 0.0481 (0.0627)
2023-01-23 01:46:35,954 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 13950, lr: 0.000135, loss: 0.0448 (0.0627)
2023-01-23 01:46:54,848 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14000, lr: 0.000135, loss: 0.0474 (0.0626)
2023-01-23 01:47:13,741 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14050, lr: 0.000136, loss: 0.0480 (0.0625)
2023-01-23 01:47:32,645 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14100, lr: 0.000136, loss: 0.0469 (0.0625)
2023-01-23 01:47:51,456 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14150, lr: 0.000137, loss: 0.0451 (0.0624)
2023-01-23 01:48:10,276 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14200, lr: 0.000137, loss: 0.0444 (0.0624)
2023-01-23 01:48:29,020 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14250, lr: 0.000138, loss: 0.0465 (0.0623)
2023-01-23 01:48:47,850 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14300, lr: 0.000138, loss: 0.0439 (0.0623)
2023-01-23 01:49:06,902 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14350, lr: 0.000139, loss: 0.0472 (0.0622)
2023-01-23 01:49:26,484 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14400, lr: 0.000139, loss: 0.0436 (0.0621)
2023-01-23 01:49:45,362 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14450, lr: 0.000140, loss: 0.0454 (0.0621)
2023-01-23 01:50:04,042 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14500, lr: 0.000140, loss: 0.0445 (0.0620)
2023-01-23 01:50:22,794 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14550, lr: 0.000141, loss: 0.0453 (0.0620)
2023-01-23 01:50:41,483 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14600, lr: 0.000141, loss: 0.0477 (0.0619)
2023-01-23 01:51:00,262 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14650, lr: 0.000142, loss: 0.0502 (0.0619)
2023-01-23 01:51:19,071 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14700, lr: 0.000142, loss: 0.0535 (0.0619)
2023-01-23 01:51:37,841 CLIP_COCO_TRAIN INFO: Epoch: 1, global_step: 14750, lr: 0.000143, loss: 0.0540 (0.0618)
2023-01-23 01:51:56,611 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 14800, lr: 0.000143, loss: 0.0489 (0.0618)
2023-01-23 01:52:15,369 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 14850, lr: 0.000143, loss: 0.0530 (0.0618)
2023-01-23 01:52:34,205 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 14900, lr: 0.000144, loss: 0.0520 (0.0617)
2023-01-23 01:52:52,794 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 14950, lr: 0.000144, loss: 0.0718 (0.0617)
2023-01-23 01:53:11,533 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15000, lr: 0.000145, loss: 0.0542 (0.0617)
2023-01-23 01:53:30,098 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15050, lr: 0.000145, loss: 0.0537 (0.0617)
2023-01-23 01:53:48,852 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15100, lr: 0.000146, loss: 0.0559 (0.0617)
2023-01-23 01:54:07,386 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15150, lr: 0.000146, loss: 0.0549 (0.0617)
2023-01-23 01:54:26,020 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15200, lr: 0.000147, loss: 0.0547 (0.0617)
2023-01-23 01:54:44,760 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15250, lr: 0.000147, loss: 0.0547 (0.0616)
2023-01-23 01:55:03,453 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15300, lr: 0.000148, loss: 0.0506 (0.0616)
2023-01-23 01:55:22,158 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15350, lr: 0.000148, loss: 0.0552 (0.0616)
2023-01-23 01:55:40,782 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15400, lr: 0.000149, loss: 0.0520 (0.0616)
2023-01-23 01:55:59,518 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15450, lr: 0.000149, loss: 0.0524 (0.0615)
2023-01-23 01:56:18,186 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15500, lr: 0.000150, loss: 0.0498 (0.0615)
2023-01-23 01:56:36,898 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15550, lr: 0.000150, loss: 0.0528 (0.0615)
2023-01-23 01:56:55,655 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15600, lr: 0.000151, loss: 0.0540 (0.0615)
2023-01-23 01:57:14,848 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15650, lr: 0.000151, loss: 0.0570 (0.0614)
2023-01-23 01:57:34,214 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15700, lr: 0.000152, loss: 0.0557 (0.0614)
2023-01-23 01:57:54,692 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15750, lr: 0.000152, loss: 0.0594 (0.0614)
2023-01-23 01:58:13,627 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15800, lr: 0.000153, loss: 0.0553 (0.0614)
2023-01-23 01:58:32,747 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15850, lr: 0.000153, loss: 0.0571 (0.0614)
2023-01-23 01:58:52,319 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15900, lr: 0.000154, loss: 0.0527 (0.0614)
2023-01-23 01:59:11,637 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 15950, lr: 0.000154, loss: 0.0546 (0.0613)
2023-01-23 01:59:30,309 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16000, lr: 0.000155, loss: 0.0552 (0.0613)
2023-01-23 01:59:49,321 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16050, lr: 0.000155, loss: 0.0522 (0.0613)
2023-01-23 02:00:09,024 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16100, lr: 0.000156, loss: 0.0551 (0.0613)
2023-01-23 02:00:28,985 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16150, lr: 0.000156, loss: 0.0498 (0.0612)
2023-01-23 02:00:48,104 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16200, lr: 0.000157, loss: 0.0560 (0.0612)
2023-01-23 02:01:06,771 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16250, lr: 0.000157, loss: 0.0550 (0.0612)
2023-01-23 02:01:25,765 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16300, lr: 0.000157, loss: 0.0530 (0.0612)
2023-01-23 02:01:44,421 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16350, lr: 0.000158, loss: 0.0510 (0.0611)
2023-01-23 02:02:03,217 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16400, lr: 0.000158, loss: 0.0522 (0.0611)
2023-01-23 02:02:23,645 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16450, lr: 0.000159, loss: 0.0489 (0.0611)
2023-01-23 02:02:43,026 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16500, lr: 0.000159, loss: 0.0508 (0.0610)
2023-01-23 02:03:02,052 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16550, lr: 0.000160, loss: 0.0502 (0.0610)
2023-01-23 02:03:21,312 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16600, lr: 0.000160, loss: 0.0495 (0.0610)
2023-01-23 02:03:40,644 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16650, lr: 0.000161, loss: 0.0519 (0.0610)
2023-01-23 02:03:59,855 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16700, lr: 0.000161, loss: 0.0497 (0.0609)
2023-01-23 02:04:19,351 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16750, lr: 0.000162, loss: 0.0487 (0.0609)
2023-01-23 02:04:39,564 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16800, lr: 0.000162, loss: 0.0521 (0.0609)
2023-01-23 02:04:58,858 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16850, lr: 0.000163, loss: 0.0527 (0.0608)
2023-01-23 02:05:18,751 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16900, lr: 0.000163, loss: 0.0534 (0.0608)
2023-01-23 02:05:38,665 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 16950, lr: 0.000164, loss: 0.0531 (0.0608)
2023-01-23 02:05:58,198 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17000, lr: 0.000164, loss: 0.0526 (0.0608)
2023-01-23 02:06:17,676 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17050, lr: 0.000165, loss: 0.0510 (0.0607)
2023-01-23 02:06:37,343 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17100, lr: 0.000165, loss: 0.0473 (0.0607)
2023-01-23 02:06:57,749 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17150, lr: 0.000166, loss: 0.0508 (0.0607)
2023-01-23 02:07:17,763 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17200, lr: 0.000166, loss: 0.0540 (0.0607)
2023-01-23 02:07:37,462 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17250, lr: 0.000167, loss: 0.0499 (0.0606)
2023-01-23 02:07:57,254 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17300, lr: 0.000167, loss: 0.0553 (0.0606)
2023-01-23 02:08:16,175 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17350, lr: 0.000168, loss: 0.0524 (0.0606)
2023-01-23 02:08:35,854 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17400, lr: 0.000168, loss: 0.0510 (0.0606)
2023-01-23 02:08:55,356 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17450, lr: 0.000169, loss: 0.0486 (0.0605)
2023-01-23 02:09:14,266 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17500, lr: 0.000169, loss: 0.0505 (0.0605)
2023-01-23 02:09:33,057 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17550, lr: 0.000170, loss: 0.0504 (0.0605)
2023-01-23 02:09:51,829 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17600, lr: 0.000170, loss: 0.0503 (0.0604)
2023-01-23 02:10:10,559 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17650, lr: 0.000171, loss: 0.0518 (0.0604)
2023-01-23 02:10:29,239 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17700, lr: 0.000171, loss: 0.0518 (0.0604)
2023-01-23 02:10:48,116 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17750, lr: 0.000171, loss: 0.0539 (0.0604)
2023-01-23 02:11:07,084 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17800, lr: 0.000172, loss: 0.0511 (0.0604)
2023-01-23 02:11:26,671 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17850, lr: 0.000172, loss: 0.0530 (0.0603)
2023-01-23 02:11:45,945 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17900, lr: 0.000173, loss: 0.0517 (0.0603)
2023-01-23 02:12:05,194 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 17950, lr: 0.000173, loss: 0.0493 (0.0603)
2023-01-23 02:12:24,036 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18000, lr: 0.000174, loss: 0.0509 (0.0603)
2023-01-23 02:12:43,141 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18050, lr: 0.000174, loss: 0.0500 (0.0602)
2023-01-23 02:13:02,090 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18100, lr: 0.000175, loss: 0.0524 (0.0602)
2023-01-23 02:13:22,273 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18150, lr: 0.000175, loss: 0.0509 (0.0602)
2023-01-23 02:13:42,081 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18200, lr: 0.000176, loss: 0.0497 (0.0602)
2023-01-23 02:14:01,607 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18250, lr: 0.000176, loss: 0.0507 (0.0601)
2023-01-23 02:14:22,285 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18300, lr: 0.000177, loss: 0.0517 (0.0601)
2023-01-23 02:14:45,777 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18350, lr: 0.000177, loss: 0.0521 (0.0601)
2023-01-23 02:15:08,784 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18400, lr: 0.000178, loss: 0.0552 (0.0601)
2023-01-23 02:15:35,587 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18450, lr: 0.000178, loss: 0.0489 (0.0601)
2023-01-23 02:15:56,503 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18500, lr: 0.000179, loss: 0.0505 (0.0600)
2023-01-23 02:16:16,981 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18550, lr: 0.000179, loss: 0.0544 (0.0600)
2023-01-23 02:16:37,139 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18600, lr: 0.000180, loss: 0.0518 (0.0600)
2023-01-23 02:16:56,850 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18650, lr: 0.000180, loss: 0.0486 (0.0600)
2023-01-23 02:17:17,407 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18700, lr: 0.000181, loss: 0.0495 (0.0599)
2023-01-23 02:17:38,627 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18750, lr: 0.000181, loss: 0.0539 (0.0599)
2023-01-23 02:17:59,990 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18800, lr: 0.000182, loss: 0.0537 (0.0599)
2023-01-23 02:18:20,644 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18850, lr: 0.000182, loss: 0.0523 (0.0599)
2023-01-23 02:18:42,046 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18900, lr: 0.000183, loss: 0.0516 (0.0598)
2023-01-23 02:19:03,891 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 18950, lr: 0.000183, loss: 0.0522 (0.0598)
2023-01-23 02:19:25,202 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19000, lr: 0.000184, loss: 0.0525 (0.0598)
2023-01-23 02:19:46,361 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19050, lr: 0.000184, loss: 0.0528 (0.0598)
2023-01-23 02:20:08,753 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19100, lr: 0.000185, loss: 0.0512 (0.0598)
2023-01-23 02:20:30,963 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19150, lr: 0.000185, loss: 0.0499 (0.0597)
2023-01-23 02:20:52,665 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19200, lr: 0.000186, loss: 0.0525 (0.0597)
2023-01-23 02:21:13,630 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19250, lr: 0.000186, loss: 0.0537 (0.0597)
2023-01-23 02:21:36,087 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19300, lr: 0.000186, loss: 0.0529 (0.0597)
2023-01-23 02:21:57,481 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19350, lr: 0.000187, loss: 0.0544 (0.0596)
2023-01-23 02:22:18,413 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19400, lr: 0.000187, loss: 0.0513 (0.0596)
2023-01-23 02:22:39,502 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19450, lr: 0.000188, loss: 0.0513 (0.0596)
2023-01-23 02:23:00,780 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19500, lr: 0.000188, loss: 0.0522 (0.0596)
2023-01-23 02:23:21,716 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19550, lr: 0.000189, loss: 0.0522 (0.0596)
2023-01-23 02:23:42,926 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19600, lr: 0.000189, loss: 0.0498 (0.0595)
2023-01-23 02:24:04,647 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19650, lr: 0.000190, loss: 0.0488 (0.0595)
2023-01-23 02:24:26,612 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19700, lr: 0.000190, loss: 0.0501 (0.0595)
2023-01-23 02:24:48,061 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19750, lr: 0.000191, loss: 0.0510 (0.0595)
2023-01-23 02:25:09,504 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19800, lr: 0.000191, loss: 0.0554 (0.0595)
2023-01-23 02:25:30,551 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19850, lr: 0.000192, loss: 0.0534 (0.0594)
2023-01-23 02:25:52,341 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19900, lr: 0.000192, loss: 0.0514 (0.0594)
2023-01-23 02:26:13,606 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 19950, lr: 0.000193, loss: 0.0526 (0.0594)
2023-01-23 02:26:34,687 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20000, lr: 0.000193, loss: 0.0505 (0.0594)
2023-01-23 02:26:36,122 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_2_20000.pt
2023-01-23 02:26:56,586 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20050, lr: 0.000194, loss: 0.0512 (0.0594)
2023-01-23 02:27:18,692 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20100, lr: 0.000194, loss: 0.0508 (0.0593)
2023-01-23 02:27:39,648 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20150, lr: 0.000195, loss: 0.0551 (0.0593)
2023-01-23 02:28:00,912 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20200, lr: 0.000195, loss: 0.0498 (0.0593)
2023-01-23 02:28:22,942 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20250, lr: 0.000196, loss: 0.0513 (0.0593)
2023-01-23 02:28:44,543 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20300, lr: 0.000196, loss: 0.0509 (0.0593)
2023-01-23 02:29:06,115 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20350, lr: 0.000197, loss: 0.0493 (0.0592)
2023-01-23 02:29:27,293 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20400, lr: 0.000197, loss: 0.0506 (0.0592)
2023-01-23 02:29:48,357 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20450, lr: 0.000198, loss: 0.0516 (0.0592)
2023-01-23 02:30:10,139 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20500, lr: 0.000198, loss: 0.0508 (0.0592)
2023-01-23 02:30:31,658 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20550, lr: 0.000199, loss: 0.0523 (0.0592)
2023-01-23 02:30:53,392 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20600, lr: 0.000199, loss: 0.0527 (0.0592)
2023-01-23 02:31:14,825 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20650, lr: 0.000200, loss: 0.0525 (0.0591)
2023-01-23 02:31:35,532 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20700, lr: 0.000200, loss: 0.0517 (0.0591)
2023-01-23 02:31:55,965 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20750, lr: 0.000200, loss: 0.0518 (0.0591)
2023-01-23 02:32:16,576 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20800, lr: 0.000201, loss: 0.0543 (0.0591)
2023-01-23 02:32:37,860 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20850, lr: 0.000201, loss: 0.0506 (0.0591)
2023-01-23 02:33:01,161 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20900, lr: 0.000202, loss: 0.0552 (0.0590)
2023-01-23 02:33:21,756 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 20950, lr: 0.000202, loss: 0.0514 (0.0590)
2023-01-23 02:33:43,551 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21000, lr: 0.000203, loss: 0.0495 (0.0590)
2023-01-23 02:34:06,800 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21050, lr: 0.000203, loss: 0.0536 (0.0590)
2023-01-23 02:34:29,651 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21100, lr: 0.000204, loss: 0.0514 (0.0590)
2023-01-23 02:34:53,904 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21150, lr: 0.000204, loss: 0.0507 (0.0589)
2023-01-23 02:35:18,943 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21200, lr: 0.000205, loss: 0.0504 (0.0589)
2023-01-23 02:35:42,174 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21250, lr: 0.000205, loss: 0.0528 (0.0589)
2023-01-23 02:36:05,449 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21300, lr: 0.000206, loss: 0.0500 (0.0589)
2023-01-23 02:36:27,248 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21350, lr: 0.000206, loss: 0.0525 (0.0589)
2023-01-23 02:36:49,340 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21400, lr: 0.000207, loss: 0.0520 (0.0589)
2023-01-23 02:37:11,531 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21450, lr: 0.000207, loss: 0.0520 (0.0588)
2023-01-23 02:37:33,225 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21500, lr: 0.000208, loss: 0.0495 (0.0588)
2023-01-23 02:37:54,950 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21550, lr: 0.000208, loss: 0.0512 (0.0588)
2023-01-23 02:38:16,711 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21600, lr: 0.000209, loss: 0.0559 (0.0588)
2023-01-23 02:38:39,372 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21650, lr: 0.000209, loss: 0.0539 (0.0588)
2023-01-23 02:39:01,447 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21700, lr: 0.000210, loss: 0.0543 (0.0588)
2023-01-23 02:39:23,100 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21750, lr: 0.000210, loss: 0.0532 (0.0587)
2023-01-23 02:39:43,727 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21800, lr: 0.000211, loss: 0.0535 (0.0587)
2023-01-23 02:40:04,418 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21850, lr: 0.000211, loss: 0.0516 (0.0587)
2023-01-23 02:40:24,701 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21900, lr: 0.000212, loss: 0.0499 (0.0587)
2023-01-23 02:40:45,042 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 21950, lr: 0.000212, loss: 0.0502 (0.0587)
2023-01-23 02:41:06,474 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 22000, lr: 0.000213, loss: 0.0528 (0.0587)
2023-01-23 02:41:29,726 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 22050, lr: 0.000213, loss: 0.0517 (0.0586)
2023-01-23 02:41:52,849 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 22100, lr: 0.000214, loss: 0.0487 (0.0586)
2023-01-23 02:42:15,756 CLIP_COCO_TRAIN INFO: Epoch: 2, global_step: 22150, lr: 0.000214, loss: 0.0531 (0.0586)
2023-01-23 02:42:37,349 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22200, lr: 0.000214, loss: 0.0601 (0.0586)
2023-01-23 02:42:58,231 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22250, lr: 0.000215, loss: 0.0515 (0.0586)
2023-01-23 02:43:18,723 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22300, lr: 0.000215, loss: 0.0523 (0.0586)
2023-01-23 02:43:39,888 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22350, lr: 0.000216, loss: 0.0527 (0.0586)
2023-01-23 02:44:02,100 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22400, lr: 0.000216, loss: 0.0510 (0.0586)
2023-01-23 02:44:24,092 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22450, lr: 0.000217, loss: 0.0500 (0.0586)
2023-01-23 02:44:47,068 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22500, lr: 0.000217, loss: 0.0543 (0.0585)
2023-01-23 02:45:09,082 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22550, lr: 0.000218, loss: 0.0498 (0.0585)
2023-01-23 02:45:30,970 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22600, lr: 0.000218, loss: 0.0516 (0.0585)
2023-01-23 02:45:52,767 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22650, lr: 0.000219, loss: 0.0520 (0.0585)
2023-01-23 02:46:15,026 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22700, lr: 0.000219, loss: 0.0543 (0.0585)
2023-01-23 02:46:37,404 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22750, lr: 0.000220, loss: 0.0521 (0.0585)
2023-01-23 02:46:58,825 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22800, lr: 0.000220, loss: 0.0561 (0.0584)
2023-01-23 02:47:21,639 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22850, lr: 0.000221, loss: 0.0510 (0.0584)
2023-01-23 02:47:43,812 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22900, lr: 0.000221, loss: 0.0491 (0.0584)
2023-01-23 02:48:06,683 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 22950, lr: 0.000222, loss: 0.0519 (0.0584)
2023-01-23 02:48:27,830 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23000, lr: 0.000222, loss: 0.0478 (0.0584)
2023-01-23 02:48:48,803 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23050, lr: 0.000223, loss: 0.0489 (0.0584)
2023-01-23 02:49:11,409 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23100, lr: 0.000223, loss: 0.0498 (0.0584)
2023-01-23 02:49:31,921 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23150, lr: 0.000224, loss: 0.0533 (0.0583)
2023-01-23 02:49:52,413 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23200, lr: 0.000224, loss: 0.0519 (0.0583)
2023-01-23 02:50:12,620 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23250, lr: 0.000225, loss: 0.0504 (0.0583)
2023-01-23 02:50:33,128 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23300, lr: 0.000225, loss: 0.0528 (0.0583)
2023-01-23 02:50:53,424 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23350, lr: 0.000226, loss: 0.0510 (0.0583)
2023-01-23 02:51:13,895 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23400, lr: 0.000226, loss: 0.0541 (0.0583)
2023-01-23 02:51:34,006 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23450, lr: 0.000227, loss: 0.0580 (0.0582)
2023-01-23 02:51:54,241 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23500, lr: 0.000227, loss: 0.0523 (0.0582)
2023-01-23 02:52:14,686 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23550, lr: 0.000228, loss: 0.0553 (0.0582)
2023-01-23 02:52:36,285 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23600, lr: 0.000228, loss: 0.0499 (0.0582)
2023-01-23 02:52:58,255 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23650, lr: 0.000228, loss: 0.0523 (0.0582)
2023-01-23 02:53:19,257 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23700, lr: 0.000229, loss: 0.0509 (0.0582)
2023-01-23 02:53:40,583 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23750, lr: 0.000229, loss: 0.0514 (0.0582)
2023-01-23 02:54:01,610 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23800, lr: 0.000230, loss: 0.0543 (0.0581)
2023-01-23 02:54:22,968 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23850, lr: 0.000230, loss: 0.0499 (0.0581)
2023-01-23 02:54:45,210 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23900, lr: 0.000231, loss: 0.0506 (0.0581)
2023-01-23 02:55:06,999 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 23950, lr: 0.000231, loss: 0.0520 (0.0581)
2023-01-23 02:55:28,304 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24000, lr: 0.000232, loss: 0.0569 (0.0581)
2023-01-23 02:55:50,025 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24050, lr: 0.000232, loss: 0.0533 (0.0581)
2023-01-23 02:56:11,094 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24100, lr: 0.000233, loss: 0.0527 (0.0581)
2023-01-23 02:56:32,767 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24150, lr: 0.000233, loss: 0.0523 (0.0580)
2023-01-23 02:56:53,806 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24200, lr: 0.000234, loss: 0.0490 (0.0580)
2023-01-23 02:57:15,467 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24250, lr: 0.000234, loss: 0.0538 (0.0580)
2023-01-23 02:57:36,373 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24300, lr: 0.000235, loss: 0.0529 (0.0580)
2023-01-23 02:57:58,069 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24350, lr: 0.000235, loss: 0.0499 (0.0580)
2023-01-23 02:58:19,382 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24400, lr: 0.000236, loss: 0.0490 (0.0580)
2023-01-23 02:58:40,904 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24450, lr: 0.000236, loss: 0.0499 (0.0580)
2023-01-23 02:59:02,501 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24500, lr: 0.000237, loss: 0.0599 (0.0579)
2023-01-23 02:59:23,147 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24550, lr: 0.000237, loss: 0.0544 (0.0579)
2023-01-23 02:59:45,306 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24600, lr: 0.000238, loss: 0.0536 (0.0579)
2023-01-23 03:00:06,979 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24650, lr: 0.000238, loss: 0.0501 (0.0579)
2023-01-23 03:00:27,835 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24700, lr: 0.000239, loss: 0.0515 (0.0579)
2023-01-23 03:00:48,504 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24750, lr: 0.000239, loss: 0.0507 (0.0579)
2023-01-23 03:01:09,556 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24800, lr: 0.000240, loss: 0.0520 (0.0579)
2023-01-23 03:01:30,561 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24850, lr: 0.000240, loss: 0.0519 (0.0579)
2023-01-23 03:01:51,676 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24900, lr: 0.000241, loss: 0.0534 (0.0579)
2023-01-23 03:02:12,749 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 24950, lr: 0.000241, loss: 0.0505 (0.0578)
2023-01-23 03:02:33,963 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25000, lr: 0.000242, loss: 0.0532 (0.0578)
2023-01-23 03:02:55,227 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25050, lr: 0.000242, loss: 0.0499 (0.0578)
2023-01-23 03:03:15,915 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25100, lr: 0.000243, loss: 0.0528 (0.0578)
2023-01-23 03:03:37,310 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25150, lr: 0.000243, loss: 0.0551 (0.0578)
2023-01-23 03:03:58,949 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25200, lr: 0.000243, loss: 0.0536 (0.0578)
2023-01-23 03:04:21,147 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25250, lr: 0.000244, loss: 0.0509 (0.0578)
2023-01-23 03:04:42,275 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25300, lr: 0.000244, loss: 0.0515 (0.0578)
2023-01-23 03:05:03,180 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25350, lr: 0.000245, loss: 0.0516 (0.0577)
2023-01-23 03:05:23,875 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25400, lr: 0.000245, loss: 0.0526 (0.0577)
2023-01-23 03:05:44,298 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25450, lr: 0.000246, loss: 0.0522 (0.0577)
2023-01-23 03:06:04,986 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25500, lr: 0.000246, loss: 0.0504 (0.0577)
2023-01-23 03:06:25,449 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25550, lr: 0.000247, loss: 0.0535 (0.0577)
2023-01-23 03:06:45,880 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25600, lr: 0.000247, loss: 0.0512 (0.0577)
2023-01-23 03:07:06,420 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25650, lr: 0.000248, loss: 0.0524 (0.0577)
2023-01-23 03:07:26,909 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25700, lr: 0.000248, loss: 0.0508 (0.0576)
2023-01-23 03:07:47,366 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25750, lr: 0.000249, loss: 0.0507 (0.0576)
2023-01-23 03:08:07,873 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25800, lr: 0.000249, loss: 0.0501 (0.0576)
2023-01-23 03:08:28,353 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25850, lr: 0.000250, loss: 0.0507 (0.0576)
2023-01-23 03:08:49,701 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25900, lr: 0.000250, loss: 0.0502 (0.0576)
2023-01-23 03:09:10,910 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 25950, lr: 0.000251, loss: 0.0496 (0.0576)
2023-01-23 03:09:31,576 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26000, lr: 0.000251, loss: 0.0525 (0.0576)
2023-01-23 03:09:52,210 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26050, lr: 0.000252, loss: 0.0482 (0.0575)
2023-01-23 03:10:13,129 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26100, lr: 0.000252, loss: 0.0478 (0.0575)
2023-01-23 03:10:35,543 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26150, lr: 0.000253, loss: 0.0516 (0.0575)
2023-01-23 03:10:56,448 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26200, lr: 0.000253, loss: 0.0511 (0.0575)
2023-01-23 03:11:17,049 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26250, lr: 0.000254, loss: 0.0505 (0.0575)
2023-01-23 03:11:38,366 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26300, lr: 0.000254, loss: 0.0502 (0.0575)
2023-01-23 03:11:59,568 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26350, lr: 0.000255, loss: 0.0505 (0.0575)
2023-01-23 03:12:21,316 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26400, lr: 0.000255, loss: 0.0520 (0.0575)
2023-01-23 03:12:42,168 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26450, lr: 0.000256, loss: 0.0515 (0.0574)
2023-01-23 03:13:02,582 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26500, lr: 0.000256, loss: 0.0510 (0.0574)
2023-01-23 03:13:24,040 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26550, lr: 0.000257, loss: 0.0541 (0.0574)
2023-01-23 03:13:44,734 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26600, lr: 0.000257, loss: 0.0543 (0.0574)
2023-01-23 03:14:05,271 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26650, lr: 0.000257, loss: 0.0494 (0.0574)
2023-01-23 03:14:25,912 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26700, lr: 0.000258, loss: 0.0497 (0.0574)
2023-01-23 03:14:47,144 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26750, lr: 0.000258, loss: 0.0508 (0.0574)
2023-01-23 03:15:07,709 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26800, lr: 0.000259, loss: 0.0490 (0.0574)
2023-01-23 03:15:29,065 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26850, lr: 0.000259, loss: 0.0509 (0.0573)
2023-01-23 03:15:50,579 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26900, lr: 0.000260, loss: 0.0488 (0.0573)
2023-01-23 03:16:12,780 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 26950, lr: 0.000260, loss: 0.0518 (0.0573)
2023-01-23 03:16:33,364 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27000, lr: 0.000261, loss: 0.0549 (0.0573)
2023-01-23 03:16:54,023 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27050, lr: 0.000261, loss: 0.0526 (0.0573)
2023-01-23 03:17:14,713 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27100, lr: 0.000262, loss: 0.0507 (0.0573)
2023-01-23 03:17:35,383 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27150, lr: 0.000262, loss: 0.0483 (0.0573)
2023-01-23 03:17:55,985 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27200, lr: 0.000263, loss: 0.0476 (0.0573)
2023-01-23 03:18:15,472 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27250, lr: 0.000263, loss: 0.0487 (0.0573)
2023-01-23 03:18:35,095 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27300, lr: 0.000264, loss: 0.0491 (0.0572)
2023-01-23 03:18:54,611 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27350, lr: 0.000264, loss: 0.0516 (0.0572)
2023-01-23 03:19:14,245 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27400, lr: 0.000265, loss: 0.0485 (0.0572)
2023-01-23 03:19:33,684 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27450, lr: 0.000265, loss: 0.0508 (0.0572)
2023-01-23 03:19:53,217 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27500, lr: 0.000266, loss: 0.0518 (0.0572)
2023-01-23 03:20:12,608 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27550, lr: 0.000266, loss: 0.0500 (0.0572)
2023-01-23 03:20:32,871 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27600, lr: 0.000267, loss: 0.0499 (0.0572)
2023-01-23 03:20:52,455 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27650, lr: 0.000267, loss: 0.0509 (0.0572)
2023-01-23 03:21:11,950 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27700, lr: 0.000268, loss: 0.0491 (0.0571)
2023-01-23 03:21:31,435 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27750, lr: 0.000268, loss: 0.0507 (0.0571)
2023-01-23 03:21:51,064 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27800, lr: 0.000269, loss: 0.0494 (0.0571)
2023-01-23 03:22:10,574 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27850, lr: 0.000269, loss: 0.0475 (0.0571)
2023-01-23 03:22:30,053 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27900, lr: 0.000270, loss: 0.0478 (0.0571)
2023-01-23 03:22:49,587 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 27950, lr: 0.000270, loss: 0.0508 (0.0571)
2023-01-23 03:23:10,777 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28000, lr: 0.000271, loss: 0.0500 (0.0571)
2023-01-23 03:23:31,524 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28050, lr: 0.000271, loss: 0.0504 (0.0571)
2023-01-23 03:23:50,907 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28100, lr: 0.000271, loss: 0.0545 (0.0571)
2023-01-23 03:24:11,178 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28150, lr: 0.000272, loss: 0.0520 (0.0570)
2023-01-23 03:24:31,823 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28200, lr: 0.000272, loss: 0.0508 (0.0570)
2023-01-23 03:24:52,516 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28250, lr: 0.000273, loss: 0.0500 (0.0570)
2023-01-23 03:25:13,339 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28300, lr: 0.000273, loss: 0.0480 (0.0570)
2023-01-23 03:25:34,037 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28350, lr: 0.000274, loss: 0.0491 (0.0570)
2023-01-23 03:25:54,883 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28400, lr: 0.000274, loss: 0.0495 (0.0570)
2023-01-23 03:26:15,600 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28450, lr: 0.000275, loss: 0.0508 (0.0570)
2023-01-23 03:26:36,281 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28500, lr: 0.000275, loss: 0.0491 (0.0570)
2023-01-23 03:26:57,182 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28550, lr: 0.000276, loss: 0.0480 (0.0569)
2023-01-23 03:27:18,064 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28600, lr: 0.000276, loss: 0.0511 (0.0569)
2023-01-23 03:27:38,723 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28650, lr: 0.000277, loss: 0.0456 (0.0569)
2023-01-23 03:27:59,541 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28700, lr: 0.000277, loss: 0.0493 (0.0569)
2023-01-23 03:28:20,341 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28750, lr: 0.000278, loss: 0.0456 (0.0569)
2023-01-23 03:28:41,206 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28800, lr: 0.000278, loss: 0.0487 (0.0569)
2023-01-23 03:29:02,032 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28850, lr: 0.000279, loss: 0.0500 (0.0569)
2023-01-23 03:29:22,720 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28900, lr: 0.000279, loss: 0.0485 (0.0569)
2023-01-23 03:29:43,760 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 28950, lr: 0.000280, loss: 0.0521 (0.0569)
2023-01-23 03:30:04,523 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29000, lr: 0.000280, loss: 0.0485 (0.0568)
2023-01-23 03:30:25,220 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29050, lr: 0.000281, loss: 0.0499 (0.0568)
2023-01-23 03:30:46,108 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29100, lr: 0.000281, loss: 0.0510 (0.0568)
2023-01-23 03:31:07,330 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29150, lr: 0.000282, loss: 0.0519 (0.0568)
2023-01-23 03:31:29,211 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29200, lr: 0.000282, loss: 0.0502 (0.0568)
2023-01-23 03:31:50,805 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29250, lr: 0.000283, loss: 0.0495 (0.0568)
2023-01-23 03:32:11,938 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29300, lr: 0.000283, loss: 0.0506 (0.0568)
2023-01-23 03:32:33,013 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29350, lr: 0.000284, loss: 0.0499 (0.0568)
2023-01-23 03:32:53,972 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29400, lr: 0.000284, loss: 0.0497 (0.0568)
2023-01-23 03:33:15,159 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29450, lr: 0.000285, loss: 0.0513 (0.0567)
2023-01-23 03:33:36,163 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29500, lr: 0.000285, loss: 0.0513 (0.0567)
2023-01-23 03:33:57,211 CLIP_COCO_TRAIN INFO: Epoch: 3, global_step: 29550, lr: 0.000286, loss: 0.0495 (0.0567)
2023-01-23 03:34:18,128 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 29600, lr: 0.000286, loss: 0.0512 (0.0567)
2023-01-23 03:34:38,958 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 29650, lr: 0.000286, loss: 0.0466 (0.0567)
2023-01-23 03:34:59,757 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 29700, lr: 0.000287, loss: 0.0495 (0.0567)
2023-01-23 03:35:20,550 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 29750, lr: 0.000287, loss: 0.0464 (0.0567)
2023-01-23 03:35:41,343 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 29800, lr: 0.000288, loss: 0.0515 (0.0567)
2023-01-23 03:36:02,170 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 29850, lr: 0.000288, loss: 0.0547 (0.0567)
2023-01-23 03:36:22,837 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 29900, lr: 0.000289, loss: 0.0453 (0.0566)
2023-01-23 03:36:43,581 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 29950, lr: 0.000289, loss: 0.0476 (0.0566)
2023-01-23 03:37:04,286 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30000, lr: 0.000290, loss: 0.0504 (0.0566)
2023-01-23 03:37:05,715 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_4_30000.pt
2023-01-23 03:37:26,139 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30050, lr: 0.000290, loss: 0.0472 (0.0566)
2023-01-23 03:37:46,777 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30100, lr: 0.000291, loss: 0.0495 (0.0566)
2023-01-23 03:38:07,401 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30150, lr: 0.000291, loss: 0.0521 (0.0566)
2023-01-23 03:38:28,200 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30200, lr: 0.000292, loss: 0.0474 (0.0566)
2023-01-23 03:38:48,867 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30250, lr: 0.000292, loss: 0.0514 (0.0566)
2023-01-23 03:39:09,746 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30300, lr: 0.000293, loss: 0.0460 (0.0566)
2023-01-23 03:39:30,637 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30350, lr: 0.000293, loss: 0.0486 (0.0566)
2023-01-23 03:39:51,323 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30400, lr: 0.000294, loss: 0.0500 (0.0565)
2023-01-23 03:40:11,981 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30450, lr: 0.000294, loss: 0.0479 (0.0565)
2023-01-23 03:40:32,663 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30500, lr: 0.000295, loss: 0.0484 (0.0565)
2023-01-23 03:40:53,346 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30550, lr: 0.000295, loss: 0.0507 (0.0565)
2023-01-23 03:41:13,921 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30600, lr: 0.000296, loss: 0.0546 (0.0565)
2023-01-23 03:41:32,788 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30650, lr: 0.000296, loss: 0.0490 (0.0565)
2023-01-23 03:41:51,409 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30700, lr: 0.000297, loss: 0.0482 (0.0565)
2023-01-23 03:42:10,158 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30750, lr: 0.000297, loss: 0.0526 (0.0565)
2023-01-23 03:42:30,805 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30800, lr: 0.000298, loss: 0.0513 (0.0565)
2023-01-23 03:42:52,890 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30850, lr: 0.000298, loss: 0.0505 (0.0564)
2023-01-23 03:43:13,186 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30900, lr: 0.000299, loss: 0.0461 (0.0564)
2023-01-23 03:43:33,316 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 30950, lr: 0.000299, loss: 0.0497 (0.0564)
2023-01-23 03:43:53,704 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31000, lr: 0.000300, loss: 0.0511 (0.0564)
2023-01-23 03:44:14,031 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31050, lr: 0.000300, loss: 0.0480 (0.0564)
2023-01-23 03:44:34,479 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31100, lr: 0.000300, loss: 0.0490 (0.0564)
2023-01-23 03:44:55,421 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31150, lr: 0.000301, loss: 0.0479 (0.0564)
2023-01-23 03:45:16,054 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31200, lr: 0.000301, loss: 0.0484 (0.0564)
2023-01-23 03:45:37,003 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31250, lr: 0.000302, loss: 0.0488 (0.0564)
2023-01-23 03:45:57,879 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31300, lr: 0.000302, loss: 0.0470 (0.0563)
2023-01-23 03:46:20,490 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31350, lr: 0.000303, loss: 0.0505 (0.0563)
2023-01-23 03:46:43,856 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31400, lr: 0.000303, loss: 0.0490 (0.0563)
2023-01-23 03:47:05,111 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31450, lr: 0.000304, loss: 0.0501 (0.0563)
2023-01-23 03:47:25,532 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31500, lr: 0.000304, loss: 0.0470 (0.0563)
2023-01-23 03:47:46,856 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31550, lr: 0.000305, loss: 0.0512 (0.0563)
2023-01-23 03:48:07,528 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31600, lr: 0.000305, loss: 0.0466 (0.0563)
2023-01-23 03:48:28,025 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31650, lr: 0.000306, loss: 0.0519 (0.0563)
2023-01-23 03:48:48,482 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31700, lr: 0.000306, loss: 0.0481 (0.0563)
2023-01-23 03:49:08,963 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31750, lr: 0.000307, loss: 0.0477 (0.0562)
2023-01-23 03:49:29,426 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31800, lr: 0.000307, loss: 0.0490 (0.0562)
2023-01-23 03:49:49,931 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31850, lr: 0.000308, loss: 0.0504 (0.0562)
2023-01-23 03:50:10,637 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31900, lr: 0.000308, loss: 0.0488 (0.0562)
2023-01-23 03:50:30,163 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 31950, lr: 0.000309, loss: 0.0522 (0.0562)
2023-01-23 03:50:49,539 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32000, lr: 0.000309, loss: 0.0484 (0.0562)
2023-01-23 03:51:08,859 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32050, lr: 0.000310, loss: 0.0489 (0.0562)
2023-01-23 03:51:28,184 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32100, lr: 0.000310, loss: 0.0479 (0.0562)
2023-01-23 03:51:47,508 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32150, lr: 0.000311, loss: 0.0492 (0.0562)
2023-01-23 03:52:06,928 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32200, lr: 0.000311, loss: 0.0507 (0.0562)
2023-01-23 03:52:26,317 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32250, lr: 0.000312, loss: 0.0498 (0.0561)
2023-01-23 03:52:45,595 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32300, lr: 0.000312, loss: 0.0492 (0.0561)
2023-01-23 03:53:04,917 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32350, lr: 0.000313, loss: 0.0538 (0.0561)
2023-01-23 03:53:24,282 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32400, lr: 0.000313, loss: 0.0478 (0.0561)
2023-01-23 03:53:43,669 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32450, lr: 0.000314, loss: 0.0488 (0.0561)
2023-01-23 03:54:03,005 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32500, lr: 0.000314, loss: 0.0486 (0.0561)
2023-01-23 03:54:22,463 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32550, lr: 0.000314, loss: 0.0472 (0.0561)
2023-01-23 03:54:41,837 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32600, lr: 0.000315, loss: 0.0491 (0.0561)
2023-01-23 03:55:01,179 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32650, lr: 0.000315, loss: 0.0498 (0.0561)
2023-01-23 03:55:20,579 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32700, lr: 0.000316, loss: 0.0468 (0.0561)
2023-01-23 03:55:39,959 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32750, lr: 0.000316, loss: 0.0490 (0.0560)
2023-01-23 03:55:59,314 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32800, lr: 0.000317, loss: 0.0476 (0.0560)
2023-01-23 03:56:18,558 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32850, lr: 0.000317, loss: 0.0491 (0.0560)
2023-01-23 03:56:38,007 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32900, lr: 0.000318, loss: 0.0489 (0.0560)
2023-01-23 03:56:57,465 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 32950, lr: 0.000318, loss: 0.0518 (0.0560)
2023-01-23 03:57:16,787 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33000, lr: 0.000319, loss: 0.0575 (0.0560)
2023-01-23 03:57:35,959 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33050, lr: 0.000319, loss: 0.0519 (0.0560)
2023-01-23 03:57:55,330 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33100, lr: 0.000320, loss: 0.0516 (0.0560)
2023-01-23 03:58:14,686 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33150, lr: 0.000320, loss: 0.0487 (0.0560)
2023-01-23 03:58:34,125 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33200, lr: 0.000321, loss: 0.0513 (0.0560)
2023-01-23 03:58:53,382 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33250, lr: 0.000321, loss: 0.0494 (0.0559)
2023-01-23 03:59:12,767 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33300, lr: 0.000322, loss: 0.0481 (0.0559)
2023-01-23 03:59:32,086 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33350, lr: 0.000322, loss: 0.0482 (0.0559)
2023-01-23 03:59:51,480 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33400, lr: 0.000323, loss: 0.0482 (0.0559)
2023-01-23 04:00:10,996 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33450, lr: 0.000323, loss: 0.0475 (0.0559)
2023-01-23 04:00:29,616 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33500, lr: 0.000324, loss: 0.0524 (0.0559)
2023-01-23 04:00:48,066 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33550, lr: 0.000324, loss: 0.0456 (0.0559)
2023-01-23 04:01:06,538 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33600, lr: 0.000325, loss: 0.0469 (0.0559)
2023-01-23 04:01:24,906 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33650, lr: 0.000325, loss: 0.0478 (0.0559)
2023-01-23 04:01:43,302 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33700, lr: 0.000326, loss: 0.0499 (0.0559)
2023-01-23 04:02:01,747 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33750, lr: 0.000326, loss: 0.0486 (0.0558)
2023-01-23 04:02:20,224 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33800, lr: 0.000327, loss: 0.0484 (0.0558)
2023-01-23 04:02:38,457 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33850, lr: 0.000327, loss: 0.0480 (0.0558)
2023-01-23 04:02:56,800 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33900, lr: 0.000328, loss: 0.0509 (0.0558)
2023-01-23 04:03:15,156 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 33950, lr: 0.000328, loss: 0.0489 (0.0558)
2023-01-23 04:03:33,558 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34000, lr: 0.000328, loss: 0.0502 (0.0558)
2023-01-23 04:03:51,885 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34050, lr: 0.000329, loss: 0.0477 (0.0558)
2023-01-23 04:04:10,255 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34100, lr: 0.000329, loss: 0.0506 (0.0558)
2023-01-23 04:04:32,655 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34150, lr: 0.000330, loss: 0.0482 (0.0558)
2023-01-23 04:04:53,080 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34200, lr: 0.000330, loss: 0.0472 (0.0558)
2023-01-23 04:05:13,498 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34250, lr: 0.000331, loss: 0.0494 (0.0557)
2023-01-23 04:05:33,779 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34300, lr: 0.000331, loss: 0.0527 (0.0557)
2023-01-23 04:05:54,276 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34350, lr: 0.000332, loss: 0.0505 (0.0557)
2023-01-23 04:06:14,975 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34400, lr: 0.000332, loss: 0.0488 (0.0557)
2023-01-23 04:06:36,070 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34450, lr: 0.000333, loss: 0.0529 (0.0557)
2023-01-23 04:06:57,225 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34500, lr: 0.000333, loss: 0.0460 (0.0557)
2023-01-23 04:07:18,963 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34550, lr: 0.000334, loss: 0.0516 (0.0557)
2023-01-23 04:07:40,481 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34600, lr: 0.000334, loss: 0.0526 (0.0557)
2023-01-23 04:08:01,231 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34650, lr: 0.000335, loss: 0.0482 (0.0557)
2023-01-23 04:08:21,800 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34700, lr: 0.000335, loss: 0.0500 (0.0557)
2023-01-23 04:08:42,283 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34750, lr: 0.000336, loss: 0.0502 (0.0557)
2023-01-23 04:09:02,746 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34800, lr: 0.000336, loss: 0.0482 (0.0557)
2023-01-23 04:09:23,190 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34850, lr: 0.000337, loss: 0.0512 (0.0556)
2023-01-23 04:09:43,705 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34900, lr: 0.000337, loss: 0.0473 (0.0556)
2023-01-23 04:10:04,119 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 34950, lr: 0.000338, loss: 0.0483 (0.0556)
2023-01-23 04:10:24,624 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35000, lr: 0.000338, loss: 0.0521 (0.0556)
2023-01-23 04:10:45,174 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35050, lr: 0.000339, loss: 0.0511 (0.0556)
2023-01-23 04:11:05,670 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35100, lr: 0.000339, loss: 0.0519 (0.0556)
2023-01-23 04:11:26,315 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35150, lr: 0.000340, loss: 0.0467 (0.0556)
2023-01-23 04:11:46,787 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35200, lr: 0.000340, loss: 0.0514 (0.0556)
2023-01-23 04:12:07,450 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35250, lr: 0.000341, loss: 0.0481 (0.0556)
2023-01-23 04:12:27,959 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35300, lr: 0.000341, loss: 0.0487 (0.0556)
2023-01-23 04:12:48,422 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35350, lr: 0.000342, loss: 0.0469 (0.0556)
2023-01-23 04:13:09,530 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35400, lr: 0.000342, loss: 0.0504 (0.0555)
2023-01-23 04:13:29,779 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35450, lr: 0.000343, loss: 0.0485 (0.0555)
2023-01-23 04:13:49,368 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35500, lr: 0.000343, loss: 0.0497 (0.0555)
2023-01-23 04:14:08,887 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35550, lr: 0.000343, loss: 0.0471 (0.0555)
2023-01-23 04:14:28,396 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35600, lr: 0.000344, loss: 0.0510 (0.0555)
2023-01-23 04:14:47,842 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35650, lr: 0.000344, loss: 0.0477 (0.0555)
2023-01-23 04:15:07,383 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35700, lr: 0.000345, loss: 0.0482 (0.0555)
2023-01-23 04:15:26,794 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35750, lr: 0.000345, loss: 0.0541 (0.0555)
2023-01-23 04:15:46,249 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35800, lr: 0.000346, loss: 0.0503 (0.0555)
2023-01-23 04:16:05,580 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35850, lr: 0.000346, loss: 0.0483 (0.0555)
2023-01-23 04:16:24,911 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35900, lr: 0.000347, loss: 0.0485 (0.0555)
2023-01-23 04:16:44,422 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 35950, lr: 0.000347, loss: 0.0494 (0.0554)
2023-01-23 04:17:03,846 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36000, lr: 0.000348, loss: 0.0486 (0.0554)
2023-01-23 04:17:23,223 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36050, lr: 0.000348, loss: 0.0500 (0.0554)
2023-01-23 04:17:42,705 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36100, lr: 0.000349, loss: 0.0503 (0.0554)
2023-01-23 04:18:02,095 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36150, lr: 0.000349, loss: 0.0503 (0.0554)
2023-01-23 04:18:21,540 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36200, lr: 0.000350, loss: 0.0473 (0.0554)
2023-01-23 04:18:41,200 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36250, lr: 0.000350, loss: 0.0488 (0.0554)
2023-01-23 04:19:00,676 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36300, lr: 0.000351, loss: 0.0512 (0.0554)
2023-01-23 04:19:20,121 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36350, lr: 0.000351, loss: 0.0479 (0.0554)
2023-01-23 04:19:39,506 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36400, lr: 0.000352, loss: 0.0492 (0.0554)
2023-01-23 04:19:58,842 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36450, lr: 0.000352, loss: 0.0506 (0.0554)
2023-01-23 04:20:18,289 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36500, lr: 0.000353, loss: 0.0501 (0.0553)
2023-01-23 04:20:37,570 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36550, lr: 0.000353, loss: 0.0483 (0.0553)
2023-01-23 04:20:56,996 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36600, lr: 0.000354, loss: 0.0470 (0.0553)
2023-01-23 04:21:16,492 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36650, lr: 0.000354, loss: 0.0498 (0.0553)
2023-01-23 04:21:35,913 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36700, lr: 0.000355, loss: 0.0469 (0.0553)
2023-01-23 04:21:55,407 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36750, lr: 0.000355, loss: 0.0525 (0.0553)
2023-01-23 04:22:14,853 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36800, lr: 0.000356, loss: 0.0491 (0.0553)
2023-01-23 04:22:34,257 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36850, lr: 0.000356, loss: 0.0474 (0.0553)
2023-01-23 04:22:53,731 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36900, lr: 0.000357, loss: 0.0479 (0.0553)
2023-01-23 04:23:13,943 CLIP_COCO_TRAIN INFO: Epoch: 4, global_step: 36950, lr: 0.000357, loss: 0.0472 (0.0553)
2023-01-23 04:23:33,120 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37000, lr: 0.000357, loss: 0.0484 (0.0553)
2023-01-23 04:23:52,411 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37050, lr: 0.000358, loss: 0.0453 (0.0552)
2023-01-23 04:24:11,604 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37100, lr: 0.000358, loss: 0.0486 (0.0552)
2023-01-23 04:24:30,765 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37150, lr: 0.000359, loss: 0.0488 (0.0552)
2023-01-23 04:24:49,916 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37200, lr: 0.000359, loss: 0.0510 (0.0552)
2023-01-23 04:25:09,108 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37250, lr: 0.000360, loss: 0.0486 (0.0552)
2023-01-23 04:25:28,292 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37300, lr: 0.000360, loss: 0.0501 (0.0552)
2023-01-23 04:25:47,395 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37350, lr: 0.000361, loss: 0.0476 (0.0552)
2023-01-23 04:26:06,575 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37400, lr: 0.000361, loss: 0.0493 (0.0552)
2023-01-23 04:26:25,891 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37450, lr: 0.000362, loss: 0.0520 (0.0552)
2023-01-23 04:26:45,157 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37500, lr: 0.000362, loss: 0.0498 (0.0552)
2023-01-23 04:27:04,466 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37550, lr: 0.000363, loss: 0.0473 (0.0552)
2023-01-23 04:27:23,799 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37600, lr: 0.000363, loss: 0.0459 (0.0552)
2023-01-23 04:27:42,912 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37650, lr: 0.000364, loss: 0.0463 (0.0551)
2023-01-23 04:28:02,162 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37700, lr: 0.000364, loss: 0.0514 (0.0551)
2023-01-23 04:28:21,385 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37750, lr: 0.000365, loss: 0.0486 (0.0551)
2023-01-23 04:28:40,695 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37800, lr: 0.000365, loss: 0.0513 (0.0551)
2023-01-23 04:28:59,910 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37850, lr: 0.000366, loss: 0.0459 (0.0551)
2023-01-23 04:29:19,100 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37900, lr: 0.000366, loss: 0.0463 (0.0551)
2023-01-23 04:29:38,355 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 37950, lr: 0.000367, loss: 0.0499 (0.0551)
2023-01-23 04:29:57,468 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38000, lr: 0.000367, loss: 0.0469 (0.0551)
2023-01-23 04:30:16,730 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38050, lr: 0.000368, loss: 0.0481 (0.0551)
2023-01-23 04:30:35,945 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38100, lr: 0.000368, loss: 0.0497 (0.0551)
2023-01-23 04:30:55,384 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38150, lr: 0.000369, loss: 0.0496 (0.0551)
2023-01-23 04:31:14,556 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38200, lr: 0.000369, loss: 0.0497 (0.0550)
2023-01-23 04:31:33,909 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38250, lr: 0.000370, loss: 0.0488 (0.0550)
2023-01-23 04:31:53,008 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38300, lr: 0.000370, loss: 0.0515 (0.0550)
2023-01-23 04:32:12,274 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38350, lr: 0.000371, loss: 0.0492 (0.0550)
2023-01-23 04:32:31,501 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38400, lr: 0.000371, loss: 0.0491 (0.0550)
2023-01-23 04:32:50,728 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38450, lr: 0.000371, loss: 0.0464 (0.0550)
2023-01-23 04:33:10,761 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38500, lr: 0.000372, loss: 0.0462 (0.0550)
2023-01-23 04:33:29,928 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38550, lr: 0.000372, loss: 0.0517 (0.0550)
2023-01-23 04:33:49,108 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38600, lr: 0.000373, loss: 0.0511 (0.0550)
2023-01-23 04:34:08,338 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38650, lr: 0.000373, loss: 0.0481 (0.0550)
2023-01-23 04:34:27,550 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38700, lr: 0.000374, loss: 0.0531 (0.0550)
2023-01-23 04:34:46,780 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38750, lr: 0.000374, loss: 0.0485 (0.0550)
2023-01-23 04:35:05,953 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38800, lr: 0.000375, loss: 0.0473 (0.0549)
2023-01-23 04:35:25,147 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38850, lr: 0.000375, loss: 0.0437 (0.0549)
2023-01-23 04:35:44,380 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38900, lr: 0.000376, loss: 0.0463 (0.0549)
2023-01-23 04:36:03,628 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 38950, lr: 0.000376, loss: 0.0475 (0.0549)
2023-01-23 04:36:22,753 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39000, lr: 0.000377, loss: 0.0497 (0.0549)
2023-01-23 04:36:42,413 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39050, lr: 0.000377, loss: 0.0497 (0.0549)
2023-01-23 04:37:02,880 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39100, lr: 0.000378, loss: 0.0469 (0.0549)
2023-01-23 04:37:23,388 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39150, lr: 0.000378, loss: 0.0504 (0.0549)
2023-01-23 04:37:43,934 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39200, lr: 0.000379, loss: 0.0490 (0.0549)
2023-01-23 04:38:04,594 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39250, lr: 0.000379, loss: 0.0514 (0.0549)
2023-01-23 04:38:25,935 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39300, lr: 0.000380, loss: 0.0466 (0.0549)
2023-01-23 04:38:46,752 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39350, lr: 0.000380, loss: 0.0456 (0.0549)
2023-01-23 04:39:07,488 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39400, lr: 0.000381, loss: 0.0472 (0.0548)
2023-01-23 04:39:28,087 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39450, lr: 0.000381, loss: 0.0465 (0.0548)
2023-01-23 04:39:49,318 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39500, lr: 0.000382, loss: 0.0456 (0.0548)
2023-01-23 04:40:11,134 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39550, lr: 0.000382, loss: 0.0472 (0.0548)
2023-01-23 04:40:32,233 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39600, lr: 0.000383, loss: 0.0474 (0.0548)
2023-01-23 04:40:53,824 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39650, lr: 0.000383, loss: 0.0499 (0.0548)
2023-01-23 04:41:15,020 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39700, lr: 0.000384, loss: 0.0494 (0.0548)
2023-01-23 04:41:35,889 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39750, lr: 0.000384, loss: 0.0507 (0.0548)
2023-01-23 04:41:56,716 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39800, lr: 0.000385, loss: 0.0464 (0.0548)
2023-01-23 04:42:18,276 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39850, lr: 0.000385, loss: 0.0465 (0.0548)
2023-01-23 04:42:39,187 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39900, lr: 0.000385, loss: 0.0470 (0.0548)
2023-01-23 04:42:59,645 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 39950, lr: 0.000386, loss: 0.0494 (0.0548)
2023-01-23 04:43:20,147 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40000, lr: 0.000386, loss: 0.0483 (0.0548)
2023-01-23 04:43:21,570 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_5_40000.pt
2023-01-23 04:43:42,074 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40050, lr: 0.000387, loss: 0.0495 (0.0547)
2023-01-23 04:44:02,514 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40100, lr: 0.000387, loss: 0.0478 (0.0547)
2023-01-23 04:44:23,463 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40150, lr: 0.000388, loss: 0.0467 (0.0547)
2023-01-23 04:44:45,048 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40200, lr: 0.000388, loss: 0.0502 (0.0547)
2023-01-23 04:45:06,842 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40250, lr: 0.000389, loss: 0.0501 (0.0547)
2023-01-23 04:45:27,646 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40300, lr: 0.000389, loss: 0.0465 (0.0547)
2023-01-23 04:45:49,266 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40350, lr: 0.000390, loss: 0.0524 (0.0547)
2023-01-23 04:46:10,433 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40400, lr: 0.000390, loss: 0.0462 (0.0547)
2023-01-23 04:46:31,761 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40450, lr: 0.000391, loss: 0.0491 (0.0547)
2023-01-23 04:46:52,314 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40500, lr: 0.000391, loss: 0.0497 (0.0547)
2023-01-23 04:47:13,691 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40550, lr: 0.000392, loss: 0.0486 (0.0547)
2023-01-23 04:47:34,925 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40600, lr: 0.000392, loss: 0.0486 (0.0547)
2023-01-23 04:47:56,616 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40650, lr: 0.000393, loss: 0.0497 (0.0547)
2023-01-23 04:48:18,236 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40700, lr: 0.000393, loss: 0.0479 (0.0546)
2023-01-23 04:48:39,881 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40750, lr: 0.000394, loss: 0.0482 (0.0546)
2023-01-23 04:49:00,325 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40800, lr: 0.000394, loss: 0.0481 (0.0546)
2023-01-23 04:49:20,782 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40850, lr: 0.000395, loss: 0.0482 (0.0546)
2023-01-23 04:49:41,074 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40900, lr: 0.000395, loss: 0.0487 (0.0546)
2023-01-23 04:50:01,526 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 40950, lr: 0.000396, loss: 0.0482 (0.0546)
2023-01-23 04:50:22,000 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41000, lr: 0.000396, loss: 0.0484 (0.0546)
2023-01-23 04:50:42,481 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41050, lr: 0.000397, loss: 0.0548 (0.0546)
2023-01-23 04:51:04,402 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41100, lr: 0.000397, loss: 0.0474 (0.0546)
2023-01-23 04:51:25,547 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41150, lr: 0.000398, loss: 0.0472 (0.0546)
2023-01-23 04:51:46,604 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41200, lr: 0.000398, loss: 0.0476 (0.0546)
2023-01-23 04:52:07,931 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41250, lr: 0.000399, loss: 0.0497 (0.0546)
2023-01-23 04:52:28,949 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41300, lr: 0.000399, loss: 0.0473 (0.0545)
2023-01-23 04:52:50,622 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41350, lr: 0.000400, loss: 0.0485 (0.0545)
2023-01-23 04:53:11,995 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41400, lr: 0.000400, loss: 0.0477 (0.0545)
2023-01-23 04:53:32,639 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41450, lr: 0.000400, loss: 0.0465 (0.0545)
2023-01-23 04:53:53,172 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41500, lr: 0.000401, loss: 0.0479 (0.0545)
2023-01-23 04:54:13,619 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41550, lr: 0.000401, loss: 0.0464 (0.0545)
2023-01-23 04:54:34,121 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41600, lr: 0.000402, loss: 0.0462 (0.0545)
2023-01-23 04:54:54,605 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41650, lr: 0.000402, loss: 0.0507 (0.0545)
2023-01-23 04:55:15,094 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41700, lr: 0.000403, loss: 0.0484 (0.0545)
2023-01-23 04:55:35,553 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41750, lr: 0.000403, loss: 0.0477 (0.0545)
2023-01-23 04:55:56,046 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41800, lr: 0.000404, loss: 0.0487 (0.0545)
2023-01-23 04:56:16,554 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41850, lr: 0.000404, loss: 0.0503 (0.0545)
2023-01-23 04:56:37,006 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41900, lr: 0.000405, loss: 0.0519 (0.0545)
2023-01-23 04:56:57,485 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 41950, lr: 0.000405, loss: 0.0477 (0.0544)
2023-01-23 04:57:17,946 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42000, lr: 0.000406, loss: 0.0479 (0.0544)
2023-01-23 04:57:38,667 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42050, lr: 0.000406, loss: 0.0475 (0.0544)
2023-01-23 04:57:59,799 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42100, lr: 0.000407, loss: 0.0479 (0.0544)
2023-01-23 04:58:20,642 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42150, lr: 0.000407, loss: 0.0482 (0.0544)
2023-01-23 04:58:41,128 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42200, lr: 0.000408, loss: 0.0512 (0.0544)
2023-01-23 04:59:01,592 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42250, lr: 0.000408, loss: 0.0472 (0.0544)
2023-01-23 04:59:22,037 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42300, lr: 0.000409, loss: 0.0431 (0.0544)
2023-01-23 04:59:42,519 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42350, lr: 0.000409, loss: 0.0459 (0.0544)
2023-01-23 05:00:03,057 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42400, lr: 0.000410, loss: 0.0496 (0.0544)
2023-01-23 05:00:23,711 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42450, lr: 0.000410, loss: 0.0489 (0.0544)
2023-01-23 05:00:44,218 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42500, lr: 0.000411, loss: 0.0458 (0.0544)
2023-01-23 05:01:04,664 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42550, lr: 0.000411, loss: 0.0485 (0.0544)
2023-01-23 05:01:25,177 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42600, lr: 0.000412, loss: 0.0492 (0.0543)
2023-01-23 05:01:45,651 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42650, lr: 0.000412, loss: 0.0459 (0.0543)
2023-01-23 05:02:06,828 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42700, lr: 0.000413, loss: 0.0472 (0.0543)
2023-01-23 05:02:27,215 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42750, lr: 0.000413, loss: 0.0490 (0.0543)
2023-01-23 05:02:47,640 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42800, lr: 0.000414, loss: 0.0508 (0.0543)
2023-01-23 05:03:08,140 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42850, lr: 0.000414, loss: 0.0480 (0.0543)
2023-01-23 05:03:28,646 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42900, lr: 0.000414, loss: 0.0472 (0.0543)
2023-01-23 05:03:49,954 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 42950, lr: 0.000415, loss: 0.0490 (0.0543)
2023-01-23 05:04:11,088 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43000, lr: 0.000415, loss: 0.0476 (0.0543)
2023-01-23 05:04:32,596 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43050, lr: 0.000416, loss: 0.0494 (0.0543)
2023-01-23 05:04:54,488 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43100, lr: 0.000416, loss: 0.0479 (0.0543)
2023-01-23 05:05:15,937 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43150, lr: 0.000417, loss: 0.0480 (0.0543)
2023-01-23 05:05:37,357 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43200, lr: 0.000417, loss: 0.0482 (0.0543)
2023-01-23 05:05:58,244 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43250, lr: 0.000418, loss: 0.0500 (0.0543)
2023-01-23 05:06:19,448 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43300, lr: 0.000418, loss: 0.0474 (0.0542)
2023-01-23 05:06:40,804 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43350, lr: 0.000419, loss: 0.0457 (0.0542)
2023-01-23 05:07:02,119 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43400, lr: 0.000419, loss: 0.0488 (0.0542)
2023-01-23 05:07:22,700 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43450, lr: 0.000420, loss: 0.0485 (0.0542)
2023-01-23 05:07:43,963 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43500, lr: 0.000420, loss: 0.0479 (0.0542)
2023-01-23 05:08:03,758 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43550, lr: 0.000421, loss: 0.0467 (0.0542)
2023-01-23 05:08:22,878 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43600, lr: 0.000421, loss: 0.0474 (0.0542)
2023-01-23 05:08:41,935 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43650, lr: 0.000422, loss: 0.0479 (0.0542)
2023-01-23 05:09:01,033 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43700, lr: 0.000422, loss: 0.0489 (0.0542)
2023-01-23 05:09:20,223 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43750, lr: 0.000423, loss: 0.0481 (0.0542)
2023-01-23 05:09:39,263 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43800, lr: 0.000423, loss: 0.0481 (0.0542)
2023-01-23 05:09:58,260 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43850, lr: 0.000424, loss: 0.0486 (0.0542)
2023-01-23 05:10:17,274 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43900, lr: 0.000424, loss: 0.0485 (0.0542)
2023-01-23 05:10:36,257 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 43950, lr: 0.000425, loss: 0.0448 (0.0541)
2023-01-23 05:10:55,348 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 44000, lr: 0.000425, loss: 0.0483 (0.0541)
2023-01-23 05:11:14,351 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 44050, lr: 0.000426, loss: 0.0491 (0.0541)
2023-01-23 05:11:33,390 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 44100, lr: 0.000426, loss: 0.0493 (0.0541)
2023-01-23 05:11:52,454 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 44150, lr: 0.000427, loss: 0.0466 (0.0541)
2023-01-23 05:12:11,763 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 44200, lr: 0.000427, loss: 0.0466 (0.0541)
2023-01-23 05:12:30,802 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 44250, lr: 0.000428, loss: 0.0477 (0.0541)
2023-01-23 05:12:49,776 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 44300, lr: 0.000428, loss: 0.0470 (0.0541)
2023-01-23 05:13:08,838 CLIP_COCO_TRAIN INFO: Epoch: 5, global_step: 44350, lr: 0.000428, loss: 0.0450 (0.0541)
2023-01-23 05:13:27,740 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44400, lr: 0.000429, loss: 0.0477 (0.0541)
2023-01-23 05:13:46,662 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44450, lr: 0.000429, loss: 0.0481 (0.0541)
2023-01-23 05:14:05,588 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44500, lr: 0.000430, loss: 0.0466 (0.0541)
2023-01-23 05:14:24,535 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44550, lr: 0.000430, loss: 0.0441 (0.0541)
2023-01-23 05:14:43,347 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44600, lr: 0.000431, loss: 0.0486 (0.0541)
2023-01-23 05:15:02,136 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44650, lr: 0.000431, loss: 0.0455 (0.0540)
2023-01-23 05:15:21,042 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44700, lr: 0.000432, loss: 0.0442 (0.0540)
2023-01-23 05:15:39,969 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44750, lr: 0.000432, loss: 0.0503 (0.0540)
2023-01-23 05:15:58,815 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44800, lr: 0.000433, loss: 0.0489 (0.0540)
2023-01-23 05:16:17,758 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44850, lr: 0.000433, loss: 0.0488 (0.0540)
2023-01-23 05:16:36,662 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44900, lr: 0.000434, loss: 0.0448 (0.0540)
2023-01-23 05:16:55,487 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 44950, lr: 0.000434, loss: 0.0521 (0.0540)
2023-01-23 05:17:14,549 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45000, lr: 0.000435, loss: 0.0467 (0.0540)
2023-01-23 05:17:33,384 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45050, lr: 0.000435, loss: 0.0450 (0.0540)
2023-01-23 05:17:51,805 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45100, lr: 0.000436, loss: 0.0475 (0.0540)
2023-01-23 05:18:10,316 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45150, lr: 0.000436, loss: 0.0458 (0.0540)
2023-01-23 05:18:28,874 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45200, lr: 0.000437, loss: 0.0492 (0.0540)
2023-01-23 05:18:47,363 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45250, lr: 0.000437, loss: 0.0454 (0.0540)
2023-01-23 05:19:05,866 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45300, lr: 0.000438, loss: 0.0512 (0.0540)
2023-01-23 05:19:24,335 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45350, lr: 0.000438, loss: 0.0451 (0.0539)
2023-01-23 05:19:42,784 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45400, lr: 0.000439, loss: 0.0450 (0.0539)
2023-01-23 05:20:01,152 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45450, lr: 0.000439, loss: 0.0459 (0.0539)
2023-01-23 05:20:19,515 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45500, lr: 0.000440, loss: 0.0446 (0.0539)
2023-01-23 05:20:38,102 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45550, lr: 0.000440, loss: 0.0501 (0.0539)
2023-01-23 05:20:56,546 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45600, lr: 0.000441, loss: 0.0478 (0.0539)
2023-01-23 05:21:14,910 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45650, lr: 0.000441, loss: 0.0502 (0.0539)
2023-01-23 05:21:33,405 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45700, lr: 0.000442, loss: 0.0492 (0.0539)
2023-01-23 05:21:51,796 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45750, lr: 0.000442, loss: 0.0477 (0.0539)
2023-01-23 05:22:10,260 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45800, lr: 0.000443, loss: 0.0496 (0.0539)
2023-01-23 05:22:28,694 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45850, lr: 0.000443, loss: 0.0441 (0.0539)
2023-01-23 05:22:47,085 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45900, lr: 0.000443, loss: 0.0466 (0.0539)
2023-01-23 05:23:05,438 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 45950, lr: 0.000444, loss: 0.0493 (0.0539)
2023-01-23 05:23:23,813 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46000, lr: 0.000444, loss: 0.0463 (0.0539)
2023-01-23 05:23:42,151 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46050, lr: 0.000445, loss: 0.0485 (0.0538)
2023-01-23 05:24:00,614 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46100, lr: 0.000445, loss: 0.0474 (0.0538)
2023-01-23 05:24:18,931 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46150, lr: 0.000446, loss: 0.0473 (0.0538)
2023-01-23 05:24:37,332 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46200, lr: 0.000446, loss: 0.0481 (0.0538)
2023-01-23 05:24:55,757 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46250, lr: 0.000447, loss: 0.0467 (0.0538)
2023-01-23 05:25:14,204 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46300, lr: 0.000447, loss: 0.0482 (0.0538)
2023-01-23 05:25:32,559 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46350, lr: 0.000448, loss: 0.0496 (0.0538)
2023-01-23 05:25:50,838 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46400, lr: 0.000448, loss: 0.0485 (0.0538)
2023-01-23 05:26:09,223 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46450, lr: 0.000449, loss: 0.0478 (0.0538)
2023-01-23 05:26:27,579 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46500, lr: 0.000449, loss: 0.0501 (0.0538)
2023-01-23 05:26:46,002 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46550, lr: 0.000450, loss: 0.0451 (0.0538)
2023-01-23 05:27:04,334 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46600, lr: 0.000450, loss: 0.0481 (0.0538)
2023-01-23 05:27:22,722 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46650, lr: 0.000451, loss: 0.0468 (0.0538)
2023-01-23 05:27:41,093 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46700, lr: 0.000451, loss: 0.0508 (0.0538)
2023-01-23 05:27:59,430 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46750, lr: 0.000452, loss: 0.0481 (0.0538)
2023-01-23 05:28:17,835 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46800, lr: 0.000452, loss: 0.0466 (0.0537)
2023-01-23 05:28:36,207 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46850, lr: 0.000453, loss: 0.0474 (0.0537)
2023-01-23 05:28:54,735 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46900, lr: 0.000453, loss: 0.0478 (0.0537)
2023-01-23 05:29:12,975 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 46950, lr: 0.000454, loss: 0.0478 (0.0537)
2023-01-23 05:29:31,295 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47000, lr: 0.000454, loss: 0.0451 (0.0537)
2023-01-23 05:29:49,634 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47050, lr: 0.000455, loss: 0.0458 (0.0537)
2023-01-23 05:30:08,153 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47100, lr: 0.000455, loss: 0.0459 (0.0537)
2023-01-23 05:30:26,427 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47150, lr: 0.000456, loss: 0.0447 (0.0537)
2023-01-23 05:30:44,713 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47200, lr: 0.000456, loss: 0.0474 (0.0537)
2023-01-23 05:31:03,107 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47250, lr: 0.000457, loss: 0.0521 (0.0537)
2023-01-23 05:31:21,574 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47300, lr: 0.000457, loss: 0.0456 (0.0537)
2023-01-23 05:31:40,096 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47350, lr: 0.000457, loss: 0.0491 (0.0537)
2023-01-23 05:31:58,424 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47400, lr: 0.000458, loss: 0.0490 (0.0537)
2023-01-23 05:32:16,814 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47450, lr: 0.000458, loss: 0.0473 (0.0537)
2023-01-23 05:32:35,105 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47500, lr: 0.000459, loss: 0.0456 (0.0537)
2023-01-23 05:32:53,409 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47550, lr: 0.000459, loss: 0.0456 (0.0536)
2023-01-23 05:33:11,722 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47600, lr: 0.000460, loss: 0.0475 (0.0536)
2023-01-23 05:33:30,083 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47650, lr: 0.000460, loss: 0.0499 (0.0536)
2023-01-23 05:33:48,428 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47700, lr: 0.000461, loss: 0.0463 (0.0536)
2023-01-23 05:34:06,770 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47750, lr: 0.000461, loss: 0.0436 (0.0536)
2023-01-23 05:34:25,040 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47800, lr: 0.000462, loss: 0.0471 (0.0536)
2023-01-23 05:34:43,444 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47850, lr: 0.000462, loss: 0.0467 (0.0536)
2023-01-23 05:35:01,762 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47900, lr: 0.000463, loss: 0.0504 (0.0536)
2023-01-23 05:35:20,089 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 47950, lr: 0.000463, loss: 0.0470 (0.0536)
2023-01-23 05:35:38,428 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48000, lr: 0.000464, loss: 0.0457 (0.0536)
2023-01-23 05:35:56,634 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48050, lr: 0.000464, loss: 0.0463 (0.0536)
2023-01-23 05:36:14,987 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48100, lr: 0.000465, loss: 0.0470 (0.0536)
2023-01-23 05:36:33,380 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48150, lr: 0.000465, loss: 0.0444 (0.0536)
2023-01-23 05:36:51,720 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48200, lr: 0.000466, loss: 0.0435 (0.0536)
2023-01-23 05:37:10,049 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48250, lr: 0.000466, loss: 0.0497 (0.0536)
2023-01-23 05:37:28,438 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48300, lr: 0.000467, loss: 0.0491 (0.0535)
2023-01-23 05:37:46,913 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48350, lr: 0.000467, loss: 0.0496 (0.0535)
2023-01-23 05:38:05,382 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48400, lr: 0.000468, loss: 0.0464 (0.0535)
2023-01-23 05:38:23,923 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48450, lr: 0.000468, loss: 0.0478 (0.0535)
2023-01-23 05:38:42,472 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48500, lr: 0.000469, loss: 0.0456 (0.0535)
2023-01-23 05:39:00,960 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48550, lr: 0.000469, loss: 0.0464 (0.0535)
2023-01-23 05:39:19,566 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48600, lr: 0.000470, loss: 0.0463 (0.0535)
2023-01-23 05:39:38,346 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48650, lr: 0.000470, loss: 0.0475 (0.0535)
2023-01-23 05:39:57,108 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48700, lr: 0.000471, loss: 0.0490 (0.0535)
2023-01-23 05:40:15,945 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48750, lr: 0.000471, loss: 0.0457 (0.0535)
2023-01-23 05:40:34,816 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48800, lr: 0.000471, loss: 0.0463 (0.0535)
2023-01-23 05:40:53,746 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48850, lr: 0.000472, loss: 0.0490 (0.0535)
2023-01-23 05:41:12,608 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48900, lr: 0.000472, loss: 0.0449 (0.0535)
2023-01-23 05:41:31,877 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 48950, lr: 0.000473, loss: 0.0489 (0.0535)
2023-01-23 05:41:51,130 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49000, lr: 0.000473, loss: 0.0450 (0.0535)
2023-01-23 05:42:10,350 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49050, lr: 0.000474, loss: 0.0460 (0.0534)
2023-01-23 05:42:29,651 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49100, lr: 0.000474, loss: 0.0547 (0.0534)
2023-01-23 05:42:48,987 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49150, lr: 0.000475, loss: 0.0455 (0.0534)
2023-01-23 05:43:08,339 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49200, lr: 0.000475, loss: 0.0449 (0.0534)
2023-01-23 05:43:27,825 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49250, lr: 0.000476, loss: 0.0460 (0.0534)
2023-01-23 05:43:47,151 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49300, lr: 0.000476, loss: 0.0481 (0.0534)
2023-01-23 05:44:06,581 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49350, lr: 0.000477, loss: 0.0474 (0.0534)
2023-01-23 05:44:26,065 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49400, lr: 0.000477, loss: 0.0467 (0.0534)
2023-01-23 05:44:45,612 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49450, lr: 0.000478, loss: 0.0442 (0.0534)
2023-01-23 05:45:05,342 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49500, lr: 0.000478, loss: 0.0456 (0.0534)
2023-01-23 05:45:24,914 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49550, lr: 0.000479, loss: 0.0468 (0.0534)
2023-01-23 05:45:44,482 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49600, lr: 0.000479, loss: 0.0467 (0.0534)
2023-01-23 05:46:04,027 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49650, lr: 0.000480, loss: 0.0464 (0.0534)
2023-01-23 05:46:23,560 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49700, lr: 0.000480, loss: 0.0482 (0.0534)
2023-01-23 05:46:43,388 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49750, lr: 0.000481, loss: 0.0524 (0.0534)
2023-01-23 05:47:03,035 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49800, lr: 0.000481, loss: 0.0493 (0.0534)
2023-01-23 05:47:22,729 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49850, lr: 0.000482, loss: 0.0495 (0.0533)
2023-01-23 05:47:42,521 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49900, lr: 0.000482, loss: 0.0437 (0.0533)
2023-01-23 05:48:02,161 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 49950, lr: 0.000483, loss: 0.0463 (0.0533)
2023-01-23 05:48:21,887 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50000, lr: 0.000483, loss: 0.0478 (0.0533)
2023-01-23 05:48:23,256 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_6_50000.pt
2023-01-23 05:48:42,848 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50050, lr: 0.000484, loss: 0.0428 (0.0533)
2023-01-23 05:49:02,634 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50100, lr: 0.000484, loss: 0.0453 (0.0533)
2023-01-23 05:49:22,463 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50150, lr: 0.000485, loss: 0.0508 (0.0533)
2023-01-23 05:49:42,350 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50200, lr: 0.000485, loss: 0.0472 (0.0533)
2023-01-23 05:50:02,262 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50250, lr: 0.000485, loss: 0.0469 (0.0533)
2023-01-23 05:50:22,129 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50300, lr: 0.000486, loss: 0.0487 (0.0533)
2023-01-23 05:50:41,956 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50350, lr: 0.000486, loss: 0.0455 (0.0533)
2023-01-23 05:51:01,841 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50400, lr: 0.000487, loss: 0.0546 (0.0533)
2023-01-23 05:51:21,703 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50450, lr: 0.000487, loss: 0.0460 (0.0533)
2023-01-23 05:51:41,720 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50500, lr: 0.000488, loss: 0.0464 (0.0533)
2023-01-23 05:52:01,584 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50550, lr: 0.000488, loss: 0.0461 (0.0533)
2023-01-23 05:52:21,097 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50600, lr: 0.000489, loss: 0.0444 (0.0533)
2023-01-23 05:52:40,733 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50650, lr: 0.000489, loss: 0.0468 (0.0532)
2023-01-23 05:53:00,488 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50700, lr: 0.000490, loss: 0.0442 (0.0532)
2023-01-23 05:53:20,192 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50750, lr: 0.000490, loss: 0.0437 (0.0532)
2023-01-23 05:53:39,892 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50800, lr: 0.000491, loss: 0.0447 (0.0532)
2023-01-23 05:53:59,542 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50850, lr: 0.000491, loss: 0.0472 (0.0532)
2023-01-23 05:54:19,269 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50900, lr: 0.000492, loss: 0.0462 (0.0532)
2023-01-23 05:54:38,947 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 50950, lr: 0.000492, loss: 0.0456 (0.0532)
2023-01-23 05:54:58,754 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51000, lr: 0.000493, loss: 0.0439 (0.0532)
2023-01-23 05:55:18,554 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51050, lr: 0.000493, loss: 0.0515 (0.0532)
2023-01-23 05:55:38,453 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51100, lr: 0.000494, loss: 0.0455 (0.0532)
2023-01-23 05:55:58,181 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51150, lr: 0.000494, loss: 0.0497 (0.0532)
2023-01-23 05:56:17,983 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51200, lr: 0.000495, loss: 0.0524 (0.0532)
2023-01-23 05:56:38,077 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51250, lr: 0.000495, loss: 0.0459 (0.0532)
2023-01-23 05:56:57,936 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51300, lr: 0.000496, loss: 0.0489 (0.0532)
2023-01-23 05:57:17,936 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51350, lr: 0.000496, loss: 0.0444 (0.0532)
2023-01-23 05:57:37,797 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51400, lr: 0.000497, loss: 0.0472 (0.0531)
2023-01-23 05:57:57,715 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51450, lr: 0.000497, loss: 0.0437 (0.0531)
2023-01-23 05:58:17,865 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51500, lr: 0.000498, loss: 0.0481 (0.0531)
2023-01-23 05:58:37,803 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51550, lr: 0.000498, loss: 0.0453 (0.0531)
2023-01-23 05:58:57,683 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51600, lr: 0.000499, loss: 0.0523 (0.0531)
2023-01-23 05:59:17,683 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51650, lr: 0.000499, loss: 0.0484 (0.0531)
2023-01-23 05:59:37,690 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51700, lr: 0.000500, loss: 0.0464 (0.0531)
2023-01-23 05:59:57,610 CLIP_COCO_TRAIN INFO: Epoch: 6, global_step: 51750, lr: 0.000500, loss: 0.0510 (0.0531)
2023-01-23 06:00:17,615 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 51800, lr: 0.000500, loss: 0.0463 (0.0531)
2023-01-23 06:00:37,437 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 51850, lr: 0.000500, loss: 0.0450 (0.0531)
2023-01-23 06:00:57,312 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 51900, lr: 0.000500, loss: 0.0452 (0.0531)
2023-01-23 06:01:17,239 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 51950, lr: 0.000500, loss: 0.0461 (0.0531)
2023-01-23 06:01:37,111 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52000, lr: 0.000500, loss: 0.0475 (0.0531)
2023-01-23 06:01:57,041 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52050, lr: 0.000500, loss: 0.0429 (0.0531)
2023-01-23 06:02:16,912 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52100, lr: 0.000500, loss: 0.0443 (0.0531)
2023-01-23 06:02:36,862 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52150, lr: 0.000500, loss: 0.0473 (0.0531)
2023-01-23 06:02:56,820 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52200, lr: 0.000500, loss: 0.0459 (0.0531)
2023-01-23 06:03:16,815 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52250, lr: 0.000500, loss: 0.0494 (0.0530)
2023-01-23 06:03:36,754 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52300, lr: 0.000500, loss: 0.0466 (0.0530)
2023-01-23 06:03:56,788 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52350, lr: 0.000500, loss: 0.0428 (0.0530)
2023-01-23 06:04:16,845 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52400, lr: 0.000500, loss: 0.0470 (0.0530)
2023-01-23 06:04:36,937 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52450, lr: 0.000500, loss: 0.0487 (0.0530)
2023-01-23 06:04:56,898 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52500, lr: 0.000500, loss: 0.0429 (0.0530)
2023-01-23 06:05:17,129 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52550, lr: 0.000500, loss: 0.0463 (0.0530)
2023-01-23 06:05:37,486 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52600, lr: 0.000500, loss: 0.0458 (0.0530)
2023-01-23 06:05:57,469 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52650, lr: 0.000500, loss: 0.0476 (0.0530)
2023-01-23 06:06:17,539 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52700, lr: 0.000500, loss: 0.0424 (0.0530)
2023-01-23 06:06:37,647 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52750, lr: 0.000500, loss: 0.0457 (0.0530)
2023-01-23 06:06:58,147 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52800, lr: 0.000500, loss: 0.0447 (0.0530)
2023-01-23 06:07:18,540 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52850, lr: 0.000500, loss: 0.0444 (0.0530)
2023-01-23 06:07:39,006 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52900, lr: 0.000500, loss: 0.0462 (0.0530)
2023-01-23 06:07:59,590 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 52950, lr: 0.000500, loss: 0.0466 (0.0530)
2023-01-23 06:08:20,098 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53000, lr: 0.000500, loss: 0.0469 (0.0530)
2023-01-23 06:08:40,616 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53050, lr: 0.000500, loss: 0.0430 (0.0529)
2023-01-23 06:09:01,063 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53100, lr: 0.000500, loss: 0.0441 (0.0529)
2023-01-23 06:09:21,515 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53150, lr: 0.000500, loss: 0.0474 (0.0529)
2023-01-23 06:09:42,011 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53200, lr: 0.000500, loss: 0.0486 (0.0529)
2023-01-23 06:10:02,487 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53250, lr: 0.000500, loss: 0.0460 (0.0529)
2023-01-23 06:10:23,056 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53300, lr: 0.000500, loss: 0.0472 (0.0529)
2023-01-23 06:10:43,669 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53350, lr: 0.000500, loss: 0.0492 (0.0529)
2023-01-23 06:11:04,577 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53400, lr: 0.000500, loss: 0.0469 (0.0529)
2023-01-23 06:11:25,241 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53450, lr: 0.000500, loss: 0.0480 (0.0529)
2023-01-23 06:11:46,321 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53500, lr: 0.000500, loss: 0.0465 (0.0529)
2023-01-23 06:12:07,308 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53550, lr: 0.000500, loss: 0.0496 (0.0529)
2023-01-23 06:12:28,558 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53600, lr: 0.000500, loss: 0.0487 (0.0529)
2023-01-23 06:12:49,846 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53650, lr: 0.000500, loss: 0.0490 (0.0529)
2023-01-23 06:13:11,207 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53700, lr: 0.000500, loss: 0.0457 (0.0529)
2023-01-23 06:13:32,720 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53750, lr: 0.000500, loss: 0.0505 (0.0529)
2023-01-23 06:13:54,017 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53800, lr: 0.000500, loss: 0.0470 (0.0529)
2023-01-23 06:14:15,424 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53850, lr: 0.000500, loss: 0.0448 (0.0529)
2023-01-23 06:14:36,853 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53900, lr: 0.000500, loss: 0.0483 (0.0528)
2023-01-23 06:14:58,268 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 53950, lr: 0.000500, loss: 0.0495 (0.0528)
2023-01-23 06:15:19,833 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54000, lr: 0.000500, loss: 0.0462 (0.0528)
2023-01-23 06:15:41,538 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54050, lr: 0.000500, loss: 0.0472 (0.0528)
2023-01-23 06:16:02,778 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54100, lr: 0.000500, loss: 0.0458 (0.0528)
2023-01-23 06:16:24,531 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54150, lr: 0.000500, loss: 0.0459 (0.0528)
2023-01-23 06:16:45,842 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54200, lr: 0.000500, loss: 0.0461 (0.0528)
2023-01-23 06:17:07,153 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54250, lr: 0.000500, loss: 0.0453 (0.0528)
2023-01-23 06:17:28,185 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54300, lr: 0.000500, loss: 0.0476 (0.0528)
2023-01-23 06:17:48,822 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54350, lr: 0.000500, loss: 0.0438 (0.0528)
2023-01-23 06:18:09,314 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54400, lr: 0.000500, loss: 0.0477 (0.0528)
2023-01-23 06:18:29,756 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54450, lr: 0.000500, loss: 0.0468 (0.0528)
2023-01-23 06:18:50,260 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54500, lr: 0.000500, loss: 0.0463 (0.0528)
2023-01-23 06:19:10,726 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54550, lr: 0.000500, loss: 0.0467 (0.0528)
2023-01-23 06:19:31,228 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54600, lr: 0.000500, loss: 0.0483 (0.0528)
2023-01-23 06:19:51,760 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54650, lr: 0.000500, loss: 0.0468 (0.0528)
2023-01-23 06:20:11,966 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54700, lr: 0.000500, loss: 0.0452 (0.0528)
2023-01-23 06:20:32,088 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54750, lr: 0.000500, loss: 0.0459 (0.0527)
2023-01-23 06:20:52,092 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54800, lr: 0.000500, loss: 0.0460 (0.0527)
2023-01-23 06:21:12,188 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54850, lr: 0.000500, loss: 0.0512 (0.0527)
2023-01-23 06:21:32,232 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54900, lr: 0.000500, loss: 0.0492 (0.0527)
2023-01-23 06:21:52,370 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 54950, lr: 0.000500, loss: 0.0473 (0.0527)
2023-01-23 06:22:12,695 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55000, lr: 0.000500, loss: 0.0465 (0.0527)
2023-01-23 06:22:32,677 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55050, lr: 0.000500, loss: 0.0493 (0.0527)
2023-01-23 06:22:52,679 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55100, lr: 0.000500, loss: 0.0460 (0.0527)
2023-01-23 06:23:12,569 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55150, lr: 0.000500, loss: 0.0471 (0.0527)
2023-01-23 06:23:32,434 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55200, lr: 0.000500, loss: 0.0453 (0.0527)
2023-01-23 06:23:52,616 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55250, lr: 0.000500, loss: 0.0460 (0.0527)
2023-01-23 06:24:12,484 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55300, lr: 0.000500, loss: 0.0453 (0.0527)
2023-01-23 06:24:32,341 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55350, lr: 0.000500, loss: 0.0490 (0.0527)
2023-01-23 06:24:52,355 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55400, lr: 0.000500, loss: 0.0465 (0.0527)
2023-01-23 06:25:12,276 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55450, lr: 0.000500, loss: 0.0456 (0.0527)
2023-01-23 06:25:32,067 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55500, lr: 0.000500, loss: 0.0456 (0.0527)
2023-01-23 06:25:52,068 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55550, lr: 0.000500, loss: 0.0506 (0.0527)
2023-01-23 06:26:12,049 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55600, lr: 0.000500, loss: 0.0474 (0.0526)
2023-01-23 06:26:31,778 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55650, lr: 0.000500, loss: 0.0459 (0.0526)
2023-01-23 06:26:51,657 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55700, lr: 0.000500, loss: 0.0470 (0.0526)
2023-01-23 06:27:11,425 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55750, lr: 0.000500, loss: 0.0519 (0.0526)
2023-01-23 06:27:31,072 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55800, lr: 0.000500, loss: 0.0474 (0.0526)
2023-01-23 06:27:50,686 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55850, lr: 0.000500, loss: 0.0473 (0.0526)
2023-01-23 06:28:10,483 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55900, lr: 0.000500, loss: 0.0499 (0.0526)
2023-01-23 06:28:30,271 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 55950, lr: 0.000499, loss: 0.0487 (0.0526)
2023-01-23 06:28:50,005 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56000, lr: 0.000499, loss: 0.0483 (0.0526)
2023-01-23 06:29:09,851 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56050, lr: 0.000499, loss: 0.0466 (0.0526)
2023-01-23 06:29:29,668 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56100, lr: 0.000499, loss: 0.0467 (0.0526)
2023-01-23 06:29:49,551 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56150, lr: 0.000499, loss: 0.0455 (0.0526)
2023-01-23 06:30:09,206 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56200, lr: 0.000499, loss: 0.0445 (0.0526)
2023-01-23 06:30:28,914 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56250, lr: 0.000499, loss: 0.0476 (0.0526)
2023-01-23 06:30:48,634 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56300, lr: 0.000499, loss: 0.0455 (0.0526)
2023-01-23 06:31:08,457 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56350, lr: 0.000499, loss: 0.0476 (0.0526)
2023-01-23 06:31:28,105 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56400, lr: 0.000499, loss: 0.0477 (0.0526)
2023-01-23 06:31:47,940 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56450, lr: 0.000499, loss: 0.0452 (0.0526)
2023-01-23 06:32:07,645 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56500, lr: 0.000499, loss: 0.0471 (0.0525)
2023-01-23 06:32:27,289 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56550, lr: 0.000499, loss: 0.0448 (0.0525)
2023-01-23 06:32:46,934 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56600, lr: 0.000499, loss: 0.0472 (0.0525)
2023-01-23 06:33:06,525 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56650, lr: 0.000499, loss: 0.0460 (0.0525)
2023-01-23 06:33:26,177 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56700, lr: 0.000499, loss: 0.0444 (0.0525)
2023-01-23 06:33:45,827 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56750, lr: 0.000499, loss: 0.0449 (0.0525)
2023-01-23 06:34:05,521 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56800, lr: 0.000499, loss: 0.0440 (0.0525)
2023-01-23 06:34:25,133 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56850, lr: 0.000499, loss: 0.0449 (0.0525)
2023-01-23 06:34:44,699 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56900, lr: 0.000499, loss: 0.0496 (0.0525)
2023-01-23 06:35:04,293 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 56950, lr: 0.000499, loss: 0.0478 (0.0525)
2023-01-23 06:35:23,912 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57000, lr: 0.000499, loss: 0.0441 (0.0525)
2023-01-23 06:35:43,668 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57050, lr: 0.000499, loss: 0.0473 (0.0525)
2023-01-23 06:36:03,313 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57100, lr: 0.000499, loss: 0.0470 (0.0525)
2023-01-23 06:36:22,936 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57150, lr: 0.000499, loss: 0.0459 (0.0525)
2023-01-23 06:36:42,627 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57200, lr: 0.000499, loss: 0.0445 (0.0525)
2023-01-23 06:37:02,268 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57250, lr: 0.000499, loss: 0.0451 (0.0525)
2023-01-23 06:37:21,992 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57300, lr: 0.000499, loss: 0.0453 (0.0525)
2023-01-23 06:37:41,596 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57350, lr: 0.000499, loss: 0.0460 (0.0525)
2023-01-23 06:38:01,194 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57400, lr: 0.000499, loss: 0.0450 (0.0524)
2023-01-23 06:38:20,781 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57450, lr: 0.000499, loss: 0.0462 (0.0524)
2023-01-23 06:38:40,406 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57500, lr: 0.000499, loss: 0.0429 (0.0524)
2023-01-23 06:38:59,887 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57550, lr: 0.000499, loss: 0.0463 (0.0524)
2023-01-23 06:39:19,427 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57600, lr: 0.000499, loss: 0.0454 (0.0524)
2023-01-23 06:39:39,130 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57650, lr: 0.000499, loss: 0.0445 (0.0524)
2023-01-23 06:39:58,795 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57700, lr: 0.000499, loss: 0.0489 (0.0524)
2023-01-23 06:40:18,410 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57750, lr: 0.000499, loss: 0.0447 (0.0524)
2023-01-23 06:40:38,046 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57800, lr: 0.000499, loss: 0.0471 (0.0524)
2023-01-23 06:40:57,645 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57850, lr: 0.000499, loss: 0.0474 (0.0524)
2023-01-23 06:41:17,216 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57900, lr: 0.000499, loss: 0.0482 (0.0524)
2023-01-23 06:41:36,863 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 57950, lr: 0.000499, loss: 0.0464 (0.0524)
2023-01-23 06:41:56,441 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58000, lr: 0.000499, loss: 0.0476 (0.0524)
2023-01-23 06:42:16,105 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58050, lr: 0.000499, loss: 0.0477 (0.0524)
2023-01-23 06:42:35,706 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58100, lr: 0.000499, loss: 0.0451 (0.0524)
2023-01-23 06:42:55,214 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58150, lr: 0.000499, loss: 0.0470 (0.0524)
2023-01-23 06:43:14,835 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58200, lr: 0.000499, loss: 0.0490 (0.0524)
2023-01-23 06:43:34,503 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58250, lr: 0.000499, loss: 0.0464 (0.0524)
2023-01-23 06:43:54,030 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58300, lr: 0.000499, loss: 0.0475 (0.0524)
2023-01-23 06:44:13,603 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58350, lr: 0.000499, loss: 0.0447 (0.0523)
2023-01-23 06:44:33,437 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58400, lr: 0.000499, loss: 0.0495 (0.0523)
2023-01-23 06:44:53,346 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58450, lr: 0.000499, loss: 0.0467 (0.0523)
2023-01-23 06:45:13,025 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58500, lr: 0.000499, loss: 0.0474 (0.0523)
2023-01-23 06:45:32,878 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58550, lr: 0.000499, loss: 0.0438 (0.0523)
2023-01-23 06:45:52,722 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58600, lr: 0.000499, loss: 0.0449 (0.0523)
2023-01-23 06:46:12,659 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58650, lr: 0.000499, loss: 0.0418 (0.0523)
2023-01-23 06:46:32,536 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58700, lr: 0.000499, loss: 0.0457 (0.0523)
2023-01-23 06:46:52,355 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58750, lr: 0.000499, loss: 0.0438 (0.0523)
2023-01-23 06:47:12,135 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58800, lr: 0.000499, loss: 0.0458 (0.0523)
2023-01-23 06:47:31,958 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58850, lr: 0.000499, loss: 0.0461 (0.0523)
2023-01-23 06:47:51,740 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58900, lr: 0.000499, loss: 0.0467 (0.0523)
2023-01-23 06:48:11,537 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 58950, lr: 0.000499, loss: 0.0463 (0.0523)
2023-01-23 06:48:31,394 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 59000, lr: 0.000498, loss: 0.0475 (0.0523)
2023-01-23 06:48:51,211 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 59050, lr: 0.000498, loss: 0.0471 (0.0523)
2023-01-23 06:49:10,928 CLIP_COCO_TRAIN INFO: Epoch: 7, global_step: 59100, lr: 0.000498, loss: 0.0435 (0.0523)
2023-01-23 06:49:30,590 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59150, lr: 0.000498, loss: 0.0507 (0.0523)
2023-01-23 06:49:50,196 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59200, lr: 0.000498, loss: 0.0439 (0.0523)
2023-01-23 06:50:09,902 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59250, lr: 0.000498, loss: 0.0453 (0.0523)
2023-01-23 06:50:29,571 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59300, lr: 0.000498, loss: 0.0456 (0.0523)
2023-01-23 06:50:49,064 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59350, lr: 0.000498, loss: 0.0436 (0.0522)
2023-01-23 06:51:08,616 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59400, lr: 0.000498, loss: 0.0521 (0.0522)
2023-01-23 06:51:28,133 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59450, lr: 0.000498, loss: 0.0449 (0.0522)
2023-01-23 06:51:47,621 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59500, lr: 0.000498, loss: 0.0438 (0.0522)
2023-01-23 06:52:07,220 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59550, lr: 0.000498, loss: 0.0481 (0.0522)
2023-01-23 06:52:26,644 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59600, lr: 0.000498, loss: 0.0472 (0.0522)
2023-01-23 06:52:46,228 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59650, lr: 0.000498, loss: 0.0463 (0.0522)
2023-01-23 06:53:05,852 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59700, lr: 0.000498, loss: 0.0445 (0.0522)
2023-01-23 06:53:25,421 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59750, lr: 0.000498, loss: 0.0464 (0.0522)
2023-01-23 06:53:45,024 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59800, lr: 0.000498, loss: 0.0449 (0.0522)
2023-01-23 06:54:04,537 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59850, lr: 0.000498, loss: 0.0478 (0.0522)
2023-01-23 06:54:24,146 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59900, lr: 0.000498, loss: 0.0491 (0.0522)
2023-01-23 06:54:43,658 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 59950, lr: 0.000498, loss: 0.0469 (0.0522)
2023-01-23 06:55:03,248 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60000, lr: 0.000498, loss: 0.0462 (0.0522)
2023-01-23 06:55:04,636 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_8_60000.pt
2023-01-23 06:55:23,932 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60050, lr: 0.000498, loss: 0.0490 (0.0522)
2023-01-23 06:55:43,052 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60100, lr: 0.000498, loss: 0.0432 (0.0522)
2023-01-23 06:56:02,245 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60150, lr: 0.000498, loss: 0.0450 (0.0522)
2023-01-23 06:56:21,497 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60200, lr: 0.000498, loss: 0.0462 (0.0522)
2023-01-23 06:56:40,696 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60250, lr: 0.000498, loss: 0.0456 (0.0522)
2023-01-23 06:56:59,908 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60300, lr: 0.000498, loss: 0.0457 (0.0521)
2023-01-23 06:57:18,902 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60350, lr: 0.000498, loss: 0.0462 (0.0521)
2023-01-23 06:57:38,023 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60400, lr: 0.000498, loss: 0.0448 (0.0521)
2023-01-23 06:57:57,281 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60450, lr: 0.000498, loss: 0.0457 (0.0521)
2023-01-23 06:58:16,459 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60500, lr: 0.000498, loss: 0.0448 (0.0521)
2023-01-23 06:58:35,678 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60550, lr: 0.000498, loss: 0.0457 (0.0521)
2023-01-23 06:58:54,834 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60600, lr: 0.000498, loss: 0.0470 (0.0521)
2023-01-23 06:59:13,923 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60650, lr: 0.000498, loss: 0.0455 (0.0521)
2023-01-23 06:59:33,057 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60700, lr: 0.000498, loss: 0.0472 (0.0521)
2023-01-23 06:59:52,270 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60750, lr: 0.000498, loss: 0.0457 (0.0521)
2023-01-23 07:00:11,448 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60800, lr: 0.000498, loss: 0.0458 (0.0521)
2023-01-23 07:00:30,544 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60850, lr: 0.000498, loss: 0.0442 (0.0521)
2023-01-23 07:00:49,844 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60900, lr: 0.000498, loss: 0.0464 (0.0521)
2023-01-23 07:01:08,997 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 60950, lr: 0.000498, loss: 0.0444 (0.0521)
2023-01-23 07:01:28,214 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61000, lr: 0.000498, loss: 0.0465 (0.0521)
2023-01-23 07:01:47,335 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61050, lr: 0.000498, loss: 0.0454 (0.0521)
2023-01-23 07:02:06,590 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61100, lr: 0.000497, loss: 0.0501 (0.0521)
2023-01-23 07:02:25,724 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61150, lr: 0.000497, loss: 0.0464 (0.0521)
2023-01-23 07:02:44,978 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61200, lr: 0.000497, loss: 0.0427 (0.0521)
2023-01-23 07:03:04,075 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61250, lr: 0.000497, loss: 0.0456 (0.0521)
2023-01-23 07:03:23,187 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61300, lr: 0.000497, loss: 0.0472 (0.0520)
2023-01-23 07:03:42,458 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61350, lr: 0.000497, loss: 0.0424 (0.0520)
2023-01-23 07:04:01,668 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61400, lr: 0.000497, loss: 0.0502 (0.0520)
2023-01-23 07:04:20,796 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61450, lr: 0.000497, loss: 0.0487 (0.0520)
2023-01-23 07:04:39,968 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61500, lr: 0.000497, loss: 0.0435 (0.0520)
2023-01-23 07:04:59,074 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61550, lr: 0.000497, loss: 0.0462 (0.0520)
2023-01-23 07:05:18,248 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61600, lr: 0.000497, loss: 0.0468 (0.0520)
2023-01-23 07:05:37,460 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61650, lr: 0.000497, loss: 0.0424 (0.0520)
2023-01-23 07:05:56,510 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61700, lr: 0.000497, loss: 0.0494 (0.0520)
2023-01-23 07:06:15,579 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61750, lr: 0.000497, loss: 0.0470 (0.0520)
2023-01-23 07:06:34,838 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61800, lr: 0.000497, loss: 0.0461 (0.0520)
2023-01-23 07:06:54,077 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61850, lr: 0.000497, loss: 0.0437 (0.0520)
2023-01-23 07:07:13,129 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61900, lr: 0.000497, loss: 0.0450 (0.0520)
2023-01-23 07:07:32,295 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 61950, lr: 0.000497, loss: 0.0472 (0.0520)
2023-01-23 07:07:51,446 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62000, lr: 0.000497, loss: 0.0456 (0.0520)
2023-01-23 07:08:10,600 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62050, lr: 0.000497, loss: 0.0459 (0.0520)
2023-01-23 07:08:29,755 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62100, lr: 0.000497, loss: 0.0454 (0.0520)
2023-01-23 07:08:48,957 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62150, lr: 0.000497, loss: 0.0456 (0.0520)
2023-01-23 07:09:08,069 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62200, lr: 0.000497, loss: 0.0489 (0.0520)
2023-01-23 07:09:27,269 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62250, lr: 0.000497, loss: 0.0456 (0.0520)
2023-01-23 07:09:46,371 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62300, lr: 0.000497, loss: 0.0440 (0.0520)
2023-01-23 07:10:05,518 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62350, lr: 0.000497, loss: 0.0471 (0.0519)
2023-01-23 07:10:24,667 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62400, lr: 0.000497, loss: 0.0489 (0.0519)
2023-01-23 07:10:43,833 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62450, lr: 0.000497, loss: 0.0468 (0.0519)
2023-01-23 07:11:03,071 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62500, lr: 0.000497, loss: 0.0451 (0.0519)
2023-01-23 07:11:22,329 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62550, lr: 0.000497, loss: 0.0471 (0.0519)
2023-01-23 07:11:41,451 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62600, lr: 0.000497, loss: 0.0467 (0.0519)
2023-01-23 07:12:00,720 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62650, lr: 0.000497, loss: 0.0424 (0.0519)
2023-01-23 07:12:19,843 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62700, lr: 0.000497, loss: 0.0449 (0.0519)
2023-01-23 07:12:39,149 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62750, lr: 0.000497, loss: 0.0449 (0.0519)
2023-01-23 07:12:58,283 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62800, lr: 0.000496, loss: 0.0460 (0.0519)
2023-01-23 07:13:17,387 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62850, lr: 0.000496, loss: 0.0478 (0.0519)
2023-01-23 07:13:36,555 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62900, lr: 0.000496, loss: 0.0453 (0.0519)
2023-01-23 07:13:55,618 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 62950, lr: 0.000496, loss: 0.0426 (0.0519)
2023-01-23 07:14:14,812 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63000, lr: 0.000496, loss: 0.0488 (0.0519)
2023-01-23 07:14:34,013 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63050, lr: 0.000496, loss: 0.0468 (0.0519)
2023-01-23 07:14:53,132 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63100, lr: 0.000496, loss: 0.0441 (0.0519)
2023-01-23 07:15:12,246 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63150, lr: 0.000496, loss: 0.0459 (0.0519)
2023-01-23 07:15:31,437 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63200, lr: 0.000496, loss: 0.0480 (0.0519)
2023-01-23 07:15:50,558 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63250, lr: 0.000496, loss: 0.0470 (0.0519)
2023-01-23 07:16:09,637 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63300, lr: 0.000496, loss: 0.0480 (0.0519)
2023-01-23 07:16:28,723 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63350, lr: 0.000496, loss: 0.0450 (0.0519)
2023-01-23 07:16:47,937 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63400, lr: 0.000496, loss: 0.0470 (0.0518)
2023-01-23 07:17:07,071 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63450, lr: 0.000496, loss: 0.0461 (0.0518)
2023-01-23 07:17:26,283 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63500, lr: 0.000496, loss: 0.0486 (0.0518)
2023-01-23 07:17:45,359 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63550, lr: 0.000496, loss: 0.0441 (0.0518)
2023-01-23 07:18:04,559 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63600, lr: 0.000496, loss: 0.0463 (0.0518)
2023-01-23 07:18:23,811 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63650, lr: 0.000496, loss: 0.0460 (0.0518)
2023-01-23 07:18:42,952 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63700, lr: 0.000496, loss: 0.0463 (0.0518)
2023-01-23 07:19:02,060 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63750, lr: 0.000496, loss: 0.0434 (0.0518)
2023-01-23 07:19:21,240 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63800, lr: 0.000496, loss: 0.0514 (0.0518)
2023-01-23 07:19:40,423 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63850, lr: 0.000496, loss: 0.0468 (0.0518)
2023-01-23 07:19:59,517 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63900, lr: 0.000496, loss: 0.0498 (0.0518)
2023-01-23 07:20:18,687 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 63950, lr: 0.000496, loss: 0.0471 (0.0518)
2023-01-23 07:20:37,741 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64000, lr: 0.000496, loss: 0.0485 (0.0518)
2023-01-23 07:20:56,873 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64050, lr: 0.000496, loss: 0.0462 (0.0518)
2023-01-23 07:21:15,997 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64100, lr: 0.000496, loss: 0.0457 (0.0518)
2023-01-23 07:21:35,122 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64150, lr: 0.000496, loss: 0.0519 (0.0518)
2023-01-23 07:21:54,203 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64200, lr: 0.000496, loss: 0.0429 (0.0518)
2023-01-23 07:22:13,444 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64250, lr: 0.000496, loss: 0.0437 (0.0518)
2023-01-23 07:22:32,523 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64300, lr: 0.000495, loss: 0.0445 (0.0518)
2023-01-23 07:22:51,666 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64350, lr: 0.000495, loss: 0.0460 (0.0518)
2023-01-23 07:23:10,775 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64400, lr: 0.000495, loss: 0.0447 (0.0518)
2023-01-23 07:23:29,926 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64450, lr: 0.000495, loss: 0.0494 (0.0517)
2023-01-23 07:23:49,010 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64500, lr: 0.000495, loss: 0.0460 (0.0517)
2023-01-23 07:24:08,221 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64550, lr: 0.000495, loss: 0.0475 (0.0517)
2023-01-23 07:24:27,363 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64600, lr: 0.000495, loss: 0.0468 (0.0517)
2023-01-23 07:24:46,597 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64650, lr: 0.000495, loss: 0.0458 (0.0517)
2023-01-23 07:25:05,818 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64700, lr: 0.000495, loss: 0.0454 (0.0517)
2023-01-23 07:25:25,039 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64750, lr: 0.000495, loss: 0.0452 (0.0517)
2023-01-23 07:25:44,221 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64800, lr: 0.000495, loss: 0.0452 (0.0517)
2023-01-23 07:26:03,419 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64850, lr: 0.000495, loss: 0.0459 (0.0517)
2023-01-23 07:26:22,617 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64900, lr: 0.000495, loss: 0.0453 (0.0517)
2023-01-23 07:26:41,945 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 64950, lr: 0.000495, loss: 0.0456 (0.0517)
2023-01-23 07:27:01,209 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65000, lr: 0.000495, loss: 0.0477 (0.0517)
2023-01-23 07:27:20,522 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65050, lr: 0.000495, loss: 0.0424 (0.0517)
2023-01-23 07:27:39,879 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65100, lr: 0.000495, loss: 0.0469 (0.0517)
2023-01-23 07:27:59,267 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65150, lr: 0.000495, loss: 0.0472 (0.0517)
2023-01-23 07:28:18,762 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65200, lr: 0.000495, loss: 0.0509 (0.0517)
2023-01-23 07:28:38,199 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65250, lr: 0.000495, loss: 0.0431 (0.0517)
2023-01-23 07:28:57,679 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65300, lr: 0.000495, loss: 0.0470 (0.0517)
2023-01-23 07:29:17,269 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65350, lr: 0.000495, loss: 0.0477 (0.0517)
2023-01-23 07:29:36,813 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65400, lr: 0.000495, loss: 0.0460 (0.0517)
2023-01-23 07:29:56,369 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65450, lr: 0.000495, loss: 0.0449 (0.0517)
2023-01-23 07:30:16,129 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65500, lr: 0.000495, loss: 0.0452 (0.0517)
2023-01-23 07:30:35,808 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65550, lr: 0.000495, loss: 0.0432 (0.0517)
2023-01-23 07:30:55,579 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65600, lr: 0.000494, loss: 0.0496 (0.0516)
2023-01-23 07:31:15,174 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65650, lr: 0.000494, loss: 0.0466 (0.0516)
2023-01-23 07:31:34,859 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65700, lr: 0.000494, loss: 0.0467 (0.0516)
2023-01-23 07:31:54,540 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65750, lr: 0.000494, loss: 0.0474 (0.0516)
2023-01-23 07:32:14,340 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65800, lr: 0.000494, loss: 0.0455 (0.0516)
2023-01-23 07:32:33,945 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65850, lr: 0.000494, loss: 0.0471 (0.0516)
2023-01-23 07:32:53,611 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65900, lr: 0.000494, loss: 0.0464 (0.0516)
2023-01-23 07:33:13,426 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 65950, lr: 0.000494, loss: 0.0448 (0.0516)
2023-01-23 07:33:32,991 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66000, lr: 0.000494, loss: 0.0462 (0.0516)
2023-01-23 07:33:52,546 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66050, lr: 0.000494, loss: 0.0458 (0.0516)
2023-01-23 07:34:12,208 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66100, lr: 0.000494, loss: 0.0443 (0.0516)
2023-01-23 07:34:31,757 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66150, lr: 0.000494, loss: 0.0450 (0.0516)
2023-01-23 07:34:51,390 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66200, lr: 0.000494, loss: 0.0471 (0.0516)
2023-01-23 07:35:11,000 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66250, lr: 0.000494, loss: 0.0461 (0.0516)
2023-01-23 07:35:30,470 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66300, lr: 0.000494, loss: 0.0456 (0.0516)
2023-01-23 07:35:50,138 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66350, lr: 0.000494, loss: 0.0458 (0.0516)
2023-01-23 07:36:09,852 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66400, lr: 0.000494, loss: 0.0416 (0.0516)
2023-01-23 07:36:29,331 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66450, lr: 0.000494, loss: 0.0464 (0.0516)
2023-01-23 07:36:48,878 CLIP_COCO_TRAIN INFO: Epoch: 8, global_step: 66500, lr: 0.000494, loss: 0.0476 (0.0516)
2023-01-23 07:37:08,358 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66550, lr: 0.000494, loss: 0.0446 (0.0516)
2023-01-23 07:37:27,643 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66600, lr: 0.000494, loss: 0.0441 (0.0516)
2023-01-23 07:37:47,122 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66650, lr: 0.000494, loss: 0.0458 (0.0516)
2023-01-23 07:38:06,535 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66700, lr: 0.000494, loss: 0.0451 (0.0515)
2023-01-23 07:38:25,908 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66750, lr: 0.000494, loss: 0.0456 (0.0515)
2023-01-23 07:38:45,194 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66800, lr: 0.000494, loss: 0.0442 (0.0515)
2023-01-23 07:39:04,429 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66850, lr: 0.000493, loss: 0.0452 (0.0515)
2023-01-23 07:39:23,778 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66900, lr: 0.000493, loss: 0.0457 (0.0515)
2023-01-23 07:39:43,194 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 66950, lr: 0.000493, loss: 0.0433 (0.0515)
2023-01-23 07:40:02,456 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67000, lr: 0.000493, loss: 0.0463 (0.0515)
2023-01-23 07:40:21,775 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67050, lr: 0.000493, loss: 0.0487 (0.0515)
2023-01-23 07:40:41,032 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67100, lr: 0.000493, loss: 0.0487 (0.0515)
2023-01-23 07:41:00,366 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67150, lr: 0.000493, loss: 0.0455 (0.0515)
2023-01-23 07:41:19,762 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67200, lr: 0.000493, loss: 0.0463 (0.0515)
2023-01-23 07:41:39,029 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67250, lr: 0.000493, loss: 0.0458 (0.0515)
2023-01-23 07:41:58,293 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67300, lr: 0.000493, loss: 0.0462 (0.0515)
2023-01-23 07:42:17,639 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67350, lr: 0.000493, loss: 0.0435 (0.0515)
2023-01-23 07:42:36,863 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67400, lr: 0.000493, loss: 0.0471 (0.0515)
2023-01-23 07:42:56,055 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67450, lr: 0.000493, loss: 0.0452 (0.0515)
2023-01-23 07:43:15,259 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67500, lr: 0.000493, loss: 0.0451 (0.0515)
2023-01-23 07:43:34,552 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67550, lr: 0.000493, loss: 0.0439 (0.0515)
2023-01-23 07:43:53,737 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67600, lr: 0.000493, loss: 0.0463 (0.0515)
2023-01-23 07:44:12,989 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67650, lr: 0.000493, loss: 0.0470 (0.0515)
2023-01-23 07:44:32,170 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67700, lr: 0.000493, loss: 0.0449 (0.0515)
2023-01-23 07:44:51,442 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67750, lr: 0.000493, loss: 0.0468 (0.0515)
2023-01-23 07:45:10,731 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67800, lr: 0.000493, loss: 0.0455 (0.0515)
2023-01-23 07:45:29,874 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67850, lr: 0.000493, loss: 0.0456 (0.0514)
2023-01-23 07:45:49,383 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67900, lr: 0.000493, loss: 0.0453 (0.0514)
2023-01-23 07:46:08,938 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 67950, lr: 0.000492, loss: 0.0450 (0.0514)
2023-01-23 07:46:28,438 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68000, lr: 0.000492, loss: 0.0476 (0.0514)
2023-01-23 07:46:47,912 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68050, lr: 0.000492, loss: 0.0462 (0.0514)
2023-01-23 07:47:07,461 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68100, lr: 0.000492, loss: 0.0432 (0.0514)
2023-01-23 07:47:26,798 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68150, lr: 0.000492, loss: 0.0440 (0.0514)
2023-01-23 07:47:46,184 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68200, lr: 0.000492, loss: 0.0428 (0.0514)
2023-01-23 07:48:05,612 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68250, lr: 0.000492, loss: 0.0465 (0.0514)
2023-01-23 07:48:25,070 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68300, lr: 0.000492, loss: 0.0456 (0.0514)
2023-01-23 07:48:44,460 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68350, lr: 0.000492, loss: 0.0439 (0.0514)
2023-01-23 07:49:03,798 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68400, lr: 0.000492, loss: 0.0444 (0.0514)
2023-01-23 07:49:23,286 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68450, lr: 0.000492, loss: 0.0447 (0.0514)
2023-01-23 07:49:42,634 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68500, lr: 0.000492, loss: 0.0488 (0.0514)
2023-01-23 07:50:02,080 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68550, lr: 0.000492, loss: 0.0422 (0.0514)
2023-01-23 07:50:21,433 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68600, lr: 0.000492, loss: 0.0470 (0.0514)
2023-01-23 07:50:40,746 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68650, lr: 0.000492, loss: 0.0436 (0.0514)
2023-01-23 07:51:00,130 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68700, lr: 0.000492, loss: 0.0454 (0.0514)
2023-01-23 07:51:19,530 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68750, lr: 0.000492, loss: 0.0460 (0.0514)
2023-01-23 07:51:38,830 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68800, lr: 0.000492, loss: 0.0434 (0.0514)
2023-01-23 07:51:58,183 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68850, lr: 0.000492, loss: 0.0463 (0.0514)
2023-01-23 07:52:17,516 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68900, lr: 0.000492, loss: 0.0542 (0.0514)
2023-01-23 07:52:36,871 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 68950, lr: 0.000492, loss: 0.0435 (0.0514)
2023-01-23 07:52:56,215 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69000, lr: 0.000491, loss: 0.0456 (0.0514)
2023-01-23 07:53:15,467 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69050, lr: 0.000491, loss: 0.0466 (0.0513)
2023-01-23 07:53:34,788 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69100, lr: 0.000491, loss: 0.0458 (0.0513)
2023-01-23 07:53:54,106 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69150, lr: 0.000491, loss: 0.0471 (0.0513)
2023-01-23 07:54:13,532 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69200, lr: 0.000491, loss: 0.0450 (0.0513)
2023-01-23 07:54:32,844 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69250, lr: 0.000491, loss: 0.0469 (0.0513)
2023-01-23 07:54:52,136 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69300, lr: 0.000491, loss: 0.0449 (0.0513)
2023-01-23 07:55:11,558 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69350, lr: 0.000491, loss: 0.0476 (0.0513)
2023-01-23 07:55:30,864 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69400, lr: 0.000491, loss: 0.0441 (0.0513)
2023-01-23 07:55:50,217 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69450, lr: 0.000491, loss: 0.0457 (0.0513)
2023-01-23 07:56:09,503 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69500, lr: 0.000491, loss: 0.0463 (0.0513)
2023-01-23 07:56:28,858 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69550, lr: 0.000491, loss: 0.0448 (0.0513)
2023-01-23 07:56:48,041 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69600, lr: 0.000491, loss: 0.0456 (0.0513)
2023-01-23 07:57:07,381 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69650, lr: 0.000491, loss: 0.0467 (0.0513)
2023-01-23 07:57:26,623 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69700, lr: 0.000491, loss: 0.0451 (0.0513)
2023-01-23 07:57:45,957 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69750, lr: 0.000491, loss: 0.0425 (0.0513)
2023-01-23 07:58:05,288 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69800, lr: 0.000491, loss: 0.0493 (0.0513)
2023-01-23 07:58:24,546 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69850, lr: 0.000491, loss: 0.0432 (0.0513)
2023-01-23 07:58:43,855 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69900, lr: 0.000491, loss: 0.0443 (0.0513)
2023-01-23 07:59:03,248 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 69950, lr: 0.000491, loss: 0.0442 (0.0513)
2023-01-23 07:59:22,534 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70000, lr: 0.000490, loss: 0.0460 (0.0513)
2023-01-23 07:59:23,952 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_9_70000.pt
2023-01-23 07:59:42,850 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70050, lr: 0.000490, loss: 0.0456 (0.0513)
2023-01-23 08:00:01,829 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70100, lr: 0.000490, loss: 0.0468 (0.0513)
2023-01-23 08:00:20,851 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70150, lr: 0.000490, loss: 0.0444 (0.0513)
2023-01-23 08:00:39,824 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70200, lr: 0.000490, loss: 0.0481 (0.0513)
2023-01-23 08:00:58,754 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70250, lr: 0.000490, loss: 0.0450 (0.0512)
2023-01-23 08:01:17,788 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70300, lr: 0.000490, loss: 0.0476 (0.0512)
2023-01-23 08:01:36,865 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70350, lr: 0.000490, loss: 0.0446 (0.0512)
2023-01-23 08:01:55,882 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70400, lr: 0.000490, loss: 0.0466 (0.0512)
2023-01-23 08:02:14,907 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70450, lr: 0.000490, loss: 0.0447 (0.0512)
2023-01-23 08:02:33,999 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70500, lr: 0.000490, loss: 0.0455 (0.0512)
2023-01-23 08:02:52,916 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70550, lr: 0.000490, loss: 0.0453 (0.0512)
2023-01-23 08:03:11,947 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70600, lr: 0.000490, loss: 0.0465 (0.0512)
2023-01-23 08:03:30,906 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70650, lr: 0.000490, loss: 0.0457 (0.0512)
2023-01-23 08:03:49,979 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70700, lr: 0.000490, loss: 0.0465 (0.0512)
2023-01-23 08:04:09,071 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70750, lr: 0.000490, loss: 0.0484 (0.0512)
2023-01-23 08:04:28,148 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70800, lr: 0.000490, loss: 0.0441 (0.0512)
2023-01-23 08:04:47,204 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70850, lr: 0.000490, loss: 0.0448 (0.0512)
2023-01-23 08:05:06,331 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70900, lr: 0.000490, loss: 0.0455 (0.0512)
2023-01-23 08:05:25,436 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 70950, lr: 0.000489, loss: 0.0424 (0.0512)
2023-01-23 08:05:44,456 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71000, lr: 0.000489, loss: 0.0460 (0.0512)
2023-01-23 08:06:03,589 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71050, lr: 0.000489, loss: 0.0422 (0.0512)
2023-01-23 08:06:22,724 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71100, lr: 0.000489, loss: 0.0469 (0.0512)
2023-01-23 08:06:41,778 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71150, lr: 0.000489, loss: 0.0454 (0.0512)
2023-01-23 08:07:00,796 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71200, lr: 0.000489, loss: 0.0426 (0.0512)
2023-01-23 08:07:19,903 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71250, lr: 0.000489, loss: 0.0449 (0.0512)
2023-01-23 08:07:38,938 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71300, lr: 0.000489, loss: 0.0438 (0.0512)
2023-01-23 08:07:58,122 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71350, lr: 0.000489, loss: 0.0445 (0.0512)
2023-01-23 08:08:17,223 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71400, lr: 0.000489, loss: 0.0456 (0.0512)
2023-01-23 08:08:36,363 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71450, lr: 0.000489, loss: 0.0496 (0.0512)
2023-01-23 08:08:55,403 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71500, lr: 0.000489, loss: 0.0480 (0.0512)
2023-01-23 08:09:14,437 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71550, lr: 0.000489, loss: 0.0468 (0.0511)
2023-01-23 08:09:33,520 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71600, lr: 0.000489, loss: 0.0482 (0.0511)
2023-01-23 08:09:52,637 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71650, lr: 0.000489, loss: 0.0473 (0.0511)
2023-01-23 08:10:11,684 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71700, lr: 0.000489, loss: 0.0475 (0.0511)
2023-01-23 08:10:30,819 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71750, lr: 0.000489, loss: 0.0405 (0.0511)
2023-01-23 08:10:49,977 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71800, lr: 0.000489, loss: 0.0468 (0.0511)
2023-01-23 08:11:09,191 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71850, lr: 0.000488, loss: 0.0438 (0.0511)
2023-01-23 08:11:28,361 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71900, lr: 0.000488, loss: 0.0453 (0.0511)
2023-01-23 08:11:47,660 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 71950, lr: 0.000488, loss: 0.0485 (0.0511)
2023-01-23 08:12:06,801 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72000, lr: 0.000488, loss: 0.0428 (0.0511)
2023-01-23 08:12:26,065 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72050, lr: 0.000488, loss: 0.0455 (0.0511)
2023-01-23 08:12:45,563 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72100, lr: 0.000488, loss: 0.0466 (0.0511)
2023-01-23 08:13:04,974 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72150, lr: 0.000488, loss: 0.0439 (0.0511)
2023-01-23 08:13:24,578 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72200, lr: 0.000488, loss: 0.0449 (0.0511)
2023-01-23 08:13:44,259 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72250, lr: 0.000488, loss: 0.0453 (0.0511)
2023-01-23 08:14:03,950 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72300, lr: 0.000488, loss: 0.0450 (0.0511)
2023-01-23 08:14:23,673 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72350, lr: 0.000488, loss: 0.0469 (0.0511)
2023-01-23 08:14:43,560 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72400, lr: 0.000488, loss: 0.0447 (0.0511)
2023-01-23 08:15:03,340 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72450, lr: 0.000488, loss: 0.0447 (0.0511)
2023-01-23 08:15:23,214 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72500, lr: 0.000488, loss: 0.0449 (0.0511)
2023-01-23 08:15:43,086 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72550, lr: 0.000488, loss: 0.0463 (0.0511)
2023-01-23 08:16:02,980 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72600, lr: 0.000488, loss: 0.0471 (0.0511)
2023-01-23 08:16:22,935 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72650, lr: 0.000488, loss: 0.0489 (0.0511)
2023-01-23 08:16:42,881 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72700, lr: 0.000487, loss: 0.0470 (0.0511)
2023-01-23 08:17:02,880 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72750, lr: 0.000487, loss: 0.0443 (0.0511)
2023-01-23 08:17:22,763 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72800, lr: 0.000487, loss: 0.0480 (0.0510)
2023-01-23 08:17:42,595 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72850, lr: 0.000487, loss: 0.0445 (0.0510)
2023-01-23 08:18:02,461 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72900, lr: 0.000487, loss: 0.0427 (0.0510)
2023-01-23 08:18:22,301 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 72950, lr: 0.000487, loss: 0.0464 (0.0510)
2023-01-23 08:18:42,223 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73000, lr: 0.000487, loss: 0.0448 (0.0510)
2023-01-23 08:19:01,884 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73050, lr: 0.000487, loss: 0.0487 (0.0510)
2023-01-23 08:19:21,634 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73100, lr: 0.000487, loss: 0.0458 (0.0510)
2023-01-23 08:19:41,391 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73150, lr: 0.000487, loss: 0.0438 (0.0510)
2023-01-23 08:20:01,258 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73200, lr: 0.000487, loss: 0.0437 (0.0510)
2023-01-23 08:20:21,085 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73250, lr: 0.000487, loss: 0.0528 (0.0510)
2023-01-23 08:20:40,864 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73300, lr: 0.000487, loss: 0.0435 (0.0510)
2023-01-23 08:21:00,654 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73350, lr: 0.000487, loss: 0.0455 (0.0510)
2023-01-23 08:21:20,454 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73400, lr: 0.000487, loss: 0.0433 (0.0510)
2023-01-23 08:21:40,261 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73450, lr: 0.000487, loss: 0.0500 (0.0510)
2023-01-23 08:21:59,967 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73500, lr: 0.000487, loss: 0.0455 (0.0510)
2023-01-23 08:22:19,641 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73550, lr: 0.000486, loss: 0.0482 (0.0510)
2023-01-23 08:22:39,393 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73600, lr: 0.000486, loss: 0.0435 (0.0510)
2023-01-23 08:22:59,101 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73650, lr: 0.000486, loss: 0.0455 (0.0510)
2023-01-23 08:23:18,880 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73700, lr: 0.000486, loss: 0.0462 (0.0510)
2023-01-23 08:23:38,610 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73750, lr: 0.000486, loss: 0.0444 (0.0510)
2023-01-23 08:23:58,325 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73800, lr: 0.000486, loss: 0.0476 (0.0510)
2023-01-23 08:24:18,139 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73850, lr: 0.000486, loss: 0.0461 (0.0510)
2023-01-23 08:24:37,697 CLIP_COCO_TRAIN INFO: Epoch: 9, global_step: 73900, lr: 0.000486, loss: 0.0438 (0.0510)
2023-01-23 08:24:57,309 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 73950, lr: 0.000486, loss: 0.0446 (0.0510)
2023-01-23 08:25:16,913 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74000, lr: 0.000486, loss: 0.0481 (0.0510)
2023-01-23 08:25:36,498 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74050, lr: 0.000486, loss: 0.0472 (0.0510)
2023-01-23 08:25:56,014 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74100, lr: 0.000486, loss: 0.0471 (0.0509)
2023-01-23 08:26:15,465 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74150, lr: 0.000486, loss: 0.0448 (0.0509)
2023-01-23 08:26:34,975 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74200, lr: 0.000486, loss: 0.0460 (0.0509)
2023-01-23 08:26:54,430 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74250, lr: 0.000486, loss: 0.0440 (0.0509)
2023-01-23 08:27:13,848 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74300, lr: 0.000486, loss: 0.0450 (0.0509)
2023-01-23 08:27:33,109 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74350, lr: 0.000485, loss: 0.0455 (0.0509)
2023-01-23 08:27:52,287 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74400, lr: 0.000485, loss: 0.0459 (0.0509)
2023-01-23 08:28:11,509 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74450, lr: 0.000485, loss: 0.0440 (0.0509)
2023-01-23 08:28:30,760 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74500, lr: 0.000485, loss: 0.0462 (0.0509)
2023-01-23 08:28:49,937 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74550, lr: 0.000485, loss: 0.0447 (0.0509)
2023-01-23 08:29:09,108 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74600, lr: 0.000485, loss: 0.0418 (0.0509)
2023-01-23 08:29:28,304 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74650, lr: 0.000485, loss: 0.0451 (0.0509)
2023-01-23 08:29:47,475 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74700, lr: 0.000485, loss: 0.0454 (0.0509)
2023-01-23 08:30:06,665 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74750, lr: 0.000485, loss: 0.0445 (0.0509)
2023-01-23 08:30:25,891 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74800, lr: 0.000485, loss: 0.0409 (0.0509)
2023-01-23 08:30:44,987 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74850, lr: 0.000485, loss: 0.0464 (0.0509)
2023-01-23 08:31:04,205 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74900, lr: 0.000485, loss: 0.0471 (0.0509)
2023-01-23 08:31:23,437 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 74950, lr: 0.000485, loss: 0.0444 (0.0509)
2023-01-23 08:31:42,510 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75000, lr: 0.000485, loss: 0.0460 (0.0509)
2023-01-23 08:32:01,749 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75050, lr: 0.000485, loss: 0.0437 (0.0509)
2023-01-23 08:32:21,025 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75100, lr: 0.000484, loss: 0.0481 (0.0509)
2023-01-23 08:32:40,293 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75150, lr: 0.000484, loss: 0.0430 (0.0509)
2023-01-23 08:32:59,362 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75200, lr: 0.000484, loss: 0.0431 (0.0509)
2023-01-23 08:33:18,512 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75250, lr: 0.000484, loss: 0.0429 (0.0509)
2023-01-23 08:33:37,671 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75300, lr: 0.000484, loss: 0.0473 (0.0509)
2023-01-23 08:33:56,850 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75350, lr: 0.000484, loss: 0.0462 (0.0509)
2023-01-23 08:34:16,054 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75400, lr: 0.000484, loss: 0.0445 (0.0509)
2023-01-23 08:34:35,277 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75450, lr: 0.000484, loss: 0.0455 (0.0509)
2023-01-23 08:34:54,424 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75500, lr: 0.000484, loss: 0.0421 (0.0508)
2023-01-23 08:35:13,588 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75550, lr: 0.000484, loss: 0.0474 (0.0508)
2023-01-23 08:35:32,702 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75600, lr: 0.000484, loss: 0.0496 (0.0508)
2023-01-23 08:35:51,811 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75650, lr: 0.000484, loss: 0.0467 (0.0508)
2023-01-23 08:36:10,910 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75700, lr: 0.000484, loss: 0.0433 (0.0508)
2023-01-23 08:36:30,106 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75750, lr: 0.000484, loss: 0.0435 (0.0508)
2023-01-23 08:36:49,225 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75800, lr: 0.000484, loss: 0.0478 (0.0508)
2023-01-23 08:37:08,311 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75850, lr: 0.000483, loss: 0.0450 (0.0508)
2023-01-23 08:37:27,399 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75900, lr: 0.000483, loss: 0.0481 (0.0508)
2023-01-23 08:37:46,499 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 75950, lr: 0.000483, loss: 0.0452 (0.0508)
2023-01-23 08:38:05,552 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76000, lr: 0.000483, loss: 0.0429 (0.0508)
2023-01-23 08:38:24,707 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76050, lr: 0.000483, loss: 0.0451 (0.0508)
2023-01-23 08:38:43,835 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76100, lr: 0.000483, loss: 0.0485 (0.0508)
2023-01-23 08:39:03,036 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76150, lr: 0.000483, loss: 0.0458 (0.0508)
2023-01-23 08:39:22,153 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76200, lr: 0.000483, loss: 0.0440 (0.0508)
2023-01-23 08:39:41,378 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76250, lr: 0.000483, loss: 0.0461 (0.0508)
2023-01-23 08:40:00,511 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76300, lr: 0.000483, loss: 0.0449 (0.0508)
2023-01-23 08:40:19,490 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76350, lr: 0.000483, loss: 0.0464 (0.0508)
2023-01-23 08:40:38,595 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76400, lr: 0.000483, loss: 0.0459 (0.0508)
2023-01-23 08:40:57,667 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76450, lr: 0.000483, loss: 0.0429 (0.0508)
2023-01-23 08:41:16,803 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76500, lr: 0.000483, loss: 0.0454 (0.0508)
2023-01-23 08:41:35,873 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76550, lr: 0.000483, loss: 0.0446 (0.0508)
2023-01-23 08:41:54,984 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76600, lr: 0.000482, loss: 0.0447 (0.0508)
2023-01-23 08:42:14,144 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76650, lr: 0.000482, loss: 0.0475 (0.0508)
2023-01-23 08:42:33,204 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76700, lr: 0.000482, loss: 0.0450 (0.0508)
2023-01-23 08:42:52,298 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76750, lr: 0.000482, loss: 0.0441 (0.0508)
2023-01-23 08:43:11,382 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76800, lr: 0.000482, loss: 0.0452 (0.0508)
2023-01-23 08:43:30,558 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76850, lr: 0.000482, loss: 0.0460 (0.0507)
2023-01-23 08:43:49,604 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76900, lr: 0.000482, loss: 0.0452 (0.0507)
2023-01-23 08:44:08,654 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 76950, lr: 0.000482, loss: 0.0446 (0.0507)
2023-01-23 08:44:27,789 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77000, lr: 0.000482, loss: 0.0443 (0.0507)
2023-01-23 08:44:46,921 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77050, lr: 0.000482, loss: 0.0485 (0.0507)
2023-01-23 08:45:06,047 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77100, lr: 0.000482, loss: 0.0440 (0.0507)
2023-01-23 08:45:25,104 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77150, lr: 0.000482, loss: 0.0453 (0.0507)
2023-01-23 08:45:44,204 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77200, lr: 0.000482, loss: 0.0438 (0.0507)
2023-01-23 08:46:03,249 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77250, lr: 0.000482, loss: 0.0458 (0.0507)
2023-01-23 08:46:22,307 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77300, lr: 0.000481, loss: 0.0436 (0.0507)
2023-01-23 08:46:41,409 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77350, lr: 0.000481, loss: 0.0466 (0.0507)
2023-01-23 08:47:00,459 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77400, lr: 0.000481, loss: 0.0469 (0.0507)
2023-01-23 08:47:19,378 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77450, lr: 0.000481, loss: 0.0430 (0.0507)
2023-01-23 08:47:38,635 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77500, lr: 0.000481, loss: 0.0419 (0.0507)
2023-01-23 08:47:57,739 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77550, lr: 0.000481, loss: 0.0442 (0.0507)
2023-01-23 08:48:16,792 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77600, lr: 0.000481, loss: 0.0468 (0.0507)
2023-01-23 08:48:35,912 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77650, lr: 0.000481, loss: 0.0449 (0.0507)
2023-01-23 08:48:54,963 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77700, lr: 0.000481, loss: 0.0480 (0.0507)
2023-01-23 08:49:13,909 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77750, lr: 0.000481, loss: 0.0443 (0.0507)
2023-01-23 08:49:33,003 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77800, lr: 0.000481, loss: 0.0482 (0.0507)
2023-01-23 08:49:52,024 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77850, lr: 0.000481, loss: 0.0480 (0.0507)
2023-01-23 08:50:11,058 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77900, lr: 0.000481, loss: 0.0465 (0.0507)
2023-01-23 08:50:30,026 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 77950, lr: 0.000480, loss: 0.0471 (0.0507)
2023-01-23 08:50:49,168 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78000, lr: 0.000480, loss: 0.0465 (0.0507)
2023-01-23 08:51:08,103 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78050, lr: 0.000480, loss: 0.0456 (0.0507)
2023-01-23 08:51:27,123 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78100, lr: 0.000480, loss: 0.0465 (0.0507)
2023-01-23 08:51:46,181 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78150, lr: 0.000480, loss: 0.0468 (0.0507)
2023-01-23 08:52:05,231 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78200, lr: 0.000480, loss: 0.0446 (0.0507)
2023-01-23 08:52:24,208 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78250, lr: 0.000480, loss: 0.0468 (0.0507)
2023-01-23 08:52:43,257 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78300, lr: 0.000480, loss: 0.0456 (0.0506)
2023-01-23 08:53:02,231 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78350, lr: 0.000480, loss: 0.0475 (0.0506)
2023-01-23 08:53:21,302 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78400, lr: 0.000480, loss: 0.0432 (0.0506)
2023-01-23 08:53:40,305 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78450, lr: 0.000480, loss: 0.0441 (0.0506)
2023-01-23 08:53:59,287 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78500, lr: 0.000480, loss: 0.0420 (0.0506)
2023-01-23 08:54:18,239 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78550, lr: 0.000480, loss: 0.0415 (0.0506)
2023-01-23 08:54:37,144 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78600, lr: 0.000480, loss: 0.0487 (0.0506)
2023-01-23 08:54:56,149 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78650, lr: 0.000479, loss: 0.0433 (0.0506)
2023-01-23 08:55:15,229 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78700, lr: 0.000479, loss: 0.0466 (0.0506)
2023-01-23 08:55:34,146 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78750, lr: 0.000479, loss: 0.0426 (0.0506)
2023-01-23 08:55:53,176 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78800, lr: 0.000479, loss: 0.0412 (0.0506)
2023-01-23 08:56:12,167 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78850, lr: 0.000479, loss: 0.0437 (0.0506)
2023-01-23 08:56:31,221 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78900, lr: 0.000479, loss: 0.0453 (0.0506)
2023-01-23 08:56:50,204 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 78950, lr: 0.000479, loss: 0.0517 (0.0506)
2023-01-23 08:57:09,281 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79000, lr: 0.000479, loss: 0.0457 (0.0506)
2023-01-23 08:57:28,385 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79050, lr: 0.000479, loss: 0.0457 (0.0506)
2023-01-23 08:57:47,604 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79100, lr: 0.000479, loss: 0.0492 (0.0506)
2023-01-23 08:58:06,831 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79150, lr: 0.000479, loss: 0.0452 (0.0506)
2023-01-23 08:58:26,077 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79200, lr: 0.000479, loss: 0.0411 (0.0506)
2023-01-23 08:58:45,315 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79250, lr: 0.000479, loss: 0.0450 (0.0506)
2023-01-23 08:59:04,723 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79300, lr: 0.000478, loss: 0.0443 (0.0506)
2023-01-23 08:59:24,072 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79350, lr: 0.000478, loss: 0.0441 (0.0506)
2023-01-23 08:59:43,444 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79400, lr: 0.000478, loss: 0.0452 (0.0506)
2023-01-23 09:00:02,920 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79450, lr: 0.000478, loss: 0.0444 (0.0506)
2023-01-23 09:00:22,364 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79500, lr: 0.000478, loss: 0.0452 (0.0506)
2023-01-23 09:00:41,887 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79550, lr: 0.000478, loss: 0.0439 (0.0506)
2023-01-23 09:01:01,484 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79600, lr: 0.000478, loss: 0.0449 (0.0506)
2023-01-23 09:01:21,121 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79650, lr: 0.000478, loss: 0.0456 (0.0506)
2023-01-23 09:01:40,703 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79700, lr: 0.000478, loss: 0.0467 (0.0506)
2023-01-23 09:02:00,516 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79750, lr: 0.000478, loss: 0.0467 (0.0505)
2023-01-23 09:02:20,105 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79800, lr: 0.000478, loss: 0.0487 (0.0505)
2023-01-23 09:02:39,697 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79850, lr: 0.000478, loss: 0.0476 (0.0505)
2023-01-23 09:02:59,415 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79900, lr: 0.000478, loss: 0.0470 (0.0505)
2023-01-23 09:03:19,086 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 79950, lr: 0.000477, loss: 0.0464 (0.0505)
2023-01-23 09:03:38,743 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80000, lr: 0.000477, loss: 0.0461 (0.0505)
2023-01-23 09:03:40,170 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_10_80000.pt
2023-01-23 09:03:59,628 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80050, lr: 0.000477, loss: 0.0464 (0.0505)
2023-01-23 09:04:19,487 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80100, lr: 0.000477, loss: 0.0477 (0.0505)
2023-01-23 09:04:39,410 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80150, lr: 0.000477, loss: 0.0444 (0.0505)
2023-01-23 09:04:59,273 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80200, lr: 0.000477, loss: 0.0450 (0.0505)
2023-01-23 09:05:19,150 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80250, lr: 0.000477, loss: 0.0437 (0.0505)
2023-01-23 09:05:39,055 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80300, lr: 0.000477, loss: 0.0440 (0.0505)
2023-01-23 09:05:58,937 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80350, lr: 0.000477, loss: 0.0431 (0.0505)
2023-01-23 09:06:18,728 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80400, lr: 0.000477, loss: 0.0471 (0.0505)
2023-01-23 09:06:38,508 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80450, lr: 0.000477, loss: 0.0432 (0.0505)
2023-01-23 09:06:58,147 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80500, lr: 0.000477, loss: 0.0432 (0.0505)
2023-01-23 09:07:17,925 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80550, lr: 0.000476, loss: 0.0476 (0.0505)
2023-01-23 09:07:37,641 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80600, lr: 0.000476, loss: 0.0445 (0.0505)
2023-01-23 09:07:57,297 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80650, lr: 0.000476, loss: 0.0505 (0.0505)
2023-01-23 09:08:16,991 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80700, lr: 0.000476, loss: 0.0423 (0.0505)
2023-01-23 09:08:36,694 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80750, lr: 0.000476, loss: 0.0432 (0.0505)
2023-01-23 09:08:56,397 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80800, lr: 0.000476, loss: 0.0454 (0.0505)
2023-01-23 09:09:16,029 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80850, lr: 0.000476, loss: 0.0436 (0.0505)
2023-01-23 09:09:35,640 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80900, lr: 0.000476, loss: 0.0503 (0.0505)
2023-01-23 09:09:55,218 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 80950, lr: 0.000476, loss: 0.0460 (0.0505)
2023-01-23 09:10:14,888 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 81000, lr: 0.000476, loss: 0.0459 (0.0505)
2023-01-23 09:10:34,503 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 81050, lr: 0.000476, loss: 0.0445 (0.0505)
2023-01-23 09:10:54,098 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 81100, lr: 0.000476, loss: 0.0433 (0.0505)
2023-01-23 09:11:13,727 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 81150, lr: 0.000476, loss: 0.0432 (0.0505)
2023-01-23 09:11:33,400 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 81200, lr: 0.000475, loss: 0.0446 (0.0505)
2023-01-23 09:11:52,989 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 81250, lr: 0.000475, loss: 0.0456 (0.0504)
2023-01-23 09:12:12,494 CLIP_COCO_TRAIN INFO: Epoch: 10, global_step: 81300, lr: 0.000475, loss: 0.0496 (0.0504)
2023-01-23 09:12:31,725 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81350, lr: 0.000475, loss: 0.0479 (0.0504)
2023-01-23 09:12:50,890 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81400, lr: 0.000475, loss: 0.0450 (0.0504)
2023-01-23 09:13:10,131 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81450, lr: 0.000475, loss: 0.0452 (0.0504)
2023-01-23 09:13:29,335 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81500, lr: 0.000475, loss: 0.0421 (0.0504)
2023-01-23 09:13:48,561 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81550, lr: 0.000475, loss: 0.0456 (0.0504)
2023-01-23 09:14:07,792 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81600, lr: 0.000475, loss: 0.0439 (0.0504)
2023-01-23 09:14:26,939 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81650, lr: 0.000475, loss: 0.0447 (0.0504)
2023-01-23 09:14:46,127 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81700, lr: 0.000475, loss: 0.0438 (0.0504)
2023-01-23 09:15:05,304 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81750, lr: 0.000475, loss: 0.0417 (0.0504)
2023-01-23 09:15:24,409 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81800, lr: 0.000474, loss: 0.0475 (0.0504)
2023-01-23 09:15:43,508 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81850, lr: 0.000474, loss: 0.0443 (0.0504)
2023-01-23 09:16:02,642 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81900, lr: 0.000474, loss: 0.0481 (0.0504)
2023-01-23 09:16:21,764 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 81950, lr: 0.000474, loss: 0.0429 (0.0504)
2023-01-23 09:16:40,869 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82000, lr: 0.000474, loss: 0.0465 (0.0504)
2023-01-23 09:16:59,936 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82050, lr: 0.000474, loss: 0.0452 (0.0504)
2023-01-23 09:17:19,092 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82100, lr: 0.000474, loss: 0.0438 (0.0504)
2023-01-23 09:17:38,215 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82150, lr: 0.000474, loss: 0.0444 (0.0504)
2023-01-23 09:17:57,346 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82200, lr: 0.000474, loss: 0.0463 (0.0504)
2023-01-23 09:18:16,417 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82250, lr: 0.000474, loss: 0.0450 (0.0504)
2023-01-23 09:18:35,668 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82300, lr: 0.000474, loss: 0.0460 (0.0504)
2023-01-23 09:18:54,790 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82350, lr: 0.000474, loss: 0.0432 (0.0504)
2023-01-23 09:19:13,875 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82400, lr: 0.000473, loss: 0.0466 (0.0504)
2023-01-23 09:19:32,929 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82450, lr: 0.000473, loss: 0.0475 (0.0504)
2023-01-23 09:19:52,087 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82500, lr: 0.000473, loss: 0.0444 (0.0504)
2023-01-23 09:20:11,084 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82550, lr: 0.000473, loss: 0.0432 (0.0504)
2023-01-23 09:20:30,402 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82600, lr: 0.000473, loss: 0.0464 (0.0504)
2023-01-23 09:20:49,582 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82650, lr: 0.000473, loss: 0.0435 (0.0504)
2023-01-23 09:21:08,740 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82700, lr: 0.000473, loss: 0.0462 (0.0504)
2023-01-23 09:21:27,807 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82750, lr: 0.000473, loss: 0.0464 (0.0504)
2023-01-23 09:21:46,866 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82800, lr: 0.000473, loss: 0.0447 (0.0503)
2023-01-23 09:22:05,973 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82850, lr: 0.000473, loss: 0.0464 (0.0503)
2023-01-23 09:22:24,935 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82900, lr: 0.000473, loss: 0.0451 (0.0503)
2023-01-23 09:22:43,990 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 82950, lr: 0.000472, loss: 0.0469 (0.0503)
2023-01-23 09:23:03,114 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83000, lr: 0.000472, loss: 0.0431 (0.0503)
2023-01-23 09:23:22,191 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83050, lr: 0.000472, loss: 0.0445 (0.0503)
2023-01-23 09:23:41,234 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83100, lr: 0.000472, loss: 0.0465 (0.0503)
2023-01-23 09:24:00,283 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83150, lr: 0.000472, loss: 0.0449 (0.0503)
2023-01-23 09:24:19,355 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83200, lr: 0.000472, loss: 0.0428 (0.0503)
2023-01-23 09:24:38,446 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83250, lr: 0.000472, loss: 0.0454 (0.0503)
2023-01-23 09:24:57,491 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83300, lr: 0.000472, loss: 0.0452 (0.0503)
2023-01-23 09:25:16,507 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83350, lr: 0.000472, loss: 0.0478 (0.0503)
2023-01-23 09:25:35,512 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83400, lr: 0.000472, loss: 0.0482 (0.0503)
2023-01-23 09:25:54,475 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83450, lr: 0.000472, loss: 0.0428 (0.0503)
2023-01-23 09:26:13,575 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83500, lr: 0.000472, loss: 0.0457 (0.0503)
2023-01-23 09:26:32,522 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83550, lr: 0.000471, loss: 0.0483 (0.0503)
2023-01-23 09:26:51,563 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83600, lr: 0.000471, loss: 0.0462 (0.0503)
2023-01-23 09:27:10,543 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83650, lr: 0.000471, loss: 0.0463 (0.0503)
2023-01-23 09:27:29,503 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83700, lr: 0.000471, loss: 0.0467 (0.0503)
2023-01-23 09:27:48,673 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83750, lr: 0.000471, loss: 0.0467 (0.0503)
2023-01-23 09:28:07,651 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83800, lr: 0.000471, loss: 0.0468 (0.0503)
2023-01-23 09:28:26,645 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83850, lr: 0.000471, loss: 0.0477 (0.0503)
2023-01-23 09:28:45,588 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83900, lr: 0.000471, loss: 0.0468 (0.0503)
2023-01-23 09:29:04,629 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 83950, lr: 0.000471, loss: 0.0440 (0.0503)
2023-01-23 09:29:23,681 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84000, lr: 0.000471, loss: 0.0468 (0.0503)
2023-01-23 09:29:42,528 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84050, lr: 0.000471, loss: 0.0465 (0.0503)
2023-01-23 09:30:01,552 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84100, lr: 0.000470, loss: 0.0446 (0.0503)
2023-01-23 09:30:20,572 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84150, lr: 0.000470, loss: 0.0471 (0.0503)
2023-01-23 09:30:39,641 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84200, lr: 0.000470, loss: 0.0439 (0.0503)
2023-01-23 09:30:58,680 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84250, lr: 0.000470, loss: 0.0466 (0.0503)
2023-01-23 09:31:17,808 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84300, lr: 0.000470, loss: 0.0418 (0.0503)
2023-01-23 09:31:36,932 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84350, lr: 0.000470, loss: 0.0466 (0.0503)
2023-01-23 09:31:56,010 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84400, lr: 0.000470, loss: 0.0464 (0.0502)
2023-01-23 09:32:15,013 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84450, lr: 0.000470, loss: 0.0467 (0.0502)
2023-01-23 09:32:34,011 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84500, lr: 0.000470, loss: 0.0433 (0.0502)
2023-01-23 09:32:53,102 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84550, lr: 0.000470, loss: 0.0481 (0.0502)
2023-01-23 09:33:12,120 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84600, lr: 0.000470, loss: 0.0434 (0.0502)
2023-01-23 09:33:31,199 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84650, lr: 0.000469, loss: 0.0454 (0.0502)
2023-01-23 09:33:50,199 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84700, lr: 0.000469, loss: 0.0462 (0.0502)
2023-01-23 09:34:09,174 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84750, lr: 0.000469, loss: 0.0480 (0.0502)
2023-01-23 09:34:28,223 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84800, lr: 0.000469, loss: 0.0443 (0.0502)
2023-01-23 09:34:47,460 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84850, lr: 0.000469, loss: 0.0420 (0.0502)
2023-01-23 09:35:06,450 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84900, lr: 0.000469, loss: 0.0452 (0.0502)
2023-01-23 09:35:25,329 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 84950, lr: 0.000469, loss: 0.0458 (0.0502)
2023-01-23 09:35:44,213 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85000, lr: 0.000469, loss: 0.0462 (0.0502)
2023-01-23 09:36:03,231 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85050, lr: 0.000469, loss: 0.0463 (0.0502)
2023-01-23 09:36:22,275 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85100, lr: 0.000469, loss: 0.0465 (0.0502)
2023-01-23 09:36:41,330 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85150, lr: 0.000469, loss: 0.0462 (0.0502)
2023-01-23 09:37:00,355 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85200, lr: 0.000468, loss: 0.0467 (0.0502)
2023-01-23 09:37:19,325 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85250, lr: 0.000468, loss: 0.0462 (0.0502)
2023-01-23 09:37:38,378 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85300, lr: 0.000468, loss: 0.0441 (0.0502)
2023-01-23 09:37:57,295 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85350, lr: 0.000468, loss: 0.0446 (0.0502)
2023-01-23 09:38:16,301 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85400, lr: 0.000468, loss: 0.0449 (0.0502)
2023-01-23 09:38:35,407 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85450, lr: 0.000468, loss: 0.0449 (0.0502)
2023-01-23 09:38:54,376 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85500, lr: 0.000468, loss: 0.0449 (0.0502)
2023-01-23 09:39:13,532 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85550, lr: 0.000468, loss: 0.0430 (0.0502)
2023-01-23 09:39:32,661 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85600, lr: 0.000468, loss: 0.0470 (0.0502)
2023-01-23 09:39:51,781 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85650, lr: 0.000468, loss: 0.0418 (0.0502)
2023-01-23 09:40:10,886 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85700, lr: 0.000468, loss: 0.0465 (0.0502)
2023-01-23 09:40:29,975 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85750, lr: 0.000467, loss: 0.0478 (0.0502)
2023-01-23 09:40:49,300 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85800, lr: 0.000467, loss: 0.0454 (0.0502)
2023-01-23 09:41:08,587 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85850, lr: 0.000467, loss: 0.0435 (0.0502)
2023-01-23 09:41:28,022 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85900, lr: 0.000467, loss: 0.0436 (0.0502)
2023-01-23 09:41:47,479 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 85950, lr: 0.000467, loss: 0.0486 (0.0502)
2023-01-23 09:42:06,887 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86000, lr: 0.000467, loss: 0.0460 (0.0502)
2023-01-23 09:42:26,376 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86050, lr: 0.000467, loss: 0.0471 (0.0501)
2023-01-23 09:42:45,863 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86100, lr: 0.000467, loss: 0.0475 (0.0501)
2023-01-23 09:43:05,297 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86150, lr: 0.000467, loss: 0.0466 (0.0501)
2023-01-23 09:43:24,995 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86200, lr: 0.000467, loss: 0.0409 (0.0501)
2023-01-23 09:43:44,460 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86250, lr: 0.000467, loss: 0.0438 (0.0501)
2023-01-23 09:44:04,074 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86300, lr: 0.000466, loss: 0.0444 (0.0501)
2023-01-23 09:44:23,673 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86350, lr: 0.000466, loss: 0.0468 (0.0501)
2023-01-23 09:44:43,245 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86400, lr: 0.000466, loss: 0.0434 (0.0501)
2023-01-23 09:45:02,856 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86450, lr: 0.000466, loss: 0.0430 (0.0501)
2023-01-23 09:45:22,358 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86500, lr: 0.000466, loss: 0.0469 (0.0501)
2023-01-23 09:45:41,969 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86550, lr: 0.000466, loss: 0.0419 (0.0501)
2023-01-23 09:46:01,483 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86600, lr: 0.000466, loss: 0.0475 (0.0501)
2023-01-23 09:46:21,051 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86650, lr: 0.000466, loss: 0.0458 (0.0501)
2023-01-23 09:46:40,711 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86700, lr: 0.000466, loss: 0.0445 (0.0501)
2023-01-23 09:47:00,235 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86750, lr: 0.000466, loss: 0.0469 (0.0501)
2023-01-23 09:47:19,773 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86800, lr: 0.000465, loss: 0.0452 (0.0501)
2023-01-23 09:47:39,263 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86850, lr: 0.000465, loss: 0.0443 (0.0501)
2023-01-23 09:47:58,765 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86900, lr: 0.000465, loss: 0.0455 (0.0501)
2023-01-23 09:48:18,207 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 86950, lr: 0.000465, loss: 0.0444 (0.0501)
2023-01-23 09:48:37,663 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87000, lr: 0.000465, loss: 0.0429 (0.0501)
2023-01-23 09:48:57,034 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87050, lr: 0.000465, loss: 0.0398 (0.0501)
2023-01-23 09:49:16,491 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87100, lr: 0.000465, loss: 0.0433 (0.0501)
2023-01-23 09:49:35,904 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87150, lr: 0.000465, loss: 0.0460 (0.0501)
2023-01-23 09:49:55,374 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87200, lr: 0.000465, loss: 0.0458 (0.0501)
2023-01-23 09:50:14,961 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87250, lr: 0.000465, loss: 0.0469 (0.0501)
2023-01-23 09:50:34,261 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87300, lr: 0.000464, loss: 0.0430 (0.0501)
2023-01-23 09:50:53,674 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87350, lr: 0.000464, loss: 0.0450 (0.0501)
2023-01-23 09:51:13,114 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87400, lr: 0.000464, loss: 0.0444 (0.0501)
2023-01-23 09:51:32,507 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87450, lr: 0.000464, loss: 0.0465 (0.0501)
2023-01-23 09:51:51,860 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87500, lr: 0.000464, loss: 0.0456 (0.0501)
2023-01-23 09:52:11,230 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87550, lr: 0.000464, loss: 0.0446 (0.0501)
2023-01-23 09:52:30,475 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87600, lr: 0.000464, loss: 0.0432 (0.0501)
2023-01-23 09:52:49,917 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87650, lr: 0.000464, loss: 0.0433 (0.0501)
2023-01-23 09:53:09,200 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87700, lr: 0.000464, loss: 0.0452 (0.0500)
2023-01-23 09:53:28,536 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87750, lr: 0.000464, loss: 0.0435 (0.0500)
2023-01-23 09:53:47,995 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87800, lr: 0.000464, loss: 0.0426 (0.0500)
2023-01-23 09:54:07,287 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87850, lr: 0.000463, loss: 0.0473 (0.0500)
2023-01-23 09:54:26,559 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87900, lr: 0.000463, loss: 0.0432 (0.0500)
2023-01-23 09:54:45,938 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 87950, lr: 0.000463, loss: 0.0429 (0.0500)
2023-01-23 09:55:05,131 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88000, lr: 0.000463, loss: 0.0488 (0.0500)
2023-01-23 09:55:24,475 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88050, lr: 0.000463, loss: 0.0450 (0.0500)
2023-01-23 09:55:43,771 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88100, lr: 0.000463, loss: 0.0464 (0.0500)
2023-01-23 09:56:03,142 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88150, lr: 0.000463, loss: 0.0465 (0.0500)
2023-01-23 09:56:22,373 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88200, lr: 0.000463, loss: 0.0477 (0.0500)
2023-01-23 09:56:41,673 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88250, lr: 0.000463, loss: 0.0414 (0.0500)
2023-01-23 09:57:00,962 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88300, lr: 0.000463, loss: 0.0451 (0.0500)
2023-01-23 09:57:20,144 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88350, lr: 0.000462, loss: 0.0449 (0.0500)
2023-01-23 09:57:39,398 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88400, lr: 0.000462, loss: 0.0446 (0.0500)
2023-01-23 09:57:58,682 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88450, lr: 0.000462, loss: 0.0456 (0.0500)
2023-01-23 09:58:17,903 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88500, lr: 0.000462, loss: 0.0464 (0.0500)
2023-01-23 09:58:37,156 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88550, lr: 0.000462, loss: 0.0439 (0.0500)
2023-01-23 09:58:56,488 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88600, lr: 0.000462, loss: 0.0442 (0.0500)
2023-01-23 09:59:15,711 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88650, lr: 0.000462, loss: 0.0454 (0.0500)
2023-01-23 09:59:34,917 CLIP_COCO_TRAIN INFO: Epoch: 11, global_step: 88700, lr: 0.000462, loss: 0.0449 (0.0500)
2023-01-23 09:59:54,049 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 88750, lr: 0.000462, loss: 0.0466 (0.0500)
2023-01-23 10:00:13,105 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 88800, lr: 0.000462, loss: 0.0436 (0.0500)
2023-01-23 10:00:32,196 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 88850, lr: 0.000461, loss: 0.0432 (0.0500)
2023-01-23 10:00:51,315 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 88900, lr: 0.000461, loss: 0.0454 (0.0500)
2023-01-23 10:01:10,562 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 88950, lr: 0.000461, loss: 0.0440 (0.0500)
2023-01-23 10:01:29,571 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89000, lr: 0.000461, loss: 0.0473 (0.0500)
2023-01-23 10:01:48,659 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89050, lr: 0.000461, loss: 0.0457 (0.0500)
2023-01-23 10:02:07,765 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89100, lr: 0.000461, loss: 0.0459 (0.0500)
2023-01-23 10:02:26,742 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89150, lr: 0.000461, loss: 0.0466 (0.0500)
2023-01-23 10:02:45,839 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89200, lr: 0.000461, loss: 0.0429 (0.0500)
2023-01-23 10:03:04,936 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89250, lr: 0.000461, loss: 0.0436 (0.0500)
2023-01-23 10:03:23,977 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89300, lr: 0.000460, loss: 0.0440 (0.0500)
2023-01-23 10:03:43,097 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89350, lr: 0.000460, loss: 0.0418 (0.0500)
2023-01-23 10:04:02,116 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89400, lr: 0.000460, loss: 0.0478 (0.0499)
2023-01-23 10:04:21,221 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89450, lr: 0.000460, loss: 0.0467 (0.0499)
2023-01-23 10:04:40,248 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89500, lr: 0.000460, loss: 0.0450 (0.0499)
2023-01-23 10:04:59,553 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89550, lr: 0.000460, loss: 0.0439 (0.0499)
2023-01-23 10:05:18,942 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89600, lr: 0.000460, loss: 0.0465 (0.0499)
2023-01-23 10:05:38,234 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89650, lr: 0.000460, loss: 0.0434 (0.0499)
2023-01-23 10:05:57,686 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89700, lr: 0.000460, loss: 0.0460 (0.0499)
2023-01-23 10:06:16,960 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89750, lr: 0.000460, loss: 0.0462 (0.0499)
2023-01-23 10:06:36,236 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89800, lr: 0.000459, loss: 0.0422 (0.0499)
2023-01-23 10:06:55,582 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89850, lr: 0.000459, loss: 0.0422 (0.0499)
2023-01-23 10:07:14,833 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89900, lr: 0.000459, loss: 0.0433 (0.0499)
2023-01-23 10:07:34,007 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 89950, lr: 0.000459, loss: 0.0463 (0.0499)
2023-01-23 10:07:53,246 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90000, lr: 0.000459, loss: 0.0451 (0.0499)
2023-01-23 10:07:54,618 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_12_90000.pt
2023-01-23 10:08:13,666 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90050, lr: 0.000459, loss: 0.0458 (0.0499)
2023-01-23 10:08:32,972 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90100, lr: 0.000459, loss: 0.0428 (0.0499)
2023-01-23 10:08:52,241 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90150, lr: 0.000459, loss: 0.0452 (0.0499)
2023-01-23 10:09:11,518 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90200, lr: 0.000459, loss: 0.0448 (0.0499)
2023-01-23 10:09:30,775 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90250, lr: 0.000459, loss: 0.0431 (0.0499)
2023-01-23 10:09:50,021 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90300, lr: 0.000458, loss: 0.0466 (0.0499)
2023-01-23 10:10:09,190 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90350, lr: 0.000458, loss: 0.0417 (0.0499)
2023-01-23 10:10:28,448 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90400, lr: 0.000458, loss: 0.0429 (0.0499)
2023-01-23 10:10:47,744 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90450, lr: 0.000458, loss: 0.0433 (0.0499)
2023-01-23 10:11:07,038 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90500, lr: 0.000458, loss: 0.0470 (0.0499)
2023-01-23 10:11:26,249 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90550, lr: 0.000458, loss: 0.0425 (0.0499)
2023-01-23 10:11:45,562 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90600, lr: 0.000458, loss: 0.0425 (0.0499)
2023-01-23 10:12:04,871 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90650, lr: 0.000458, loss: 0.0443 (0.0499)
2023-01-23 10:12:24,133 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90700, lr: 0.000458, loss: 0.0423 (0.0499)
2023-01-23 10:12:43,399 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90750, lr: 0.000457, loss: 0.0470 (0.0499)
2023-01-23 10:13:02,573 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90800, lr: 0.000457, loss: 0.0423 (0.0499)
2023-01-23 10:13:21,832 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90850, lr: 0.000457, loss: 0.0427 (0.0499)
2023-01-23 10:13:40,895 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90900, lr: 0.000457, loss: 0.0445 (0.0499)
2023-01-23 10:14:00,180 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 90950, lr: 0.000457, loss: 0.0397 (0.0499)
2023-01-23 10:14:19,305 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91000, lr: 0.000457, loss: 0.0451 (0.0499)
2023-01-23 10:14:38,497 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91050, lr: 0.000457, loss: 0.0421 (0.0499)
2023-01-23 10:14:57,769 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91100, lr: 0.000457, loss: 0.0485 (0.0498)
2023-01-23 10:15:16,933 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91150, lr: 0.000457, loss: 0.0427 (0.0498)
2023-01-23 10:15:35,917 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91200, lr: 0.000457, loss: 0.0439 (0.0498)
2023-01-23 10:15:54,950 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91250, lr: 0.000456, loss: 0.0437 (0.0498)
2023-01-23 10:16:13,912 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91300, lr: 0.000456, loss: 0.0482 (0.0498)
2023-01-23 10:16:32,847 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91350, lr: 0.000456, loss: 0.0442 (0.0498)
2023-01-23 10:16:51,829 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91400, lr: 0.000456, loss: 0.0437 (0.0498)
2023-01-23 10:17:10,782 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91450, lr: 0.000456, loss: 0.0426 (0.0498)
2023-01-23 10:17:29,774 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91500, lr: 0.000456, loss: 0.0446 (0.0498)
2023-01-23 10:17:48,816 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91550, lr: 0.000456, loss: 0.0465 (0.0498)
2023-01-23 10:18:07,802 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91600, lr: 0.000456, loss: 0.0437 (0.0498)
2023-01-23 10:18:26,754 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91650, lr: 0.000456, loss: 0.0451 (0.0498)
2023-01-23 10:18:45,748 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91700, lr: 0.000455, loss: 0.0475 (0.0498)
2023-01-23 10:19:04,728 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91750, lr: 0.000455, loss: 0.0433 (0.0498)
2023-01-23 10:19:23,723 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91800, lr: 0.000455, loss: 0.0457 (0.0498)
2023-01-23 10:19:42,605 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91850, lr: 0.000455, loss: 0.0437 (0.0498)
2023-01-23 10:20:01,621 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91900, lr: 0.000455, loss: 0.0462 (0.0498)
2023-01-23 10:20:20,573 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 91950, lr: 0.000455, loss: 0.0458 (0.0498)
2023-01-23 10:20:39,611 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92000, lr: 0.000455, loss: 0.0453 (0.0498)
2023-01-23 10:20:58,666 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92050, lr: 0.000455, loss: 0.0427 (0.0498)
2023-01-23 10:21:17,728 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92100, lr: 0.000455, loss: 0.0464 (0.0498)
2023-01-23 10:21:36,805 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92150, lr: 0.000454, loss: 0.0467 (0.0498)
2023-01-23 10:21:55,856 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92200, lr: 0.000454, loss: 0.0439 (0.0498)
2023-01-23 10:22:15,145 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92250, lr: 0.000454, loss: 0.0419 (0.0498)
2023-01-23 10:22:34,408 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92300, lr: 0.000454, loss: 0.0458 (0.0498)
2023-01-23 10:22:53,641 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92350, lr: 0.000454, loss: 0.0458 (0.0498)
2023-01-23 10:23:12,857 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92400, lr: 0.000454, loss: 0.0421 (0.0498)
2023-01-23 10:23:32,145 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92450, lr: 0.000454, loss: 0.0430 (0.0498)
2023-01-23 10:23:51,658 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92500, lr: 0.000454, loss: 0.0455 (0.0498)
2023-01-23 10:24:11,083 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92550, lr: 0.000454, loss: 0.0450 (0.0498)
2023-01-23 10:24:30,560 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92600, lr: 0.000453, loss: 0.0458 (0.0498)
2023-01-23 10:24:50,002 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92650, lr: 0.000453, loss: 0.0446 (0.0498)
2023-01-23 10:25:09,420 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92700, lr: 0.000453, loss: 0.0432 (0.0498)
2023-01-23 10:25:28,897 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92750, lr: 0.000453, loss: 0.0439 (0.0498)
2023-01-23 10:25:48,444 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92800, lr: 0.000453, loss: 0.0429 (0.0498)
2023-01-23 10:26:07,903 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92850, lr: 0.000453, loss: 0.0404 (0.0498)
2023-01-23 10:26:27,407 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92900, lr: 0.000453, loss: 0.0446 (0.0497)
2023-01-23 10:26:46,965 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 92950, lr: 0.000453, loss: 0.0407 (0.0497)
2023-01-23 10:27:06,636 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93000, lr: 0.000453, loss: 0.0432 (0.0497)
2023-01-23 10:27:26,317 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93050, lr: 0.000452, loss: 0.0440 (0.0497)
2023-01-23 10:27:45,702 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93100, lr: 0.000452, loss: 0.0442 (0.0497)
2023-01-23 10:28:05,167 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93150, lr: 0.000452, loss: 0.0427 (0.0497)
2023-01-23 10:28:24,642 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93200, lr: 0.000452, loss: 0.0392 (0.0497)
2023-01-23 10:28:44,084 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93250, lr: 0.000452, loss: 0.0447 (0.0497)
2023-01-23 10:29:03,623 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93300, lr: 0.000452, loss: 0.0439 (0.0497)
2023-01-23 10:29:23,029 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93350, lr: 0.000452, loss: 0.0435 (0.0497)
2023-01-23 10:29:42,457 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93400, lr: 0.000452, loss: 0.0449 (0.0497)
2023-01-23 10:30:01,886 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93450, lr: 0.000452, loss: 0.0443 (0.0497)
2023-01-23 10:30:21,323 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93500, lr: 0.000451, loss: 0.0480 (0.0497)
2023-01-23 10:30:40,701 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93550, lr: 0.000451, loss: 0.0413 (0.0497)
2023-01-23 10:31:00,288 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93600, lr: 0.000451, loss: 0.0437 (0.0497)
2023-01-23 10:31:19,779 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93650, lr: 0.000451, loss: 0.0485 (0.0497)
2023-01-23 10:31:39,306 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93700, lr: 0.000451, loss: 0.0481 (0.0497)
2023-01-23 10:31:58,649 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93750, lr: 0.000451, loss: 0.0463 (0.0497)
2023-01-23 10:32:18,270 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93800, lr: 0.000451, loss: 0.0441 (0.0497)
2023-01-23 10:32:37,655 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93850, lr: 0.000451, loss: 0.0431 (0.0497)
2023-01-23 10:32:57,043 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93900, lr: 0.000451, loss: 0.0468 (0.0497)
2023-01-23 10:33:16,453 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 93950, lr: 0.000450, loss: 0.0443 (0.0497)
2023-01-23 10:33:35,716 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94000, lr: 0.000450, loss: 0.0434 (0.0497)
2023-01-23 10:33:55,007 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94050, lr: 0.000450, loss: 0.0446 (0.0497)
2023-01-23 10:34:14,358 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94100, lr: 0.000450, loss: 0.0447 (0.0497)
2023-01-23 10:34:33,819 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94150, lr: 0.000450, loss: 0.0441 (0.0497)
2023-01-23 10:34:53,100 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94200, lr: 0.000450, loss: 0.0418 (0.0497)
2023-01-23 10:35:12,494 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94250, lr: 0.000450, loss: 0.0450 (0.0497)
2023-01-23 10:35:31,804 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94300, lr: 0.000450, loss: 0.0446 (0.0497)
2023-01-23 10:35:51,135 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94350, lr: 0.000450, loss: 0.0460 (0.0497)
2023-01-23 10:36:10,575 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94400, lr: 0.000449, loss: 0.0440 (0.0497)
2023-01-23 10:36:29,821 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94450, lr: 0.000449, loss: 0.0439 (0.0497)
2023-01-23 10:36:49,042 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94500, lr: 0.000449, loss: 0.0441 (0.0497)
2023-01-23 10:37:08,402 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94550, lr: 0.000449, loss: 0.0458 (0.0497)
2023-01-23 10:37:27,706 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94600, lr: 0.000449, loss: 0.0437 (0.0497)
2023-01-23 10:37:46,950 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94650, lr: 0.000449, loss: 0.0468 (0.0497)
2023-01-23 10:38:06,157 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94700, lr: 0.000449, loss: 0.0463 (0.0497)
2023-01-23 10:38:25,485 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94750, lr: 0.000449, loss: 0.0471 (0.0496)
2023-01-23 10:38:44,763 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94800, lr: 0.000449, loss: 0.0441 (0.0496)
2023-01-23 10:39:04,110 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94850, lr: 0.000448, loss: 0.0452 (0.0496)
2023-01-23 10:39:23,445 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94900, lr: 0.000448, loss: 0.0466 (0.0496)
2023-01-23 10:39:42,649 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 94950, lr: 0.000448, loss: 0.0438 (0.0496)
2023-01-23 10:40:01,963 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95000, lr: 0.000448, loss: 0.0450 (0.0496)
2023-01-23 10:40:21,161 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95050, lr: 0.000448, loss: 0.0448 (0.0496)
2023-01-23 10:40:40,487 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95100, lr: 0.000448, loss: 0.0455 (0.0496)
2023-01-23 10:40:59,780 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95150, lr: 0.000448, loss: 0.0462 (0.0496)
2023-01-23 10:41:19,001 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95200, lr: 0.000448, loss: 0.0439 (0.0496)
2023-01-23 10:41:38,282 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95250, lr: 0.000447, loss: 0.0480 (0.0496)
2023-01-23 10:41:57,466 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95300, lr: 0.000447, loss: 0.0447 (0.0496)
2023-01-23 10:42:16,706 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95350, lr: 0.000447, loss: 0.0438 (0.0496)
2023-01-23 10:42:36,008 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95400, lr: 0.000447, loss: 0.0446 (0.0496)
2023-01-23 10:42:55,198 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95450, lr: 0.000447, loss: 0.0446 (0.0496)
2023-01-23 10:43:14,471 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95500, lr: 0.000447, loss: 0.0474 (0.0496)
2023-01-23 10:43:33,652 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95550, lr: 0.000447, loss: 0.0499 (0.0496)
2023-01-23 10:43:52,811 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95600, lr: 0.000447, loss: 0.0475 (0.0496)
2023-01-23 10:44:12,029 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95650, lr: 0.000447, loss: 0.0450 (0.0496)
2023-01-23 10:44:31,095 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95700, lr: 0.000446, loss: 0.0425 (0.0496)
2023-01-23 10:44:50,272 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95750, lr: 0.000446, loss: 0.0456 (0.0496)
2023-01-23 10:45:09,444 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95800, lr: 0.000446, loss: 0.0429 (0.0496)
2023-01-23 10:45:28,567 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95850, lr: 0.000446, loss: 0.0419 (0.0496)
2023-01-23 10:45:47,742 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95900, lr: 0.000446, loss: 0.0433 (0.0496)
2023-01-23 10:46:07,014 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 95950, lr: 0.000446, loss: 0.0458 (0.0496)
2023-01-23 10:46:26,364 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 96000, lr: 0.000446, loss: 0.0435 (0.0496)
2023-01-23 10:46:45,489 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 96050, lr: 0.000446, loss: 0.0442 (0.0496)
2023-01-23 10:47:04,804 CLIP_COCO_TRAIN INFO: Epoch: 12, global_step: 96100, lr: 0.000445, loss: 0.0479 (0.0496)
2023-01-23 10:47:23,843 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96150, lr: 0.000445, loss: 0.0462 (0.0496)
2023-01-23 10:47:42,935 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96200, lr: 0.000445, loss: 0.0463 (0.0496)
2023-01-23 10:48:01,839 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96250, lr: 0.000445, loss: 0.0443 (0.0496)
2023-01-23 10:48:20,896 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96300, lr: 0.000445, loss: 0.0466 (0.0496)
2023-01-23 10:48:39,897 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96350, lr: 0.000445, loss: 0.0423 (0.0496)
2023-01-23 10:48:58,969 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96400, lr: 0.000445, loss: 0.0447 (0.0496)
2023-01-23 10:49:17,944 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96450, lr: 0.000445, loss: 0.0432 (0.0496)
2023-01-23 10:49:37,078 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96500, lr: 0.000445, loss: 0.0424 (0.0496)
2023-01-23 10:49:56,135 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96550, lr: 0.000444, loss: 0.0442 (0.0496)
2023-01-23 10:50:15,155 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96600, lr: 0.000444, loss: 0.0426 (0.0496)
2023-01-23 10:50:34,212 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96650, lr: 0.000444, loss: 0.0442 (0.0495)
2023-01-23 10:50:53,397 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96700, lr: 0.000444, loss: 0.0474 (0.0495)
2023-01-23 10:51:12,415 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96750, lr: 0.000444, loss: 0.0466 (0.0495)
2023-01-23 10:51:31,468 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96800, lr: 0.000444, loss: 0.0476 (0.0495)
2023-01-23 10:51:50,486 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96850, lr: 0.000444, loss: 0.0455 (0.0495)
2023-01-23 10:52:09,447 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96900, lr: 0.000444, loss: 0.0422 (0.0495)
2023-01-23 10:52:28,458 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 96950, lr: 0.000443, loss: 0.0449 (0.0495)
2023-01-23 10:52:47,488 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97000, lr: 0.000443, loss: 0.0436 (0.0495)
2023-01-23 10:53:06,523 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97050, lr: 0.000443, loss: 0.0447 (0.0495)
2023-01-23 10:53:25,557 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97100, lr: 0.000443, loss: 0.0425 (0.0495)
2023-01-23 10:53:44,457 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97150, lr: 0.000443, loss: 0.0481 (0.0495)
2023-01-23 10:54:03,432 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97200, lr: 0.000443, loss: 0.0422 (0.0495)
2023-01-23 10:54:22,316 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97250, lr: 0.000443, loss: 0.0494 (0.0495)
2023-01-23 10:54:41,327 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97300, lr: 0.000443, loss: 0.0451 (0.0495)
2023-01-23 10:55:00,346 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97350, lr: 0.000442, loss: 0.0402 (0.0495)
2023-01-23 10:55:19,277 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97400, lr: 0.000442, loss: 0.0451 (0.0495)
2023-01-23 10:55:38,328 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97450, lr: 0.000442, loss: 0.0438 (0.0495)
2023-01-23 10:55:57,306 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97500, lr: 0.000442, loss: 0.0445 (0.0495)
2023-01-23 10:56:16,150 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97550, lr: 0.000442, loss: 0.0462 (0.0495)
2023-01-23 10:56:35,260 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97600, lr: 0.000442, loss: 0.0477 (0.0495)
2023-01-23 10:56:54,201 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97650, lr: 0.000442, loss: 0.0433 (0.0495)
2023-01-23 10:57:13,236 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97700, lr: 0.000442, loss: 0.0461 (0.0495)
2023-01-23 10:57:32,156 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97750, lr: 0.000442, loss: 0.0451 (0.0495)
2023-01-23 10:57:51,058 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97800, lr: 0.000441, loss: 0.0460 (0.0495)
2023-01-23 10:58:10,077 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97850, lr: 0.000441, loss: 0.0484 (0.0495)
2023-01-23 10:58:29,144 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97900, lr: 0.000441, loss: 0.0447 (0.0495)
2023-01-23 10:58:48,238 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 97950, lr: 0.000441, loss: 0.0460 (0.0495)
2023-01-23 10:59:07,279 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98000, lr: 0.000441, loss: 0.0439 (0.0495)
2023-01-23 10:59:26,288 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98050, lr: 0.000441, loss: 0.0418 (0.0495)
2023-01-23 10:59:45,224 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98100, lr: 0.000441, loss: 0.0462 (0.0495)
2023-01-23 11:00:04,294 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98150, lr: 0.000441, loss: 0.0473 (0.0495)
2023-01-23 11:00:23,193 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98200, lr: 0.000440, loss: 0.0457 (0.0495)
2023-01-23 11:00:42,043 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98250, lr: 0.000440, loss: 0.0447 (0.0495)
2023-01-23 11:01:01,056 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98300, lr: 0.000440, loss: 0.0454 (0.0495)
2023-01-23 11:01:20,113 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98350, lr: 0.000440, loss: 0.0416 (0.0495)
2023-01-23 11:01:39,071 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98400, lr: 0.000440, loss: 0.0470 (0.0495)
2023-01-23 11:01:58,106 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98450, lr: 0.000440, loss: 0.0446 (0.0495)
2023-01-23 11:02:17,109 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98500, lr: 0.000440, loss: 0.0449 (0.0495)
2023-01-23 11:02:36,089 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98550, lr: 0.000440, loss: 0.0453 (0.0494)
2023-01-23 11:02:55,033 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98600, lr: 0.000439, loss: 0.0446 (0.0494)
2023-01-23 11:03:14,039 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98650, lr: 0.000439, loss: 0.0422 (0.0494)
2023-01-23 11:03:33,022 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98700, lr: 0.000439, loss: 0.0451 (0.0494)
2023-01-23 11:03:51,886 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98750, lr: 0.000439, loss: 0.0455 (0.0494)
2023-01-23 11:04:10,768 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98800, lr: 0.000439, loss: 0.0453 (0.0494)
2023-01-23 11:04:29,770 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98850, lr: 0.000439, loss: 0.0433 (0.0494)
2023-01-23 11:04:48,744 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98900, lr: 0.000439, loss: 0.0451 (0.0494)
2023-01-23 11:05:07,670 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 98950, lr: 0.000439, loss: 0.0451 (0.0494)
2023-01-23 11:05:26,689 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99000, lr: 0.000438, loss: 0.0459 (0.0494)
2023-01-23 11:05:45,608 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99050, lr: 0.000438, loss: 0.0454 (0.0494)
2023-01-23 11:06:04,561 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99100, lr: 0.000438, loss: 0.0451 (0.0494)
2023-01-23 11:06:23,545 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99150, lr: 0.000438, loss: 0.0455 (0.0494)
2023-01-23 11:06:42,505 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99200, lr: 0.000438, loss: 0.0463 (0.0494)
2023-01-23 11:07:01,461 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99250, lr: 0.000438, loss: 0.0458 (0.0494)
2023-01-23 11:07:20,312 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99300, lr: 0.000438, loss: 0.0437 (0.0494)
2023-01-23 11:07:39,454 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99350, lr: 0.000438, loss: 0.0452 (0.0494)
2023-01-23 11:07:58,685 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99400, lr: 0.000437, loss: 0.0506 (0.0494)
2023-01-23 11:08:17,775 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99450, lr: 0.000437, loss: 0.0433 (0.0494)
2023-01-23 11:08:36,953 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99500, lr: 0.000437, loss: 0.0470 (0.0494)
2023-01-23 11:08:56,177 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99550, lr: 0.000437, loss: 0.0427 (0.0494)
2023-01-23 11:09:15,412 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99600, lr: 0.000437, loss: 0.0464 (0.0494)
2023-01-23 11:09:34,515 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99650, lr: 0.000437, loss: 0.0464 (0.0494)
2023-01-23 11:09:53,678 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99700, lr: 0.000437, loss: 0.0454 (0.0494)
2023-01-23 11:10:13,000 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99750, lr: 0.000437, loss: 0.0450 (0.0494)
2023-01-23 11:10:32,075 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99800, lr: 0.000436, loss: 0.0443 (0.0494)
2023-01-23 11:10:51,330 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99850, lr: 0.000436, loss: 0.0443 (0.0494)
2023-01-23 11:11:10,524 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99900, lr: 0.000436, loss: 0.0465 (0.0494)
2023-01-23 11:11:29,640 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 99950, lr: 0.000436, loss: 0.0445 (0.0494)
2023-01-23 11:11:48,796 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100000, lr: 0.000436, loss: 0.0425 (0.0494)
2023-01-23 11:11:50,178 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_13_100000.pt
2023-01-23 11:12:09,256 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100050, lr: 0.000436, loss: 0.0446 (0.0494)
2023-01-23 11:12:28,321 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100100, lr: 0.000436, loss: 0.0464 (0.0494)
2023-01-23 11:12:47,427 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100150, lr: 0.000436, loss: 0.0436 (0.0494)
2023-01-23 11:13:06,568 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100200, lr: 0.000435, loss: 0.0446 (0.0494)
2023-01-23 11:13:25,841 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100250, lr: 0.000435, loss: 0.0436 (0.0494)
2023-01-23 11:13:44,998 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100300, lr: 0.000435, loss: 0.0445 (0.0494)
2023-01-23 11:14:04,040 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100350, lr: 0.000435, loss: 0.0448 (0.0494)
2023-01-23 11:14:23,230 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100400, lr: 0.000435, loss: 0.0427 (0.0494)
2023-01-23 11:14:42,380 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100450, lr: 0.000435, loss: 0.0429 (0.0494)
2023-01-23 11:15:01,438 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100500, lr: 0.000435, loss: 0.0421 (0.0494)
2023-01-23 11:15:20,627 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100550, lr: 0.000435, loss: 0.0444 (0.0493)
2023-01-23 11:15:39,884 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100600, lr: 0.000434, loss: 0.0447 (0.0493)
2023-01-23 11:15:59,068 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100650, lr: 0.000434, loss: 0.0469 (0.0493)
2023-01-23 11:16:18,203 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100700, lr: 0.000434, loss: 0.0453 (0.0493)
2023-01-23 11:16:37,307 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100750, lr: 0.000434, loss: 0.0417 (0.0493)
2023-01-23 11:16:56,360 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100800, lr: 0.000434, loss: 0.0431 (0.0493)
2023-01-23 11:17:15,533 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100850, lr: 0.000434, loss: 0.0445 (0.0493)
2023-01-23 11:17:34,719 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100900, lr: 0.000434, loss: 0.0430 (0.0493)
2023-01-23 11:17:53,781 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 100950, lr: 0.000433, loss: 0.0450 (0.0493)
2023-01-23 11:18:12,725 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101000, lr: 0.000433, loss: 0.0420 (0.0493)
2023-01-23 11:18:31,605 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101050, lr: 0.000433, loss: 0.0483 (0.0493)
2023-01-23 11:18:50,525 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101100, lr: 0.000433, loss: 0.0480 (0.0493)
2023-01-23 11:19:09,438 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101150, lr: 0.000433, loss: 0.0423 (0.0493)
2023-01-23 11:19:28,392 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101200, lr: 0.000433, loss: 0.0457 (0.0493)
2023-01-23 11:19:47,414 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101250, lr: 0.000433, loss: 0.0455 (0.0493)
2023-01-23 11:20:06,344 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101300, lr: 0.000433, loss: 0.0442 (0.0493)
2023-01-23 11:20:25,348 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101350, lr: 0.000432, loss: 0.0447 (0.0493)
2023-01-23 11:20:44,169 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101400, lr: 0.000432, loss: 0.0444 (0.0493)
2023-01-23 11:21:03,203 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101450, lr: 0.000432, loss: 0.0442 (0.0493)
2023-01-23 11:21:22,112 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101500, lr: 0.000432, loss: 0.0457 (0.0493)
2023-01-23 11:21:41,099 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101550, lr: 0.000432, loss: 0.0435 (0.0493)
2023-01-23 11:22:00,006 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101600, lr: 0.000432, loss: 0.0429 (0.0493)
2023-01-23 11:22:19,028 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101650, lr: 0.000432, loss: 0.0455 (0.0493)
2023-01-23 11:22:37,966 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101700, lr: 0.000432, loss: 0.0419 (0.0493)
2023-01-23 11:22:56,905 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101750, lr: 0.000431, loss: 0.0453 (0.0493)
2023-01-23 11:23:15,926 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101800, lr: 0.000431, loss: 0.0446 (0.0493)
2023-01-23 11:23:34,810 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101850, lr: 0.000431, loss: 0.0453 (0.0493)
2023-01-23 11:23:53,779 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101900, lr: 0.000431, loss: 0.0444 (0.0493)
2023-01-23 11:24:12,694 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 101950, lr: 0.000431, loss: 0.0442 (0.0493)
2023-01-23 11:24:31,548 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102000, lr: 0.000431, loss: 0.0431 (0.0493)
2023-01-23 11:24:50,592 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102050, lr: 0.000431, loss: 0.0449 (0.0493)
2023-01-23 11:25:09,514 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102100, lr: 0.000430, loss: 0.0440 (0.0493)
2023-01-23 11:25:28,445 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102150, lr: 0.000430, loss: 0.0446 (0.0493)
2023-01-23 11:25:47,328 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102200, lr: 0.000430, loss: 0.0430 (0.0493)
2023-01-23 11:26:06,332 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102250, lr: 0.000430, loss: 0.0440 (0.0493)
2023-01-23 11:26:25,247 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102300, lr: 0.000430, loss: 0.0468 (0.0493)
2023-01-23 11:26:44,177 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102350, lr: 0.000430, loss: 0.0425 (0.0493)
2023-01-23 11:27:03,076 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102400, lr: 0.000430, loss: 0.0423 (0.0493)
2023-01-23 11:27:21,973 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102450, lr: 0.000430, loss: 0.0408 (0.0493)
2023-01-23 11:27:40,997 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102500, lr: 0.000429, loss: 0.0436 (0.0493)
2023-01-23 11:27:59,984 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102550, lr: 0.000429, loss: 0.0481 (0.0492)
2023-01-23 11:28:18,880 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102600, lr: 0.000429, loss: 0.0456 (0.0492)
2023-01-23 11:28:37,905 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102650, lr: 0.000429, loss: 0.0445 (0.0492)
2023-01-23 11:28:56,820 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102700, lr: 0.000429, loss: 0.0462 (0.0492)
2023-01-23 11:29:15,778 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102750, lr: 0.000429, loss: 0.0412 (0.0492)
2023-01-23 11:29:34,662 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102800, lr: 0.000429, loss: 0.0401 (0.0492)
2023-01-23 11:29:53,585 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102850, lr: 0.000429, loss: 0.0459 (0.0492)
2023-01-23 11:30:12,547 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102900, lr: 0.000428, loss: 0.0457 (0.0492)
2023-01-23 11:30:31,391 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 102950, lr: 0.000428, loss: 0.0413 (0.0492)
2023-01-23 11:30:50,314 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103000, lr: 0.000428, loss: 0.0443 (0.0492)
2023-01-23 11:31:09,373 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103050, lr: 0.000428, loss: 0.0448 (0.0492)
2023-01-23 11:31:28,312 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103100, lr: 0.000428, loss: 0.0418 (0.0492)
2023-01-23 11:31:47,342 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103150, lr: 0.000428, loss: 0.0434 (0.0492)
2023-01-23 11:32:06,373 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103200, lr: 0.000428, loss: 0.0478 (0.0492)
2023-01-23 11:32:25,324 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103250, lr: 0.000427, loss: 0.0420 (0.0492)
2023-01-23 11:32:44,349 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103300, lr: 0.000427, loss: 0.0428 (0.0492)
2023-01-23 11:33:03,303 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103350, lr: 0.000427, loss: 0.0422 (0.0492)
2023-01-23 11:33:22,168 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103400, lr: 0.000427, loss: 0.0455 (0.0492)
2023-01-23 11:33:41,279 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103450, lr: 0.000427, loss: 0.0451 (0.0492)
2023-01-23 11:34:00,255 CLIP_COCO_TRAIN INFO: Epoch: 13, global_step: 103500, lr: 0.000427, loss: 0.0459 (0.0492)
2023-01-23 11:34:19,169 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103550, lr: 0.000427, loss: 0.0454 (0.0492)
2023-01-23 11:34:38,126 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103600, lr: 0.000427, loss: 0.0425 (0.0492)
2023-01-23 11:34:57,074 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103650, lr: 0.000426, loss: 0.0414 (0.0492)
2023-01-23 11:35:16,017 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103700, lr: 0.000426, loss: 0.0427 (0.0492)
2023-01-23 11:35:34,905 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103750, lr: 0.000426, loss: 0.0430 (0.0492)
2023-01-23 11:35:53,732 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103800, lr: 0.000426, loss: 0.0432 (0.0492)
2023-01-23 11:36:12,558 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103850, lr: 0.000426, loss: 0.0431 (0.0492)
2023-01-23 11:36:31,425 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103900, lr: 0.000426, loss: 0.0492 (0.0492)
2023-01-23 11:36:50,291 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 103950, lr: 0.000426, loss: 0.0409 (0.0492)
2023-01-23 11:37:09,246 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104000, lr: 0.000425, loss: 0.0423 (0.0492)
2023-01-23 11:37:28,166 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104050, lr: 0.000425, loss: 0.0425 (0.0492)
2023-01-23 11:37:47,003 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104100, lr: 0.000425, loss: 0.0445 (0.0492)
2023-01-23 11:38:05,815 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104150, lr: 0.000425, loss: 0.0452 (0.0492)
2023-01-23 11:38:24,642 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104200, lr: 0.000425, loss: 0.0450 (0.0492)
2023-01-23 11:38:43,455 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104250, lr: 0.000425, loss: 0.0415 (0.0492)
2023-01-23 11:39:02,414 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104300, lr: 0.000425, loss: 0.0431 (0.0492)
2023-01-23 11:39:21,342 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104350, lr: 0.000424, loss: 0.0441 (0.0492)
2023-01-23 11:39:40,195 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104400, lr: 0.000424, loss: 0.0420 (0.0492)
2023-01-23 11:39:59,108 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104450, lr: 0.000424, loss: 0.0458 (0.0492)
2023-01-23 11:40:18,065 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104500, lr: 0.000424, loss: 0.0415 (0.0492)
2023-01-23 11:40:36,981 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104550, lr: 0.000424, loss: 0.0442 (0.0492)
2023-01-23 11:40:55,939 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104600, lr: 0.000424, loss: 0.0441 (0.0492)
2023-01-23 11:41:14,710 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104650, lr: 0.000424, loss: 0.0448 (0.0491)
2023-01-23 11:41:33,555 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104700, lr: 0.000424, loss: 0.0423 (0.0491)
2023-01-23 11:41:52,408 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104750, lr: 0.000423, loss: 0.0461 (0.0491)
2023-01-23 11:42:11,294 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104800, lr: 0.000423, loss: 0.0451 (0.0491)
2023-01-23 11:42:30,387 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104850, lr: 0.000423, loss: 0.0505 (0.0491)
2023-01-23 11:42:49,478 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104900, lr: 0.000423, loss: 0.0438 (0.0491)
2023-01-23 11:43:08,592 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 104950, lr: 0.000423, loss: 0.0413 (0.0491)
2023-01-23 11:43:27,725 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105000, lr: 0.000423, loss: 0.0460 (0.0491)
2023-01-23 11:43:46,866 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105050, lr: 0.000423, loss: 0.0443 (0.0491)
2023-01-23 11:44:05,986 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105100, lr: 0.000422, loss: 0.0439 (0.0491)
2023-01-23 11:44:25,007 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105150, lr: 0.000422, loss: 0.0447 (0.0491)
2023-01-23 11:44:44,170 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105200, lr: 0.000422, loss: 0.0457 (0.0491)
2023-01-23 11:45:03,341 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105250, lr: 0.000422, loss: 0.0433 (0.0491)
2023-01-23 11:45:22,415 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105300, lr: 0.000422, loss: 0.0412 (0.0491)
2023-01-23 11:45:41,574 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105350, lr: 0.000422, loss: 0.0419 (0.0491)
2023-01-23 11:46:00,609 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105400, lr: 0.000422, loss: 0.0436 (0.0491)
2023-01-23 11:46:19,608 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105450, lr: 0.000421, loss: 0.0437 (0.0491)
2023-01-23 11:46:38,718 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105500, lr: 0.000421, loss: 0.0422 (0.0491)
2023-01-23 11:46:57,705 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105550, lr: 0.000421, loss: 0.0423 (0.0491)
2023-01-23 11:47:16,745 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105600, lr: 0.000421, loss: 0.0399 (0.0491)
2023-01-23 11:47:35,856 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105650, lr: 0.000421, loss: 0.0458 (0.0491)
2023-01-23 11:47:54,927 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105700, lr: 0.000421, loss: 0.0458 (0.0491)
2023-01-23 11:48:13,995 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105750, lr: 0.000421, loss: 0.0420 (0.0491)
2023-01-23 11:48:33,091 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105800, lr: 0.000421, loss: 0.0434 (0.0491)
2023-01-23 11:48:52,182 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105850, lr: 0.000420, loss: 0.0428 (0.0491)
2023-01-23 11:49:11,225 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105900, lr: 0.000420, loss: 0.0448 (0.0491)
2023-01-23 11:49:30,252 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 105950, lr: 0.000420, loss: 0.0419 (0.0491)
2023-01-23 11:49:49,329 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106000, lr: 0.000420, loss: 0.0430 (0.0491)
2023-01-23 11:50:08,309 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106050, lr: 0.000420, loss: 0.0439 (0.0491)
2023-01-23 11:50:27,338 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106100, lr: 0.000420, loss: 0.0414 (0.0491)
2023-01-23 11:50:46,364 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106150, lr: 0.000420, loss: 0.0452 (0.0491)
2023-01-23 11:51:05,417 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106200, lr: 0.000419, loss: 0.0441 (0.0491)
2023-01-23 11:51:24,526 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106250, lr: 0.000419, loss: 0.0427 (0.0491)
2023-01-23 11:51:43,557 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106300, lr: 0.000419, loss: 0.0471 (0.0491)
2023-01-23 11:52:02,521 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106350, lr: 0.000419, loss: 0.0440 (0.0491)
2023-01-23 11:52:21,491 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106400, lr: 0.000419, loss: 0.0415 (0.0491)
2023-01-23 11:52:40,482 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106450, lr: 0.000419, loss: 0.0438 (0.0491)
2023-01-23 11:52:59,532 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106500, lr: 0.000419, loss: 0.0463 (0.0491)
2023-01-23 11:53:18,467 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106550, lr: 0.000418, loss: 0.0485 (0.0491)
2023-01-23 11:53:37,471 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106600, lr: 0.000418, loss: 0.0456 (0.0491)
2023-01-23 11:53:56,503 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106650, lr: 0.000418, loss: 0.0431 (0.0491)
2023-01-23 11:54:15,557 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106700, lr: 0.000418, loss: 0.0448 (0.0491)
2023-01-23 11:54:34,528 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106750, lr: 0.000418, loss: 0.0415 (0.0491)
2023-01-23 11:54:53,444 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106800, lr: 0.000418, loss: 0.0452 (0.0490)
2023-01-23 11:55:12,548 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106850, lr: 0.000418, loss: 0.0430 (0.0490)
2023-01-23 11:55:31,606 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106900, lr: 0.000417, loss: 0.0445 (0.0490)
2023-01-23 11:55:50,671 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 106950, lr: 0.000417, loss: 0.0418 (0.0490)
2023-01-23 11:56:09,640 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107000, lr: 0.000417, loss: 0.0437 (0.0490)
2023-01-23 11:56:28,655 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107050, lr: 0.000417, loss: 0.0442 (0.0490)
2023-01-23 11:56:47,360 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107100, lr: 0.000417, loss: 0.0450 (0.0490)
2023-01-23 11:57:06,104 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107150, lr: 0.000417, loss: 0.0467 (0.0490)
2023-01-23 11:57:24,925 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107200, lr: 0.000417, loss: 0.0444 (0.0490)
2023-01-23 11:57:43,818 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107250, lr: 0.000416, loss: 0.0459 (0.0490)
2023-01-23 11:58:02,621 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107300, lr: 0.000416, loss: 0.0449 (0.0490)
2023-01-23 11:58:21,349 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107350, lr: 0.000416, loss: 0.0461 (0.0490)
2023-01-23 11:58:40,122 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107400, lr: 0.000416, loss: 0.0426 (0.0490)
2023-01-23 11:58:58,950 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107450, lr: 0.000416, loss: 0.0476 (0.0490)
2023-01-23 11:59:17,696 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107500, lr: 0.000416, loss: 0.0428 (0.0490)
2023-01-23 11:59:36,646 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107550, lr: 0.000416, loss: 0.0420 (0.0490)
2023-01-23 11:59:55,527 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107600, lr: 0.000415, loss: 0.0436 (0.0490)
2023-01-23 12:00:14,336 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107650, lr: 0.000415, loss: 0.0433 (0.0490)
2023-01-23 12:00:33,182 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107700, lr: 0.000415, loss: 0.0467 (0.0490)
2023-01-23 12:00:51,962 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107750, lr: 0.000415, loss: 0.0437 (0.0490)
2023-01-23 12:01:10,724 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107800, lr: 0.000415, loss: 0.0419 (0.0490)
2023-01-23 12:01:29,535 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107850, lr: 0.000415, loss: 0.0452 (0.0490)
2023-01-23 12:01:48,172 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107900, lr: 0.000415, loss: 0.0457 (0.0490)
2023-01-23 12:02:07,197 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 107950, lr: 0.000414, loss: 0.0423 (0.0490)
2023-01-23 12:02:26,027 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108000, lr: 0.000414, loss: 0.0409 (0.0490)
2023-01-23 12:02:44,796 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108050, lr: 0.000414, loss: 0.0454 (0.0490)
2023-01-23 12:03:03,534 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108100, lr: 0.000414, loss: 0.0427 (0.0490)
2023-01-23 12:03:22,319 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108150, lr: 0.000414, loss: 0.0486 (0.0490)
2023-01-23 12:03:41,164 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108200, lr: 0.000414, loss: 0.0454 (0.0490)
2023-01-23 12:03:59,998 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108250, lr: 0.000414, loss: 0.0453 (0.0490)
2023-01-23 12:04:18,867 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108300, lr: 0.000413, loss: 0.0430 (0.0490)
2023-01-23 12:04:37,535 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108350, lr: 0.000413, loss: 0.0463 (0.0490)
2023-01-23 12:04:56,336 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108400, lr: 0.000413, loss: 0.0446 (0.0490)
2023-01-23 12:05:15,151 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108450, lr: 0.000413, loss: 0.0432 (0.0490)
2023-01-23 12:05:33,950 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108500, lr: 0.000413, loss: 0.0416 (0.0490)
2023-01-23 12:05:52,794 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108550, lr: 0.000413, loss: 0.0444 (0.0490)
2023-01-23 12:06:11,702 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108600, lr: 0.000413, loss: 0.0409 (0.0490)
2023-01-23 12:06:30,379 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108650, lr: 0.000412, loss: 0.0430 (0.0490)
2023-01-23 12:06:49,267 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108700, lr: 0.000412, loss: 0.0457 (0.0490)
2023-01-23 12:07:08,037 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108750, lr: 0.000412, loss: 0.0423 (0.0490)
2023-01-23 12:07:26,817 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108800, lr: 0.000412, loss: 0.0438 (0.0490)
2023-01-23 12:07:45,537 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108850, lr: 0.000412, loss: 0.0432 (0.0490)
2023-01-23 12:08:04,372 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108900, lr: 0.000412, loss: 0.0428 (0.0490)
2023-01-23 12:08:23,226 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 108950, lr: 0.000412, loss: 0.0427 (0.0489)
2023-01-23 12:08:42,148 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109000, lr: 0.000411, loss: 0.0424 (0.0489)
2023-01-23 12:09:00,945 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109050, lr: 0.000411, loss: 0.0438 (0.0489)
2023-01-23 12:09:19,775 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109100, lr: 0.000411, loss: 0.0419 (0.0489)
2023-01-23 12:09:38,582 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109150, lr: 0.000411, loss: 0.0465 (0.0489)
2023-01-23 12:09:57,437 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109200, lr: 0.000411, loss: 0.0417 (0.0489)
2023-01-23 12:10:16,193 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109250, lr: 0.000411, loss: 0.0446 (0.0489)
2023-01-23 12:10:35,068 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109300, lr: 0.000411, loss: 0.0451 (0.0489)
2023-01-23 12:10:53,842 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109350, lr: 0.000410, loss: 0.0426 (0.0489)
2023-01-23 12:11:12,567 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109400, lr: 0.000410, loss: 0.0429 (0.0489)
2023-01-23 12:11:31,407 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109450, lr: 0.000410, loss: 0.0460 (0.0489)
2023-01-23 12:11:50,346 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109500, lr: 0.000410, loss: 0.0469 (0.0489)
2023-01-23 12:12:09,230 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109550, lr: 0.000410, loss: 0.0454 (0.0489)
2023-01-23 12:12:28,023 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109600, lr: 0.000410, loss: 0.0433 (0.0489)
2023-01-23 12:12:46,889 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109650, lr: 0.000410, loss: 0.0428 (0.0489)
2023-01-23 12:13:05,674 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109700, lr: 0.000409, loss: 0.0455 (0.0489)
2023-01-23 12:13:24,444 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109750, lr: 0.000409, loss: 0.0470 (0.0489)
2023-01-23 12:13:43,246 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109800, lr: 0.000409, loss: 0.0416 (0.0489)
2023-01-23 12:14:02,082 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109850, lr: 0.000409, loss: 0.0444 (0.0489)
2023-01-23 12:14:20,870 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109900, lr: 0.000409, loss: 0.0445 (0.0489)
2023-01-23 12:14:39,771 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 109950, lr: 0.000409, loss: 0.0402 (0.0489)
2023-01-23 12:14:58,545 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110000, lr: 0.000409, loss: 0.0425 (0.0489)
2023-01-23 12:14:59,899 CLIP_COCO_TRAIN INFO: Save checkpoint to saved_checkpoints\checkpoint_14_110000.pt
2023-01-23 12:15:18,583 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110050, lr: 0.000408, loss: 0.0401 (0.0489)
2023-01-23 12:15:37,396 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110100, lr: 0.000408, loss: 0.0435 (0.0489)
2023-01-23 12:15:56,440 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110150, lr: 0.000408, loss: 0.0421 (0.0489)
2023-01-23 12:16:15,423 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110200, lr: 0.000408, loss: 0.0444 (0.0489)
2023-01-23 12:16:34,494 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110250, lr: 0.000408, loss: 0.0451 (0.0489)
2023-01-23 12:16:53,417 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110300, lr: 0.000408, loss: 0.0435 (0.0489)
2023-01-23 12:17:12,566 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110350, lr: 0.000407, loss: 0.0433 (0.0489)
2023-01-23 12:17:31,661 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110400, lr: 0.000407, loss: 0.0444 (0.0489)
2023-01-23 12:17:50,737 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110450, lr: 0.000407, loss: 0.0450 (0.0489)
2023-01-23 12:18:09,769 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110500, lr: 0.000407, loss: 0.0434 (0.0489)
2023-01-23 12:18:28,820 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110550, lr: 0.000407, loss: 0.0436 (0.0489)
2023-01-23 12:18:47,807 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110600, lr: 0.000407, loss: 0.0439 (0.0489)
2023-01-23 12:19:06,804 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110650, lr: 0.000407, loss: 0.0416 (0.0489)
2023-01-23 12:19:25,794 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110700, lr: 0.000406, loss: 0.0421 (0.0489)
2023-01-23 12:19:44,852 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110750, lr: 0.000406, loss: 0.0424 (0.0489)
2023-01-23 12:20:03,947 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110800, lr: 0.000406, loss: 0.0455 (0.0489)
2023-01-23 12:20:22,929 CLIP_COCO_TRAIN INFO: Epoch: 14, global_step: 110850, lr: 0.000406, loss: 0.0419 (0.0489)
2023-01-23 12:20:41,941 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 110900, lr: 0.000406, loss: 0.0428 (0.0489)
2023-01-23 12:21:00,775 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 110950, lr: 0.000406, loss: 0.0445 (0.0489)
2023-01-23 12:21:19,849 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111000, lr: 0.000406, loss: 0.0444 (0.0489)
2023-01-23 12:21:38,842 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111050, lr: 0.000405, loss: 0.0449 (0.0489)
2023-01-23 12:21:57,691 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111100, lr: 0.000405, loss: 0.0414 (0.0489)
2023-01-23 12:22:16,676 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111150, lr: 0.000405, loss: 0.0443 (0.0489)
2023-01-23 12:22:35,487 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111200, lr: 0.000405, loss: 0.0433 (0.0488)
2023-01-23 12:22:54,400 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111250, lr: 0.000405, loss: 0.0461 (0.0488)
2023-01-23 12:23:13,228 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111300, lr: 0.000405, loss: 0.0435 (0.0488)
2023-01-23 12:23:32,014 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111350, lr: 0.000405, loss: 0.0457 (0.0488)
2023-01-23 12:23:50,865 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111400, lr: 0.000404, loss: 0.0453 (0.0488)
2023-01-23 12:24:09,699 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111450, lr: 0.000404, loss: 0.0442 (0.0488)
2023-01-23 12:24:28,557 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111500, lr: 0.000404, loss: 0.0451 (0.0488)
2023-01-23 12:24:47,397 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111550, lr: 0.000404, loss: 0.0442 (0.0488)
2023-01-23 12:25:06,257 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111600, lr: 0.000404, loss: 0.0437 (0.0488)
2023-01-23 12:25:25,101 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111650, lr: 0.000404, loss: 0.0439 (0.0488)
2023-01-23 12:25:43,979 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111700, lr: 0.000403, loss: 0.0442 (0.0488)
2023-01-23 12:26:02,789 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111750, lr: 0.000403, loss: 0.0472 (0.0488)
2023-01-23 12:26:21,588 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111800, lr: 0.000403, loss: 0.0425 (0.0488)
2023-01-23 12:26:40,390 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111850, lr: 0.000403, loss: 0.0392 (0.0488)
2023-01-23 12:26:59,315 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111900, lr: 0.000403, loss: 0.0435 (0.0488)
2023-01-23 12:27:18,217 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 111950, lr: 0.000403, loss: 0.0463 (0.0488)
2023-01-23 12:27:37,000 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112000, lr: 0.000403, loss: 0.0450 (0.0488)
2023-01-23 12:27:55,876 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112050, lr: 0.000402, loss: 0.0421 (0.0488)
2023-01-23 12:28:14,741 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112100, lr: 0.000402, loss: 0.0440 (0.0488)
2023-01-23 12:28:33,593 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112150, lr: 0.000402, loss: 0.0471 (0.0488)
2023-01-23 12:28:52,446 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112200, lr: 0.000402, loss: 0.0452 (0.0488)
2023-01-23 12:29:11,279 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112250, lr: 0.000402, loss: 0.0440 (0.0488)
2023-01-23 12:29:30,089 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112300, lr: 0.000402, loss: 0.0430 (0.0488)
2023-01-23 12:29:48,979 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112350, lr: 0.000402, loss: 0.0456 (0.0488)
2023-01-23 12:30:07,804 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112400, lr: 0.000401, loss: 0.0404 (0.0488)
2023-01-23 12:30:26,689 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112450, lr: 0.000401, loss: 0.0420 (0.0488)
2023-01-23 12:30:45,490 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112500, lr: 0.000401, loss: 0.0417 (0.0488)
2023-01-23 12:31:04,319 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112550, lr: 0.000401, loss: 0.0480 (0.0488)
2023-01-23 12:31:23,245 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112600, lr: 0.000401, loss: 0.0424 (0.0488)
2023-01-23 12:31:42,210 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112650, lr: 0.000401, loss: 0.0457 (0.0488)
2023-01-23 12:32:01,042 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112700, lr: 0.000400, loss: 0.0457 (0.0488)
2023-01-23 12:32:20,006 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112750, lr: 0.000400, loss: 0.0438 (0.0488)
2023-01-23 12:32:38,927 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112800, lr: 0.000400, loss: 0.0463 (0.0488)
2023-01-23 12:32:57,779 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112850, lr: 0.000400, loss: 0.0430 (0.0488)
2023-01-23 12:33:16,630 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112900, lr: 0.000400, loss: 0.0456 (0.0488)
2023-01-23 12:33:35,557 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 112950, lr: 0.000400, loss: 0.0465 (0.0488)
2023-01-23 12:33:54,478 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113000, lr: 0.000400, loss: 0.0448 (0.0488)
2023-01-23 12:34:13,327 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113050, lr: 0.000399, loss: 0.0437 (0.0488)
2023-01-23 12:34:32,185 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113100, lr: 0.000399, loss: 0.0445 (0.0488)
2023-01-23 12:34:50,993 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113150, lr: 0.000399, loss: 0.0423 (0.0488)
2023-01-23 12:35:09,579 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113200, lr: 0.000399, loss: 0.0445 (0.0488)
2023-01-23 12:35:28,199 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113250, lr: 0.000399, loss: 0.0448 (0.0488)
2023-01-23 12:35:46,792 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113300, lr: 0.000399, loss: 0.0423 (0.0488)
2023-01-23 12:36:05,380 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113350, lr: 0.000398, loss: 0.0439 (0.0488)
2023-01-23 12:36:24,015 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113400, lr: 0.000398, loss: 0.0400 (0.0488)
2023-01-23 12:36:42,612 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113450, lr: 0.000398, loss: 0.0458 (0.0487)
2023-01-23 12:37:01,412 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113500, lr: 0.000398, loss: 0.0442 (0.0487)
2023-01-23 12:37:20,067 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113550, lr: 0.000398, loss: 0.0446 (0.0487)
2023-01-23 12:37:38,738 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113600, lr: 0.000398, loss: 0.0443 (0.0487)
2023-01-23 12:37:57,421 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113650, lr: 0.000398, loss: 0.0416 (0.0487)
2023-01-23 12:38:16,014 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113700, lr: 0.000397, loss: 0.0413 (0.0487)
2023-01-23 12:38:34,688 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113750, lr: 0.000397, loss: 0.0428 (0.0487)
2023-01-23 12:38:53,317 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113800, lr: 0.000397, loss: 0.0427 (0.0487)
2023-01-23 12:39:11,947 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113850, lr: 0.000397, loss: 0.0474 (0.0487)
2023-01-23 12:39:30,663 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113900, lr: 0.000397, loss: 0.0440 (0.0487)
2023-01-23 12:39:49,245 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 113950, lr: 0.000397, loss: 0.0447 (0.0487)
2023-01-23 12:40:08,017 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114000, lr: 0.000396, loss: 0.0462 (0.0487)
2023-01-23 12:40:26,711 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114050, lr: 0.000396, loss: 0.0444 (0.0487)
2023-01-23 12:40:45,375 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114100, lr: 0.000396, loss: 0.0400 (0.0487)
2023-01-23 12:41:03,930 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114150, lr: 0.000396, loss: 0.0444 (0.0487)
2023-01-23 12:41:24,095 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114200, lr: 0.000396, loss: 0.0457 (0.0487)
2023-01-23 12:41:46,566 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114250, lr: 0.000396, loss: 0.0509 (0.0487)
2023-01-23 12:42:06,257 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114300, lr: 0.000396, loss: 0.0447 (0.0487)
2023-01-23 12:42:25,744 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114350, lr: 0.000395, loss: 0.0428 (0.0487)
2023-01-23 12:42:45,360 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114400, lr: 0.000395, loss: 0.0399 (0.0487)
2023-01-23 12:43:05,253 CLIP_COCO_TRAIN INFO: Epoch: 15, global_step: 114450, lr: 0.000395, loss: 0.0417 (0.0487)
2023-01-23 13:50:34,294 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 13:50:37,166 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 13:50:37,167 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 13:50:37,168 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 13:50:37,169 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 13:50:37,169 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 13:50:37,170 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 13:50:37,171 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 13:50:37,172 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 13:50:37,172 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 13:51:16,338 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 13:51:19,201 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 13:51:19,202 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 13:51:19,203 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 13:51:19,204 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 13:51:19,205 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 13:51:19,206 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 13:51:19,206 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 13:51:19,207 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 13:51:19,208 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 13:53:29,498 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 13:53:32,263 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 13:53:32,264 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 13:53:32,265 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 13:53:32,266 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 13:53:32,267 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 13:53:32,267 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 13:53:32,268 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 13:53:32,268 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 13:53:32,269 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 13:55:10,635 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 13:55:13,515 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 13:55:13,515 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 13:55:13,517 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 13:55:13,520 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 13:55:13,522 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 13:55:13,524 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 13:55:13,525 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 13:55:13,526 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 13:55:13,526 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 13:57:00,004 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 13:57:02,783 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 13:57:02,786 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 13:57:02,787 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 13:57:02,788 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 13:57:02,789 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 13:57:02,790 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 13:57:02,790 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 13:57:02,791 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 13:57:02,792 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 13:59:42,323 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 13:59:45,248 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 13:59:45,249 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 13:59:45,251 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 13:59:45,252 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 13:59:45,253 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 13:59:45,254 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 13:59:45,255 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 13:59:45,256 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 13:59:45,256 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:01:48,669 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:01:51,460 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:01:51,461 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:01:51,462 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:01:51,463 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:01:51,463 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:01:51,464 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:01:51,465 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:01:51,465 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:01:51,466 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:06:11,966 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:06:14,692 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:06:14,693 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:06:14,694 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:06:14,694 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:06:14,695 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:06:14,696 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:06:14,696 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:06:14,697 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:06:14,698 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:06:46,752 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:06:49,409 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:06:49,410 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:06:49,411 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:06:49,412 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:06:49,413 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:06:49,414 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:06:49,414 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:06:49,415 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:06:49,415 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:07:23,544 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:07:26,185 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:07:26,186 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:07:26,187 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:07:26,189 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:07:26,190 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:07:26,191 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:07:26,193 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:07:26,195 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:07:26,196 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:07:57,530 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:08:00,425 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:08:00,426 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:08:00,427 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:08:00,427 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:08:00,428 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:08:00,428 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:08:00,429 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:08:00,429 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:08:00,430 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:12:48,867 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:12:51,783 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:12:51,784 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:12:51,785 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:12:51,786 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:12:51,786 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:12:51,787 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:12:51,787 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:12:51,787 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:12:51,788 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:13:50,457 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:13:53,202 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:13:53,204 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:13:53,206 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:13:53,208 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:13:53,210 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:13:53,212 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:13:53,213 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:13:53,214 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:13:53,215 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:15:35,047 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:15:37,767 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:15:37,769 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:15:37,771 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:15:37,772 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:15:37,773 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:15:37,775 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:15:37,776 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:15:37,777 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:15:37,778 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:16:02,020 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:16:04,768 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:16:04,769 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:16:04,770 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:16:04,771 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:16:04,771 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:16:04,772 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:16:04,772 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:16:04,773 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:16:04,773 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:17:12,784 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:17:15,585 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:17:15,588 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:17:15,590 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:17:15,592 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:17:15,593 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:17:15,594 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:17:15,596 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:17:15,598 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:17:15,598 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:19:15,199 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:19:18,013 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:19:18,014 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:19:18,016 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:19:18,019 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:19:18,020 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:19:18,022 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:19:18,023 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:19:18,024 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:19:18,025 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:20:07,074 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:20:10,013 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:20:10,014 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:20:10,015 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:20:10,015 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:20:10,015 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:20:10,017 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:20:10,017 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:20:10,018 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:20:10,019 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:23:03,567 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:23:06,451 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:23:06,452 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:23:06,454 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:23:06,456 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:23:06,458 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:23:06,459 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:23:06,460 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:23:06,460 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:23:06,461 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:24:01,120 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:24:04,004 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:24:04,005 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:24:04,006 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:24:04,007 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:24:04,007 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:24:04,008 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:24:04,009 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:24:04,009 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:24:04,010 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:27:14,957 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:27:17,714 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:27:17,714 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:27:17,715 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:27:17,716 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:27:17,716 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:27:17,717 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:27:17,718 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:27:17,719 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:27:17,720 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:31:14,300 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:31:17,118 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:31:17,119 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:31:17,120 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:31:17,121 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:31:17,121 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:31:17,122 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:31:17,123 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:31:17,124 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:31:17,124 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:34:15,756 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:34:18,582 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:34:18,583 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:34:18,585 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:34:18,587 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:34:18,588 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:34:18,589 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:34:18,590 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:34:18,591 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:34:18,592 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:39:54,843 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:39:57,610 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:39:57,612 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:39:57,614 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:39:57,615 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:39:57,615 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:39:57,616 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:39:57,617 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:39:57,618 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:39:57,618 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:40:36,027 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:40:38,749 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:40:38,750 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:40:38,750 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:40:38,750 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:40:38,751 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:40:38,751 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:40:38,751 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:40:38,752 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:40:38,752 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 14:41:11,323 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 14:41:14,159 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 14:41:14,161 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 14:41:14,163 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 14:41:14,165 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 14:41:14,167 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 14:41:14,169 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 14:41:14,170 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 14:41:14,171 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 14:41:14,171 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 15:15:32,682 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 15:15:35,729 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 15:15:35,731 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 15:15:35,732 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 15:15:35,734 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 15:15:35,734 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 15:15:35,735 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 15:15:35,737 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 15:15:35,737 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 15:15:35,739 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-23 15:16:39,942 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-23 15:16:42,719 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-23 15:16:42,721 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-23 15:16:42,722 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-23 15:16:42,723 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-23 15:16:42,724 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-23 15:16:42,725 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-23 15:16:42,726 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-23 15:16:42,727 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-23 15:16:42,727 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-30 18:37:34,214 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-30 18:38:14,734 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-30 18:38:16,807 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-30 18:38:16,807 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-30 18:38:16,808 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-30 18:38:16,808 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-30 18:38:16,808 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-30 18:38:16,809 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-30 18:38:16,809 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-30 18:38:16,809 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-30 18:38:16,810 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-30 20:03:32,043 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-30 20:03:34,151 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-30 20:03:34,152 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-30 20:03:34,152 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-30 20:03:34,152 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-30 20:03:34,153 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-30 20:03:34,153 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-30 20:03:34,153 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-30 20:03:34,153 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-30 20:03:34,154 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
2023-01-30 23:13:57,518 CLIP_COCO_TRAIN INFO: Training/evaluation parameters {'per_gpu_train_batch_size': 1, 'per_gpu_eval_batch_size': 128, 'n_gpu': 1, 'num_workers': 0, 'num_train_epochs': 35, 'gradient_accumulation_steps': 1, 'logging_steps': 50, 'save_steps': 10000, 'saved_checkpoints': 'saved_checkpoints', 'logs': 'logs', 'optimizer': {'params': {'eps': 1e-08, 'lr': 0.0005, 'weight_decay': 0.1}, 'type': 'AdamW'}}
2023-01-30 23:13:59,685 CLIP_COCO_TRAIN INFO: ***** Running training *****
2023-01-30 23:13:59,686 CLIP_COCO_TRAIN INFO:   Num examples = 118287
2023-01-30 23:13:59,686 CLIP_COCO_TRAIN INFO:   Num Epochs = 35
2023-01-30 23:13:59,687 CLIP_COCO_TRAIN INFO:   Number of GPUs = 1
2023-01-30 23:13:59,687 CLIP_COCO_TRAIN INFO:   Batch size per GPU = 1
2023-01-30 23:13:59,687 CLIP_COCO_TRAIN INFO:   Total train batch size (w. parallel, & accumulation) = 1
2023-01-30 23:13:59,688 CLIP_COCO_TRAIN INFO:   Gradient Accumulation steps = 1
2023-01-30 23:13:59,688 CLIP_COCO_TRAIN INFO:   Total optimization steps = 4140045
2023-01-30 23:13:59,688 CLIP_COCO_TRAIN INFO:   warmup steps = 828009
